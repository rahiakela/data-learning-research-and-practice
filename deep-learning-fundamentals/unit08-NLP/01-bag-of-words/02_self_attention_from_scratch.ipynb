{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-fundamentals/unit08-NLP/01-bag-of-words/02_self_attention_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed46618-9b66-425c-b7a0-f606d4593e2d",
      "metadata": {
        "id": "eed46618-9b66-425c-b7a0-f606d4593e2d"
      },
      "source": [
        "##Self-attention works from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07784975-91ec-4a0b-8761-0f2a1790a2c9",
      "metadata": {
        "id": "07784975-91ec-4a0b-8761-0f2a1790a2c9"
      },
      "source": [
        "**Reference**\n",
        "\n",
        "[Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "kywwhUORWSgA"
      },
      "id": "kywwhUORWSgA"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "YcGxibJO0wM8"
      },
      "id": "YcGxibJO0wM8",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d98f84c6-761a-46cb-a566-ce98779dfb90",
      "metadata": {
        "id": "d98f84c6-761a-46cb-a566-ce98779dfb90"
      },
      "source": [
        "## 1) Embedding Input Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd96d52b-94bd-4554-9a8c-ff9af76e09a8",
      "metadata": {
        "id": "cd96d52b-94bd-4554-9a8c-ff9af76e09a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3aa33d-2e37-44e0-bfb9-f8e441d26587"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "sentence = \"Life is short, eat dessert first\"\n",
        "\n",
        "# create vocab\n",
        "vocab = {w: i for i, w in enumerate(sorted(sentence.replace(\",\", \"\").split()))}\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make integer-vector representation\n",
        "sentence_vec = torch.tensor([vocab[w] for w in sentence.replace(\",\", \"\").split()])\n",
        "sentence_vec"
      ],
      "metadata": {
        "id": "-vCUMM0OYA5k",
        "outputId": "7ec11782-c967-4950-c1e7-744153055b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-vCUMM0OYA5k",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 4, 5, 2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ec41419-b265-45f9-b1c9-f56aba6fe2f1",
      "metadata": {
        "id": "0ec41419-b265-45f9-b1c9-f56aba6fe2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6d2f39-d625-4dac-adcc-bfda4d85d83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 16])\n",
            "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
            "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
            "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
            "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
            "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
            "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
            "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
            "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
            "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
            "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
            "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
            "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# let's embed this integer-vector representation\n",
        "embedding = torch.nn.Embedding(6, 16)\n",
        "embedded_sentence = embedding(sentence_vec).detach()\n",
        "\n",
        "print(embedded_sentence.shape)\n",
        "print(embedded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01ee00f-6ac3-40c5-85d2-f5f43566d9a7",
      "metadata": {
        "id": "b01ee00f-6ac3-40c5-85d2-f5f43566d9a7"
      },
      "source": [
        "## 2)  Weight Matrices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "# For computing dot-product between the query and key vectors, it contain the same number of elements\n",
        "d_q, d_k, d_v = 24, 24, 28\n",
        "\n",
        "W_Q = torch.nn.Parameter(torch.rand(d_q, d))\n",
        "W_K = torch.nn.Parameter(torch.rand(d_k, d))\n",
        "W_V = torch.nn.Parameter(torch.rand(d_v, d))"
      ],
      "metadata": {
        "id": "itTmD8VVZweC"
      },
      "id": "itTmD8VVZweC",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_Q.shape, W_K.shape, W_V.shape"
      ],
      "metadata": {
        "id": "5SLyXO8CZqVW",
        "outputId": "ee900d88-bf1c-48e7-ce3e-f0dbab9120cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5SLyXO8CZqVW",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([24, 16]), torch.Size([24, 16]), torch.Size([28, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3) Computing Attention Weights"
      ],
      "metadata": {
        "id": "VqClvV5DY2T0"
      },
      "id": "VqClvV5DY2T0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d50678-3ab0-4075-ab50-3c12e63fd95f",
      "metadata": {
        "id": "65d50678-3ab0-4075-ab50-3c12e63fd95f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03491130-ad33-4fb7-8ed2-12de9662d400",
      "metadata": {
        "id": "03491130-ad33-4fb7-8ed2-12de9662d400",
        "outputId": "5299e405-e4a7-4f64-a9b9-3da7212afdde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12dd8956-f4db-410b-94c0-78190a8881cf",
      "metadata": {
        "id": "12dd8956-f4db-410b-94c0-78190a8881cf",
        "outputId": "842171b2-05b1-4deb-ff2d-d20fbc65ab64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 74 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e42b356-2aad-4447-b714-be0880df3c6c",
      "metadata": {
        "id": "9e42b356-2aad-4447-b714-be0880df3c6c",
        "outputId": "2905ae37-72dc-471e-e1b0-1314bd72c0b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "np.array(X_train[0].todense())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f185b5b-b7b2-4660-b6df-8c6faee8bf19",
      "metadata": {
        "id": "3f185b5b-b7b2-4660-b6df-8c6faee8bf19",
        "outputId": "75140cb7-4028-464e-a3a6-78f605c65948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9926,   67,    5,    0,    1,    0,    1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "np.bincount(np.array(X_train[0].todense())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e6a768-8fa8-444c-8bba-3c3797229a53",
      "metadata": {
        "id": "23e6a768-8fa8-444c-8bba-3c3797229a53",
        "outputId": "d44190bd-53b5-4996-94e8-17f52ccf6bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_train[0].todense().flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae181592-134d-4cff-983f-90d6fcae5068",
      "metadata": {
        "id": "ae181592-134d-4cff-983f-90d6fcae5068",
        "outputId": "634fbec1-7424-4ee0-da8a-34a064539852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "np.array(X_train.todense()).shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}