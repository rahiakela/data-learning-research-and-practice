{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-fundamentals/unit08-NLP/02-large-language-model/3_finetuning-all-layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5d72f4",
      "metadata": {
        "id": "3c5d72f4"
      },
      "source": [
        "# Finetuning All Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0873756d-262a-4525-b809-4e0b3a1e63dd",
      "metadata": {
        "id": "0873756d-262a-4525-b809-4e0b3a1e63dd"
      },
      "source": [
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-fundamentals/unit08-NLP/02-large-language-model/images/finetuning-ii.png?raw=1)\n",
        "\n",
        "\n",
        "**Reference**\n",
        "\n",
        "[Understanding Parameter-Efficient Finetuning of Large Language Models](https://lightning.ai/pages/community/article/understanding-llama-adapters/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "qdx7zCCnSX3H"
      },
      "id": "qdx7zCCnSX3H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd9cda8",
      "metadata": {
        "id": "6fd9cda8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install lightning\n",
        "!pip install torchmetrics\n",
        "!pip install mlxtend==0.21.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92ea5612",
      "metadata": {
        "id": "92ea5612"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/rasbt/blog-finetuning-llama-adapters/raw/main/three-conventional-methods/local_dataset_utilities.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7191cf-62ed-4793-8358-bee70b233d05",
      "metadata": {
        "id": "fe7191cf-62ed-4793-8358-bee70b233d05"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as op\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import lightning as L\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoModel\n",
        "\n",
        "import torchmetrics\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "\n",
        "from local_dataset_utilities import download_dataset, load_dataset_into_to_dataframe, partition_dataset\n",
        "from local_dataset_utilities import IMDBDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09213821-b2b4-402e-adf8-7c7fe4ec57cb",
      "metadata": {
        "tags": [],
        "id": "09213821-b2b4-402e-adf8-7c7fe4ec57cb"
      },
      "source": [
        "# 1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb31ac90-9e3a-41d0-baf1-8e613043924b",
      "metadata": {
        "id": "fb31ac90-9e3a-41d0-baf1-8e613043924b",
        "outputId": "b9561277-de63-4275-99d2-13e0d3d4a375"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 50000/50000 [00:24<00:00, 2023.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n"
          ]
        }
      ],
      "source": [
        "download_dataset()\n",
        "\n",
        "df = load_dataset_into_to_dataframe()\n",
        "partition_dataset(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221f30a1-b433-4304-a18d-8d03abd42b58",
      "metadata": {
        "id": "221f30a1-b433-4304-a18d-8d03abd42b58"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "876736c1-ae27-491c-850b-050507fa02b5",
      "metadata": {
        "id": "876736c1-ae27-491c-850b-050507fa02b5"
      },
      "source": [
        "# 2 Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe0cca0-bac4-49ed-982c-14c998e578d1",
      "metadata": {
        "id": "afe0cca0-bac4-49ed-982c-14c998e578d1"
      },
      "source": [
        "**Load the dataset via `load_dataset`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1aa66c7",
      "metadata": {
        "id": "a1aa66c7",
        "outputId": "be4402e7-4b9f-44b7-87c1-fe2b45092aa4",
        "colab": {
          "referenced_widgets": [
            "9d9091423f5c4c7f8ce30a4208df97ce",
            "c620f73d0ffe4e94a4336899859b5003",
            "",
            "dff20829bf3c4a51ac3e59007045d98c"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset csv/default to /home/sebastian/.cache/huggingface/datasets/csv/default-3e50991f5e7f1651/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d9091423f5c4c7f8ce30a4208df97ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c620f73d0ffe4e94a4336899859b5003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset csv downloaded and prepared to /home/sebastian/.cache/huggingface/datasets/csv/default-3e50991f5e7f1651/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dff20829bf3c4a51ac3e59007045d98c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['index', 'text', 'label'],\n",
            "        num_rows: 35000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['index', 'text', 'label'],\n",
            "        num_rows: 5000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['index', 'text', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "imdb_dataset = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\n",
        "        \"train\": \"train.csv\",\n",
        "        \"validation\": \"val.csv\",\n",
        "        \"test\": \"test.csv\",\n",
        "    },\n",
        ")\n",
        "\n",
        "print(imdb_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b201159-f3fa-4649-8076-eff8bc5535d3",
      "metadata": {
        "id": "8b201159-f3fa-4649-8076-eff8bc5535d3"
      },
      "source": [
        "**Tokenize the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea762ba",
      "metadata": {
        "id": "5ea762ba",
        "outputId": "1b1e7403-2244-4302-88d5-fd31cda427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer input max length: 512\n",
            "Tokenizer vocabulary size: 30522\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(\"Tokenizer input max length:\", tokenizer.model_max_length)\n",
        "print(\"Tokenizer vocabulary size:\", tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8432c15c",
      "metadata": {
        "id": "8432c15c"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb392cf",
      "metadata": {
        "id": "0bb392cf",
        "outputId": "8f4d55c0-ee12-4ebc-fe04-cf149ba11900",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imdb_tokenized = imdb_dataset.map(tokenize_text, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4103c3",
      "metadata": {
        "id": "6d4103c3"
      },
      "outputs": [],
      "source": [
        "del imdb_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ef894c-978f-47f2-9d61-cb6a9f38e745",
      "metadata": {
        "id": "89ef894c-978f-47f2-9d61-cb6a9f38e745"
      },
      "outputs": [],
      "source": [
        "imdb_tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea67091-aeb7-46c1-871f-638ce58d8a0e",
      "metadata": {
        "id": "0ea67091-aeb7-46c1-871f-638ce58d8a0e"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff16488-abe6-48af-9b03-868b457b0ea3",
      "metadata": {
        "id": "7ff16488-abe6-48af-9b03-868b457b0ea3"
      },
      "source": [
        "# 3 DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0807b068-7d8f-4055-a26a-177e07dea4c7",
      "metadata": {
        "id": "0807b068-7d8f-4055-a26a-177e07dea4c7"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, dataset_dict, partition_key=\"train\"):\n",
        "        self.partition = dataset_dict[partition_key]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.partition[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.partition.num_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90cb08f3-ef77-4351-8b19-42d99dd24f98",
      "metadata": {
        "id": "90cb08f3-ef77-4351-8b19-42d99dd24f98"
      },
      "outputs": [],
      "source": [
        "train_dataset = IMDBDataset(imdb_tokenized, partition_key=\"train\")\n",
        "val_dataset = IMDBDataset(imdb_tokenized, partition_key=\"validation\")\n",
        "test_dataset = IMDBDataset(imdb_tokenized, partition_key=\"test\")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=12,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=12,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=12,\n",
        "    num_workers=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78e774ab-45a0-4c48-ad61-a3d0e1927ef4",
      "metadata": {
        "id": "78e774ab-45a0-4c48-ad61-a3d0e1927ef4"
      },
      "source": [
        "# 4 Initializing DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc28ddbe-1a96-4c24-9f5c-40ffdca4a572",
      "metadata": {
        "id": "dc28ddbe-1a96-4c24-9f5c-40ffdca4a572",
        "outputId": "8ebb98a7-dcea-45ce-98ca-b261400768a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def1cf25-0a7d-4bb2-9419-b7a8fe1c1eab",
      "metadata": {
        "id": "def1cf25-0a7d-4bb2-9419-b7a8fe1c1eab"
      },
      "source": [
        "## 5 Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534f7a59-2c86-4895-ad7c-2cdd675b003a",
      "metadata": {
        "id": "534f7a59-2c86-4895-ad7c-2cdd675b003a"
      },
      "source": [
        "**Wrap in LightningModule for Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2c474d",
      "metadata": {
        "id": "9f2c474d"
      },
      "outputs": [],
      "source": [
        "class CustomLightningModule(L.LightningModule):\n",
        "    def __init__(self, model, learning_rate=5e-5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "\n",
        "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        return self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "        self.log(\"train_loss\", outputs[\"loss\"])\n",
        "        return outputs[\"loss\"]  # this is passed to the optimizer for training\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "        self.log(\"val_loss\", outputs[\"loss\"], prog_bar=True)\n",
        "\n",
        "        logits = outputs[\"logits\"]\n",
        "        predicted_labels = torch.argmax(logits, 1)\n",
        "        self.val_acc(predicted_labels, batch[\"label\"])\n",
        "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        outputs = self(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"],\n",
        "                       labels=batch[\"label\"])\n",
        "\n",
        "        logits = outputs[\"logits\"]\n",
        "        predicted_labels = torch.argmax(logits, 1)\n",
        "        self.test_acc(predicted_labels, batch[\"label\"])\n",
        "        self.log(\"accuracy\", self.test_acc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "lightning_model = CustomLightningModule(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6dab813-e1fc-47cd-87a1-5eb8070699c6",
      "metadata": {
        "id": "e6dab813-e1fc-47cd-87a1-5eb8070699c6"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"max\", monitor=\"val_acc\"\n",
        "    )  # save top 1 model\n",
        "]\n",
        "logger = CSVLogger(save_dir=\"logs/\", name=\"my-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "492aa043-02da-459e-a266-091b34254ac6",
      "metadata": {
        "id": "492aa043-02da-459e-a266-091b34254ac6",
        "outputId": "f0fd7765-c08c-415d-c77e-d3318d36eeb1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=3,\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"gpu\",\n",
        "    precision=\"16-mixed\",\n",
        "    devices=[0],\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18bf9b5-d247-405f-86c4-513a52238a14",
      "metadata": {
        "id": "f18bf9b5-d247-405f-86c4-513a52238a14",
        "outputId": "ee8ef8e0-ba44-40cb-bb48-b2f4010f7a6c",
        "colab": {
          "referenced_widgets": [
            "",
            "2964f4eb454849f0ab94c10e80c6e947"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "/home/sebastian/miniforge3/envs/finetuning-blog/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory logs/my-model/version_0/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
            "\n",
            "  | Name     | Type                                | Params\n",
            "-----------------------------------------------------------------\n",
            "0 | model    | DistilBertForSequenceClassification | 67.0 M\n",
            "1 | val_acc  | MulticlassAccuracy                  | 0     \n",
            "2 | test_acc | MulticlassAccuracy                  | 0     \n",
            "-----------------------------------------------------------------\n",
            "67.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "67.0 M    Total params\n",
            "267.820   Total estimated model params size (MB)\n",
            "/home/sebastian/miniforge3/envs/finetuning-blog/lib/python3.9/site-packages/lightning/fabric/loggers/csv_logs.py:188: UserWarning: Experiment logs directory logs/my-model/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2964f4eb454849f0ab94c10e80c6e947",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time elapsed 7.21 min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "trainer.fit(model=lightning_model,\n",
        "            train_dataloaders=train_loader,\n",
        "            val_dataloaders=val_loader)\n",
        "\n",
        "print(f\"Time elapsed {elapsed/60:.2f} min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d795778a-70d2-4b04-96fb-598eccbcd1be",
      "metadata": {
        "id": "d795778a-70d2-4b04-96fb-598eccbcd1be",
        "outputId": "23137853-77b3-4684-c640-6f5475f5bfaa",
        "colab": {
          "referenced_widgets": [
            "8b4da131e12047d1a5405c80a54bd209"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Restoring states from the checkpoint path at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
            "Loaded model weights from the checkpoint at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n",
            "/home/sebastian/miniforge3/envs/finetuning-blog/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b4da131e12047d1a5405c80a54bd209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9919999837875366     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9919999837875366    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'accuracy': 0.9919999837875366}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(lightning_model, dataloaders=train_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ca0af1-106e-4ef7-9793-478d580af827",
      "metadata": {
        "id": "10ca0af1-106e-4ef7-9793-478d580af827",
        "outputId": "5c61ccad-d6e6-4523-d209-52e82996c31d",
        "colab": {
          "referenced_widgets": [
            "1b3d7837d2c149c0ad84347b03c0179e"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Restoring states from the checkpoint path at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
            "Loaded model weights from the checkpoint at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b3d7837d2c149c0ad84347b03c0179e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9251999855041504     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9251999855041504    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'accuracy': 0.9251999855041504}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(lightning_model, dataloaders=val_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb92de4-d483-4627-b9f3-f0bba0cddd9c",
      "metadata": {
        "id": "eeb92de4-d483-4627-b9f3-f0bba0cddd9c",
        "outputId": "db158119-8ea5-4a47-b59c-f982f50e1026",
        "colab": {
          "referenced_widgets": [
            "3a05c398964e469c928cac221541e4fd"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "Restoring states from the checkpoint path at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
            "Loaded model weights from the checkpoint at logs/my-model/version_0/checkpoints/epoch=2-step=8751-v1.ckpt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a05c398964e469c928cac221541e4fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9214000105857849     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9214000105857849    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'accuracy': 0.9214000105857849}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(lightning_model, dataloaders=test_loader, ckpt_path=\"best\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}