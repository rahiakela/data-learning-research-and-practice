{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-transformer-encoder-for-text-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFfv9y65T/nEHuV4kB+yKs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/11-deep-learning-for-text/03_transformer_encoder_for_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer encoder for text classification"
      ],
      "metadata": {
        "id": "bVyFMTsGCS2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factoring outputs into multiple independent spaces, adding residual connections, adding normalization layers—all of these are standard architecture patterns that one would be wise to leverage in any complex model. Together, these bells and whistles form the Transformer encoder—one\n",
        "of two critical parts that make up the Transformer architecture.\n",
        "\n",
        "<img src='https://github.com/rahiakela/data-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/11-deep-learning-for-text/images/2.png?raw=1' width='600'/>\n",
        "\n",
        "The original Transformer architecture consists of two parts: a Transformer encoder that processes the source sequence, and a Transformer decoder that uses the source sequence to generate a translated version.\n",
        "\n",
        "Crucially, the encoder part can be used for text classification—it’s a very generic module that ingests a sequence and learns to turn it into a more useful representation.\n",
        "\n",
        "Let’s implement a Transformer encoder and try it on the movie review sentiment\n",
        "classification task.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwj5k3eqCizD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "8av_x5IrLvDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import os, pathlib, shutil, random"
      ],
      "metadata": {
        "id": "qqyixaVcLwJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start by downloading the dataset from the Stanford page and uncompressing it:"
      ],
      "metadata": {
        "id": "uD5ryFCIMTIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "tar -xf aclImdb_v1.tar.gz\n",
        "\n",
        "# delete unwanted file and subdirectory\n",
        "rm -rf aclImdb/train/unsup\n",
        "rm -rf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "qikpFafHMZRp",
        "outputId": "017712f7-b950-4585-c4fd-a759e72f2d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  16.7M      0  0:00:04  0:00:04 --:--:-- 17.9M\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the content of a few of these text files\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "id": "1P--z8OhM6ub",
        "outputId": "d0335ec0-4b80-4d03-f7a1-8872bb9eb08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let’s download the GloVe word embeddings."
      ],
      "metadata": {
        "id": "u3jPbA4vb8Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "mik4B6eFb9d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the IMDB movie reviews data"
      ],
      "metadata": {
        "id": "KFSx_y3EN9zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, the `train/pos/` directory contains a set of `12,500` text files, each of which\n",
        "contains the text body of a positive-sentiment movie review to be used as training data.\n",
        "The negative-sentiment reviews live in the “neg” directories. \n",
        "\n",
        "In total, there are `25,000`\n",
        "text files for training and another 25,000 for testing.\n",
        "\n",
        "Next, let’s prepare a validation set by setting apart 20% of the training text files in a new directory, `aclImdb/val`:"
      ],
      "metadata": {
        "id": "qlF10e0JN-gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir/\"val\"\n",
        "train_dir = base_dir/\"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir/category)\n",
        "  files = os.listdir(train_dir/category)\n",
        "  # Shuffle the list of training files using a seed, to ensure we get the same validation set every time we run the code\n",
        "  random.Random(1337).shuffle(files)\n",
        "  # Take 20% of the training files to use for validation\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    # Move the files to aclImdb/val/neg and aclImdb/val/pos\n",
        "    shutil.move(train_dir/category/fname, val_dir/category/fname)"
      ],
      "metadata": {
        "id": "YMuEAvy2OQRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember how, we used the `image_dataset_from_directory` utility to\n",
        "create a batched Dataset of images and their labels for a directory structure? You can do the exact same thing for text files using the `text_dataset_from_directory` utility.\n",
        "\n",
        "Let’s create three Dataset objects for training, validation, and testing:"
      ],
      "metadata": {
        "id": "TIAswQR1SUUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size)\n",
        "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)"
      ],
      "metadata": {
        "id": "V6vA9z3ASbd3",
        "outputId": "743d7443-98b0-441b-ac6e-a471f7b4865a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These datasets yield inputs that are TensorFlow `tf.string` tensors and targets that are `int32` tensors encoding the value “0” or “1.”"
      ],
      "metadata": {
        "id": "lMPppHlCTFC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)\n",
        "  print(\"inputs.dtype:\", inputs.dtype)\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ],
      "metadata": {
        "id": "nwyYSSmCTHml",
        "outputId": "74a047b7-be19-4b61-dba9-ff0b153d7dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"Not an altogether bad start for the program -- but what a slap in the face to real law enforcement. The worst part of the series is that it attempts to bill itself as reality fare -- and is anything but. Men and women that dedicate their lives to the enforcement of laws deserve better than this. What is next, medical school in a minute? Charo performing lipo? Charles Grodin assisting on a hip replacement? C'mon...show a little respect. Even the citizens of Muncie are outing the program as staged. Police Academy = High School Gym? Poor editing (how many times can they use the car-to-car shot of the Taco Bell in the background?), cheesy siren effects (the same loop added ad nauseum to every 'call' whether rolling code or not), and last, but not least -- more officer safety issues than you could shake a stick at.<br /><br />If I want to see manufactured police work and wise-ass fake cops, I would watch RENO 911.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparing datasets for sequences"
      ],
      "metadata": {
        "id": "s4JUN4qkQY9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let’s prepare datasets that return integer sequences."
      ],
      "metadata": {
        "id": "h7T3QwANQfoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "\n",
        "# Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "# This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 600 words.\n",
        "text_vectorization = layers.TextVectorization(max_tokens=max_tokens,\n",
        "                                              output_mode=\"int\",\n",
        "                                              output_sequence_length=max_length)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "eKQRxZI9Qmk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer encoder"
      ],
      "metadata": {
        "id": "4S4HkAW2aue8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s implement a Transformer encoder and try it on the movie review sentiment\n",
        "classification task."
      ],
      "metadata": {
        "id": "F020b46bd13J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "  pass"
      ],
      "metadata": {
        "id": "XcmggiT3eAz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  # Fill entry i in the matrix with the word vector for index i. Words not found in the embedding index will be all zeros.\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "TCd6xDx4ee3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we use a Constant initializer to load the pretrained embeddings in an Embedding layer. \n",
        "\n",
        "So as not to disrupt the pretrained representations during training, we freeze\n",
        "the layer via `trainable=False`:"
      ],
      "metadata": {
        "id": "CzZAoDmQgQal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(max_tokens, embedding_dim, \n",
        "                                   embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                                   trainable=False, mask_zero=True)"
      ],
      "metadata": {
        "id": "4k1vNrkEgXRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’re now ready to train a new model—identical to our previous model, but leveraging the `100-dimensional` pretrained GloVe embeddings instead of `128-dimensional` learned embeddings."
      ],
      "metadata": {
        "id": "mHRV6Tfkg1_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One input is a sequence of integers\n",
        "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "# add a bidirectional LSTM\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hxcMnAkug6RX",
        "outputId": "b31d96e4-857a-42fb-85c7-2558ae3026d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               34048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,034,113\n",
            "Trainable params: 34,113\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\", save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1, callbacks=callbacks)\n",
        "\n",
        "model = keras.model.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test accuracy: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "T-ogl15Qg_y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll find that on this particular task, pretrained embeddings aren’t very helpful, because the dataset contains enough samples that it is possible to learn a specialized enough embedding space from scratch. \n",
        "\n",
        "However, leveraging pretrained embeddings can be very helpful when you’re working with a smaller dataset."
      ],
      "metadata": {
        "id": "t9fTBTPehn3v"
      }
    }
  ]
}