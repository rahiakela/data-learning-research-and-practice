{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-transformer-encoder-for-text-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoLHybSSNmL7JH6iLVUgYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/11-deep-learning-for-text/03_transformer_encoder_for_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer encoder for text classification"
      ],
      "metadata": {
        "id": "bVyFMTsGCS2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factoring outputs into multiple independent spaces, adding residual connections, adding normalization layers—all of these are standard architecture patterns that one would be wise to leverage in any complex model. Together, these bells and whistles form the Transformer encoder—one\n",
        "of two critical parts that make up the Transformer architecture.\n",
        "\n",
        "<img src='https://github.com/rahiakela/data-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/11-deep-learning-for-text/images/2.png?raw=1' width='600'/>\n",
        "\n",
        "The original Transformer architecture consists of two parts: a Transformer encoder that processes the source sequence, and a Transformer decoder that uses the source sequence to generate a translated version.\n",
        "\n",
        "Crucially, the encoder part can be used for text classification—it’s a very generic module that ingests a sequence and learns to turn it into a more useful representation.\n",
        "\n",
        "Let’s implement a Transformer encoder and try it on the movie review sentiment\n",
        "classification task.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwj5k3eqCizD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "8av_x5IrLvDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import os, pathlib, shutil, random"
      ],
      "metadata": {
        "id": "qqyixaVcLwJ_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start by downloading the dataset from the Stanford page and uncompressing it:"
      ],
      "metadata": {
        "id": "uD5ryFCIMTIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "tar -xf aclImdb_v1.tar.gz\n",
        "\n",
        "# delete unwanted file and subdirectory\n",
        "rm -rf aclImdb/train/unsup\n",
        "rm -rf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "qikpFafHMZRp",
        "outputId": "cebd44a0-d2df-4478-a775-d4cccb79a58a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  7289k      0  0:00:11  0:00:11 --:--:-- 16.1M\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the content of a few of these text files\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "id": "1P--z8OhM6ub",
        "outputId": "49e10a84-ec4c-4ee2-cc3f-f481351bea72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the IMDB movie reviews data"
      ],
      "metadata": {
        "id": "KFSx_y3EN9zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, the `train/pos/` directory contains a set of `12,500` text files, each of which\n",
        "contains the text body of a positive-sentiment movie review to be used as training data.\n",
        "The negative-sentiment reviews live in the “neg” directories. \n",
        "\n",
        "In total, there are `25,000`\n",
        "text files for training and another 25,000 for testing.\n",
        "\n",
        "Next, let’s prepare a validation set by setting apart 20% of the training text files in a new directory, `aclImdb/val`:"
      ],
      "metadata": {
        "id": "qlF10e0JN-gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir/\"val\"\n",
        "train_dir = base_dir/\"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir/category)\n",
        "  files = os.listdir(train_dir/category)\n",
        "  # Shuffle the list of training files using a seed, to ensure we get the same validation set every time we run the code\n",
        "  random.Random(1337).shuffle(files)\n",
        "  # Take 20% of the training files to use for validation\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    # Move the files to aclImdb/val/neg and aclImdb/val/pos\n",
        "    shutil.move(train_dir/category/fname, val_dir/category/fname)"
      ],
      "metadata": {
        "id": "YMuEAvy2OQRY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember how, we used the `image_dataset_from_directory` utility to\n",
        "create a batched Dataset of images and their labels for a directory structure? You can do the exact same thing for text files using the `text_dataset_from_directory` utility.\n",
        "\n",
        "Let’s create three Dataset objects for training, validation, and testing:"
      ],
      "metadata": {
        "id": "TIAswQR1SUUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size)\n",
        "val_ds = keras.utils.text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
        "test_ds = keras.utils.text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)"
      ],
      "metadata": {
        "id": "V6vA9z3ASbd3",
        "outputId": "27234b65-4cb0-4665-fb25-4ea961919e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These datasets yield inputs that are TensorFlow `tf.string` tensors and targets that are `int32` tensors encoding the value “0” or “1.”"
      ],
      "metadata": {
        "id": "lMPppHlCTFC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)\n",
        "  print(\"inputs.dtype:\", inputs.dtype)\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ],
      "metadata": {
        "id": "nwyYSSmCTHml",
        "outputId": "888d79c7-d2d5-4156-cb31-47cbe5d78a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"To bad for this fine film that it had to be released the same year as Braveheart. Though it is a very different kind of film, the conflict between Scottish commoners and English nobility is front and center here as well. Roughly 400 years had passed between the time Braveheart took place and Rob Roy was set, but some things never seemed to change. Scottland is still run by English nobles, and the highlanders never can seem to catch a break when dealing with them. Rob Roy is handsomely done, but not the grand epic that Braveheart was. There are no large-scale battles, and the conflict here is more between individuals. And helpfully so not all Englishmen are portrayed as evil this time. Rob Roy is simply a film about those with honor, and those who are truly evil.<br /><br />Liam Neeson plays the title character Rob Roy MacGregor. He is the leader of the MacGregor clan and his basic function is to tend to and protect the cattle of the local nobleman of record known as the Marquis of Montrose (John Hurt). Things look pretty rough for the MacGregor clan as winter is approaching, and there seems to be a lack of food for everyone. Rob Roy puts together a plan to borrow 1000 pounds from the Marquis and purchase some cattle of his own. He would then sell them off for a higher price and use the money to improve the general well-being of his community. Sounds fair enough, doesn't it? Problems arise when two cronies of the Marquis steal the money for themselves. One of them, known as Archibald Cunningham, is perhaps the most evil character ever put on film. Played wonderfully by Tim Roth, this man is a penniless would-be noble who has been sent to live with the Marquis by his mother. This man is disgustingly effeminate, rude, heartless, and very dangerous with a sword. He fathers a child with a hand maiden and refuses to own up to the responsibility. He rapes Macgregor's wife and burns him out of his home. This guy is truly as rotten as movie characters come. Along with another crony of the Marquis (Brian Cox) Cunningham steals the money and uses it to settle his own debts. Though it is painfully obvious to most people what happened, the Marquis still holds MacGregor to the debt. This sets up conflict that will take many lives and challenge the strengths of a man simply fighting to hold on to his dignity.<br /><br />Spoilers ahead!!!!!<br /><br />Luckily for the MacGregor's, a Duke who is no friend to the Marquis sets up a final duel between Rob Roy and Cunningham to resolve the conflict one and for all. This sword fight has been considered by many to be one of the best ever filmed. Cunningham is thought by many to be a sure winner with his speed and grace. And for most of the fight, it looks like these attributes will win out. Just when it looks like Rob Roy is finished, he turns the tables in a shockingly grotesque manner. The first time you see what happens, you will probably be as shocked as Cunningham! Rob Roy is beautifully filmed, wonderfully acted, and perfectly paced. The score is quite memorable, too. The casting choices seem to have worked out as Jessica Lange, who might seem to be out of her element, actually turns in one of the strongest performances as Mary MacGregor. The film is violent, but there isn't too much gore. It is a lusty picture full of deviant behavior, however. The nobility are largely played as being amoral and sleazy. The film has no obvious flaws, thus it gets 10 of 10 stars.<br /><br />The Hound.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preparing datasets for sequences"
      ],
      "metadata": {
        "id": "s4JUN4qkQY9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let’s prepare datasets that return integer sequences."
      ],
      "metadata": {
        "id": "h7T3QwANQfoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "\n",
        "# Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "\n",
        "# This is a reasonable choice, since the average review length is 233 words, and only 5% of reviews are longer than 600 words.\n",
        "text_vectorization = layers.TextVectorization(max_tokens=max_tokens,\n",
        "                                              output_mode=\"int\",\n",
        "                                              output_sequence_length=max_length)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "eKQRxZI9Qmk2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer encoder"
      ],
      "metadata": {
        "id": "4S4HkAW2aue8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s implement a Transformer encoder and try it on the movie review sentiment\n",
        "classification task."
      ],
      "metadata": {
        "id": "F020b46bd13J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "  \n",
        "  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.embed_dim = embed_dim    # Size of the input token vectors\n",
        "    self.dense_dim = dense_dim    # Size of the inner dense layer\n",
        "    self.num_heads = num_heads  # Number of attention heads\n",
        "\n",
        "    self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.dense_projection = keras.Sequential([\n",
        "         layers.Dense(dense_dim, activation=\"relu\"),\n",
        "         layers.Dense(embed_dim)                                     \n",
        "    ])\n",
        "\n",
        "    self.layernorm_1 = layers.LayerNormalization()\n",
        "    self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    # The mask that will be generated by the Embedding layer will be 2D, but the attention layer expects to be 3D or 4D, so we expand its rank.\n",
        "    if mask is not None:\n",
        "      mask = mask[:, tf.newaxis, :]\n",
        "    attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "    projection_input = self.layernorm_1(inputs + attention_output)\n",
        "    projection_output = self.dense_projection(projection_input)\n",
        "    return self.layernorm_2(projection_input + projection_output)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "        \"embed_dim\": self.embed_dim,\n",
        "        \"num_heads\": self.num_heads,\n",
        "        \"dense_dim\": self.dense_dim\n",
        "    })\n",
        "    return config"
      ],
      "metadata": {
        "id": "XcmggiT3eAz0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because `BatchNormalization` doesn’t work well for sequence data. Instead, we’re using the layer, `LayerNormalization` which normalizes each sequence independently from other sequences in the batch.\n",
        "\n",
        "```python\n",
        "def layer_normalization(batch_of_sequences):\n",
        "  # Input shape: (batch_size, sequence_length, embedding_dim)\n",
        "  # To compute mean and variance, we only pool data over the last axis (axis -1).\n",
        "  mean = np.mean(batch_of_sequences, keepdims=True, axis=-1)\n",
        "  variance = np.var(batch_of_sequences, keepdims=True, axis=-1)\n",
        "  return (batch_of_sequences - mean) / variance\n",
        "```\n",
        "\n",
        "Compare to BatchNormalization (during training):\n",
        "\n",
        "```python\n",
        "def batch_normalization(batch_of_images):\n",
        "  # Input shape: (batch_size, height, width, channels)\n",
        "  # Pool data over the batch axis (axis 0), which creates interactions between samples in a batch.\n",
        "  mean = np.mean(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
        "  variance = np.var(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
        "  return (batch_of_images - mean) / variance\n",
        "```\n",
        "\n",
        "While collects information from many samples to obtain accu\n",
        "`BatchNormalization` rate statistics for the feature means and variances,\n",
        "pools data `LayerNormalization` within each sequence separately, which is more appropriate for sequence data.\n",
        "\n",
        "Now that we’ve implemented our TransformerEncoder, we can use it to assemble a\n",
        "text-classification model.\n",
        "\n"
      ],
      "metadata": {
        "id": "UCu7BVXoDP5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32"
      ],
      "metadata": {
        "id": "b_S16wGHE8co"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One input is a sequence of integers\n",
        "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "# Since TransformerEncoder returns full sequences, we need to reduce each sequence to a single vector for classification via a global pooling layer.\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hxcMnAkug6RX",
        "outputId": "507a2d1d-48da-4032-f900-c9f7c91f84f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, None, 256)        543776    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,664,033\n",
            "Trainable params: 5,664,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\", save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "T-ogl15Qg_y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide the custom TransformerEncoder class to the model-loading process.\n",
        "model = tf.keras.models.load_model(\"transformer_encoder.keras\", custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
        "print(f\"Test accuracy: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "Bwx9nh6AWxJv",
        "outputId": "8d85a26b-cef4-49d1-a58b-76b6bb023a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 636s 812ms/step - loss: 0.2987 - accuracy: 0.8764\n",
            "Test accuracy: 0.876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Self-attention` is a set-processing mechanism, focused on the relationships between pairs of sequence elements—it’s blind to whether these elements occur at the beginning, at the end, or in the middle of a sequence.\n",
        "\n",
        "`Transformer` was a hybrid approach that is technically order-agnostic, but that manually injects order information in the representations it processes. \n",
        "\n",
        "This is the missing ingredient! It’s called `positional encoding`."
      ],
      "metadata": {
        "id": "t9fTBTPehn3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Re-inject order information using positional encoding"
      ],
      "metadata": {
        "id": "yg7DLtm7Ippv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LNH2w2K0I6-O"
      }
    }
  ]
}