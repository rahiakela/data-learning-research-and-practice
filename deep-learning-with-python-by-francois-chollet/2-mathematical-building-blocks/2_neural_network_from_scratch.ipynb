{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-neural-network-from-scratch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOq70qEKe+vfGpCv7zJdx7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/2-mathematical-building-blocks/2_neural_network_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPJWYkEzn0-x"
      },
      "source": [
        "##Neural Network from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jge4t8T3oHfA"
      },
      "source": [
        "You should now have a general understanding\n",
        "of what’s going on behind the scenes in a neural network. What was a magical\n",
        "black box at the start, has turned into a clearer picture.\n",
        "\n",
        "<img src='images/2.png?raw=1' width='800'/>\n",
        "\n",
        "- the model, composed of layers that are chained together, maps the input data to predictions. \n",
        "- The loss function then compares these predictions\n",
        "to the targets, producing a loss value: a measure of how well the model’s predictions match what was expected. \n",
        "- The optimizer uses this loss value to update the model’s weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlW4h5vdpa3N"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IXiaYkrCla"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAud-_puuj1p"
      },
      "source": [
        "##NN using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSL_MlYwu3VQ"
      },
      "source": [
        "Now you understand that the input images are stored in NumPy tensors, which are\n",
        "here formatted as float32 tensors of shape (60000, 784) (training data) and (10000,\n",
        "784) (test data) respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZL4iPADuq_W",
        "outputId": "02415869-d5fc-4236-8ff1-88ab14802065"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg5JqcZsu4R2"
      },
      "source": [
        "Now you understand that this model consists of a chain of two Dense layers, that each\n",
        "layer applies a few simple tensor operations to the input data, and that these operations\n",
        "involve weight tensors. Weight tensors, which are attributes of the layers, are\n",
        "where the knowledge of the model persists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rlG8gpgu71Q"
      },
      "source": [
        "model = keras.Sequential([\n",
        "   layers.Dense(512, activation=\"relu\"),\n",
        "   layers.Dense(10, activation=\"softmax\")                      \n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdutgLbxvUgH"
      },
      "source": [
        "Now you understand that sparse_categorical_crossentropy is the loss function\n",
        "that’s used as a feedback signal for learning the weight tensors, and which the training\n",
        "phase will attempt to minimize. \n",
        "\n",
        "You also know that this reduction of the loss\n",
        "happens via mini-batch stochastic gradient descent. The exact rules governing a specific\n",
        "use of gradient descent are defined by the rmsprop optimizer passed as the first\n",
        "argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZctRRGBvc8q"
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weUDRAeMvtn7"
      },
      "source": [
        "Now you understand what happens when you call fit: the model will start to iterate\n",
        "on the training data in mini-batches of 128 samples, 5 times over (each iteration over\n",
        "all the training data is called an epoch).\n",
        "\n",
        "For each batch, the model will compute the\n",
        "gradient of the loss with regard to the weights (using the Backpropagation algorithm,\n",
        "which derives from the chain rule in calculus) and move the weights in the direction\n",
        "that will reduce the value of the loss for this batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-tSBvyDvoLA",
        "outputId": "2eb9e8da-3933-427b-fb9e-7e51dd2a0a46"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2598 - accuracy: 0.9248\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1038 - accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0680 - accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0497 - accuracy: 0.9847\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0377 - accuracy: 0.9884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f91347913d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTntBbZwv8_Z"
      },
      "source": [
        "After these 5 epochs, the model will have performed 2,345 gradient updates (469\n",
        "per epoch), and the loss of the model will be sufficiently low that the model will be\n",
        "capable of classifying handwritten digits with high accuracy.\n",
        "\n",
        "At this point, you already know most of what there is to know about neural networks.\n",
        "Let’s prove it by reimplementing a simplified version of that first example\n",
        "“from scratch” in TensorFlow, step by step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBUzy-DIwEJX"
      },
      "source": [
        "##NN from scratch in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEdUocYXwGYh"
      },
      "source": [
        ""
      ]
    }
  ]
}