{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-keras-training-and-evaluation-fundamentals.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIDFPHLOITuRASzbk2izzB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/7-deep-dive-into-keras/02_keras_training_and_evaluation_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Keras model fundamentals"
      ],
      "metadata": {
        "id": "luPerGH_0G31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three APIs for building models in Keras:\n",
        "\n",
        "* The Sequential model, the most approachable API—it’s basically a Python list. As such, it’s limited to simple stacks of layers.\n",
        "* The Functional API, which focuses on graph-like model architectures. It represents\n",
        "a nice mid-point between usability and flexibility, and as such, it’s the\n",
        "most commonly used model-building API.\n",
        "* Model subclassing, a low-level option where you write everything yourself from\n",
        "scratch. This is ideal if you want full control over every little thing. However, you\n",
        "won’t get access to many built-in Keras features, and you will be more at risk of\n",
        "making mistakes.\n",
        "\n",
        "<img src='https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/7-deep-dive-into-keras/images/1.png?raw=1' width='600'/>"
      ],
      "metadata": {
        "id": "TdZ1Nkni0Pga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "USIIvxaF9LXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "t_xajM529MdN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using built-in training and evaluation loops"
      ],
      "metadata": {
        "id": "WyN_Mwlm9SSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The principle of progressive disclosure of complexity—access to a spectrum of workflows\n",
        "that go from dead easy to arbitrarily flexible, one step at a time—also applies to\n",
        "model training. Keras provides you with different workflows for training models. \n",
        "\n",
        "They\n",
        "can be as simple as calling `fit()` on your data, or as advanced as writing a new training\n",
        "algorithm from scratch.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MIA3a99S8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_model():\n",
        "  inputs = keras.Input(shape=(28 * 28, ))\n",
        "  features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "  features = layers.Dropout(0.5)(features)\n",
        "  outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Yl4SfVWC-lQ0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your data, reserving\n",
        "some for validation."
      ],
      "metadata": {
        "id": "lsxXM2oI-7QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]"
      ],
      "metadata": {
        "id": "zeHqVyQN_AhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca31edb8-b883-4e50-cbcc-657aa5142f1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model, optionally providing validation data to monitor performance on unseen data\n",
        "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "eEDNr-Wu_WNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae46c90-a0ff-4f94-ba73-36db6aa7baa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.2942 - accuracy: 0.9118 - val_loss: 0.1474 - val_accuracy: 0.9578\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 0.1617 - accuracy: 0.9551 - val_loss: 0.1218 - val_accuracy: 0.9678\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1387 - accuracy: 0.9622 - val_loss: 0.1125 - val_accuracy: 0.9716\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2db7386c50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss and metrics on new data\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "QkxZ0AFk_tro",
        "outputId": "957df352-f4c1-4044-fa29-f7c33f2c410d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1009 - accuracy: 0.9725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute classification probabilities on new data\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "ob6Gx9h0AF16"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple of ways you can customize this simple workflow:\n",
        "\n",
        "* Provide your own custom metrics.\n",
        "* Pass `callbacks` to the `fit()` method to schedule actions to be taken at specific points during training.\n"
      ],
      "metadata": {
        "id": "nhjBPi8XAL4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Writing your own metrics"
      ],
      "metadata": {
        "id": "h8MWD0tkAvrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics are key to measuring the performance of your model—in particular, to measuring\n",
        "the difference between its performance on the training data and its performance\n",
        "on the test data.\n",
        "\n",
        "A Keras metric is a subclass of the `keras.metrics.Metric` class. Like layers, a metric\n",
        "has an internal state stored in TensorFlow variables. Unlike layers, these variables\n",
        "aren’t updated via backpropagation, so you have to write the state-update logic yourself,\n",
        "which happens in the `update_state()` method.\n",
        "\n",
        "For example, here’s a simple custom metric that measures the root mean squared\n",
        "error (RMSE)."
      ],
      "metadata": {
        "id": "2BmgTQUrJW9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name=\"rmse\", **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "\n",
        "    # Define the state variables in the constructor.\n",
        "    self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "    self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    # To match our MNIST model, we expect categorical predictions and integer labels.\n",
        "    y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
        "    mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "    self.mse_sum.assign_add(mse)\n",
        "    num_samples = tf.shape(y_pred)[0]\n",
        "    self.total_samples.assign_add(num_samples)\n",
        "\n",
        "  def result(self):\n",
        "    return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.mse_sum.assign(0)\n",
        "    self.total_samples.assign(0)"
      ],
      "metadata": {
        "id": "6x6fmKh1JU-f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Custom metrics can be used just like built-in ones. Let’s test-drive our own metric:"
      ],
      "metadata": {
        "id": "LJ951pStxXT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "\n",
        "# train the model, optionally providing validation data to monitor performance on unseen data\n",
        "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FtKi4uGxZtZ",
        "outputId": "45c33b9e-aa64-4275-d0ce-0e9a32d8778d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2975 - accuracy: 0.9120 - rmse: 7.1765 - val_loss: 0.1539 - val_accuracy: 0.9562 - val_rmse: 7.3494\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1680 - accuracy: 0.9520 - rmse: 7.3519 - val_loss: 0.1348 - val_accuracy: 0.9636 - val_rmse: 7.4066\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1397 - accuracy: 0.9621 - rmse: 7.3886 - val_loss: 0.1178 - val_accuracy: 0.9708 - val_rmse: 7.4230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2db4944250>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss and metrics on new data\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THoc3w3dxtDz",
        "outputId": "c1d95f53-5851-4353-93e5-f9d111df0c1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9746 - rmse: 7.4363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute classification probabilities on new data\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "IHUX2XdgydGQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using callbacks"
      ],
      "metadata": {
        "id": "2LZ856EkBaDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Keras `callbacks` API will help you\n",
        "transform your call to `model.fit()` from a paper airplane into a smart, autonomous\n",
        "drone that can self-introspect and dynamically take action.\n",
        "\n",
        "A callback is an object (a class instance implementing specific methods) that is\n",
        "passed to the model in the call to `fit()` and that is called by the model at various\n",
        "points during training. It has access to all the available data about the state of the\n",
        "model and its performance, and it can take action: interrupt training, save a model,\n",
        "load a different weight set, or otherwise alter the state of the model.\n",
        "\n",
        "Here are some examples of ways you can use callbacks:\n",
        "\n",
        "* **Model checkpointing**—Saving the current state of the model at different points\n",
        "during training.\n",
        "* **Early stopping**—Interrupting training when the validation loss is no longer\n",
        "improving (and of course, saving the best model obtained during training).\n",
        "* **Dynamically adjusting the value of certain parameters during training**—Such as the\n",
        "learning rate of the optimizer.\n",
        "* **Logging training and validation metrics during training, or visualizing the representations\n",
        "learned by the model as they’re updated**—The `fit()` progress bar that you’re\n",
        "familiar with is in fact a callback!\n",
        "\n"
      ],
      "metadata": {
        "id": "lb5R-ufpBfks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EarlyStopping and ModelCheckpoint"
      ],
      "metadata": {
        "id": "FhJE-Ww-uu-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The EarlyStopping callback interrupts training once a target metric being monitored\n",
        "has stopped improving for a fixed number of epochs. \n",
        "\n",
        "For instance, this callback\n",
        "allows you to interrupt training as soon as you start overfitting, thus avoiding having to\n",
        "retrain your model for a smaller number of epochs. This callback is typically used in combination with ModelCheckpoint, which lets you continually save the model during\n",
        "training (and, optionally, save only the current best model so far: the version of the\n",
        "model that achieved the best performance at the end of an epoch)."
      ],
      "metadata": {
        "id": "j3hfvyutuxWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_list = [\n",
        "   # Monitors the model’s validation accuracy and Interrupts training when accuracy has stopped improving for two epochs     \n",
        "   keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2),\n",
        "   keras.callbacks.ModelCheckpoint(filepath=\"checkpoint_path.keras\", monitor=\"val_loss\", save_best_only=True)          \n",
        "]"
      ],
      "metadata": {
        "id": "BlPEtMaXvxD6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "\n",
        "# train the model, optionally providing validation data to monitor performance on unseen data\n",
        "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels), callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "1EWQl1zB8Wrp",
        "outputId": "3bfc7041-887a-4048-ebf9-9050f09cef39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2928 - accuracy: 0.9141 - rmse: 7.1823 - val_loss: 0.1511 - val_accuracy: 0.9573 - val_rmse: 7.3665\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1668 - accuracy: 0.9541 - rmse: 7.3548 - val_loss: 0.1272 - val_accuracy: 0.9652 - val_rmse: 7.4079\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.1399 - accuracy: 0.9626 - rmse: 7.3881 - val_loss: 0.1180 - val_accuracy: 0.9693 - val_rmse: 7.4214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2db45ac990>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reload the model you’ve saved, just use."
      ],
      "metadata": {
        "id": "PSXMnilowtNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\")"
      ],
      "metadata": {
        "id": "RobjRdAZwuR_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss and metrics on new data\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "NFd_QXkNw3F_",
        "outputId": "96a54341-8bea-4e53-ac03-e85bca33a496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9723 - rmse: 5.2285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute classification probabilities on new data\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "G85G7GHzw3fU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom callback"
      ],
      "metadata": {
        "id": "UfXbpJDaxHCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qn-V58GwxJn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion"
      ],
      "metadata": {
        "id": "ZRD1kfxL9xIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the Functional API provides you with a pretty good trade-off between\n",
        "ease of use and flexibility. It also gives you direct access to layer connectivity, which is\n",
        "very powerful for use cases such as model plotting or feature extraction. \n",
        "\n",
        "If you can use\n",
        "the Functional API—that is, if your model can be expressed as a directed acyclic graph\n",
        "of layers—I recommend using it over model subclassing.\n",
        "\n",
        "In general, using Functional models\n",
        "that include subclassed layers provides the best of both worlds: high development flexibility\n",
        "while retaining the advantages of the Functional API.\n",
        "\n"
      ],
      "metadata": {
        "id": "F2c73QKJ90I7"
      }
    }
  ]
}