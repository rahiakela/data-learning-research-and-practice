{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-keras-training-and-evaluation-fundamentals.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9aTjeKzccd+BBK5hKVTKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/7-deep-dive-into-keras/02_keras_training_and_evaluation_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Keras model fundamentals"
      ],
      "metadata": {
        "id": "luPerGH_0G31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three APIs for building models in Keras:\n",
        "\n",
        "* The Sequential model, the most approachable API—it’s basically a Python list. As such, it’s limited to simple stacks of layers.\n",
        "* The Functional API, which focuses on graph-like model architectures. It represents\n",
        "a nice mid-point between usability and flexibility, and as such, it’s the\n",
        "most commonly used model-building API.\n",
        "* Model subclassing, a low-level option where you write everything yourself from\n",
        "scratch. This is ideal if you want full control over every little thing. However, you\n",
        "won’t get access to many built-in Keras features, and you will be more at risk of\n",
        "making mistakes.\n",
        "\n",
        "<img src='https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-python-by-francois-chollet/7-deep-dive-into-keras/images/1.png?raw=1' width='600'/>"
      ],
      "metadata": {
        "id": "TdZ1Nkni0Pga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "USIIvxaF9LXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "t_xajM529MdN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using built-in training and evaluation loops"
      ],
      "metadata": {
        "id": "WyN_Mwlm9SSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The principle of progressive disclosure of complexity—access to a spectrum of workflows\n",
        "that go from dead easy to arbitrarily flexible, one step at a time—also applies to\n",
        "model training. Keras provides you with different workflows for training models. \n",
        "\n",
        "They\n",
        "can be as simple as calling `fit()` on your data, or as advanced as writing a new training\n",
        "algorithm from scratch.\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MIA3a99S8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mnist_model():\n",
        "  inputs = keras.Input(shape=(28 * 28, ))\n",
        "  features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "  features = layers.Dropout(0.5)(features)\n",
        "  outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Yl4SfVWC-lQ0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your data, reserving\n",
        "some for validation."
      ],
      "metadata": {
        "id": "lsxXM2oI-7QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]"
      ],
      "metadata": {
        "id": "zeHqVyQN_AhE",
        "outputId": "9f94b026-c133-4dda-94a7-7e7cf3aa614d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# train the model, optionally providing validation data to monitor performance on unseen data\n",
        "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "eEDNr-Wu_WNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2554ea18-2c85-40df-fd9f-70ee0d395c84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2968 - accuracy: 0.9121 - val_loss: 0.1424 - val_accuracy: 0.9588\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1643 - accuracy: 0.9538 - val_loss: 0.1219 - val_accuracy: 0.9663\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1394 - accuracy: 0.9623 - val_loss: 0.1165 - val_accuracy: 0.9693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9f7e32a90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss and metrics on new data\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "QkxZ0AFk_tro",
        "outputId": "15646b7f-05c6-4c89-cdb6-de58accfd659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute classification probabilities on new data\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "ob6Gx9h0AF16"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a couple of ways you can customize this simple workflow:\n",
        "\n",
        "* Provide your own custom metrics.\n",
        "* Pass `callbacks` to the `fit()` method to schedule actions to be taken at specific points during training.\n"
      ],
      "metadata": {
        "id": "nhjBPi8XAL4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Writing your own metrics"
      ],
      "metadata": {
        "id": "h8MWD0tkAvrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics are key to measuring the performance of your model—in particular, to measuring\n",
        "the difference between its performance on the training data and its performance\n",
        "on the test data.\n",
        "\n",
        "A Keras metric is a subclass of the `keras.metrics.Metric` class. Like layers, a metric\n",
        "has an internal state stored in TensorFlow variables. Unlike layers, these variables\n",
        "aren’t updated via backpropagation, so you have to write the state-update logic yourself,\n",
        "which happens in the `update_state()` method.\n",
        "\n",
        "For example, here’s a simple custom metric that measures the root mean squared\n",
        "error (RMSE)."
      ],
      "metadata": {
        "id": "2BmgTQUrJW9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name=\"rmse\", **kwargs):\n",
        "    super().__init__(name=name, **kwargs)\n",
        "\n",
        "    # Define the state variables in the constructor.\n",
        "    self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "    self.total_samples = self.add_weight(name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    # To match our MNIST model, we expect categorical predictions and integer labels.\n",
        "    y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
        "    mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "    self.mse_sum.assign_add(mse)\n",
        "    num_samples = tf.shape(y_pred)[0]\n",
        "    self.total_samples.assign_add(num_samples)\n",
        "\n",
        "  def result(self):\n",
        "    return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.mse_sum.assign(0)\n",
        "    self.total_samples.assign(0)"
      ],
      "metadata": {
        "id": "6x6fmKh1JU-f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Custom metrics can be used just like built-in ones. Let’s test-drive our own metric:"
      ],
      "metadata": {
        "id": "LJ951pStxXT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "# Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "\n",
        "# train the model, optionally providing validation data to monitor performance on unseen data\n",
        "model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "5FtKi4uGxZtZ",
        "outputId": "46440c80-cd58-4cf7-cbbd-ccd43697f24c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2943 - accuracy: 0.9125 - rmse: 7.1820 - val_loss: 0.1448 - val_accuracy: 0.9597 - val_rmse: 7.3612\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1661 - accuracy: 0.9535 - rmse: 7.3533 - val_loss: 0.1189 - val_accuracy: 0.9672 - val_rmse: 7.4027\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1386 - accuracy: 0.9632 - rmse: 7.3914 - val_loss: 0.1103 - val_accuracy: 0.9720 - val_rmse: 7.4186\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9f221ba10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the loss and metrics on new data\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "THoc3w3dxtDz",
        "outputId": "45b52e0c-d267-48c9-a400-02bd3435e5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9730 - rmse: 7.4314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute classification probabilities on new data\n",
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "IHUX2XdgydGQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using callbacks"
      ],
      "metadata": {
        "id": "2LZ856EkBaDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lb5R-ufpBfks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1EWQl1zB8Wrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This inputs object holds information about the shape and dtype of the data that the\n",
        "model will process:"
      ],
      "metadata": {
        "id": "kpRgefBCB-eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "id": "iLGXl_PGB-_t",
        "outputId": "929d8f82-65cc-43ce-b8d6-935a52615c1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.dtype"
      ],
      "metadata": {
        "id": "y9jbzGXqIHMF",
        "outputId": "b4e9036e-4469-4013-8f37-c09f69e32e4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call such an object a symbolic tensor. It doesn’t contain any actual data, but it\n",
        "encodes the specifications of the actual tensors of data that the model will see when\n",
        "you use it. It stands for future tensors of data.\n",
        "\n",
        "All Keras layers can be called both on real tensors of data and on these symbolic tensors."
      ],
      "metadata": {
        "id": "DNawZBJXIQ2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "id": "ldN80GiEIYy6",
        "outputId": "6e86962c-c8da-4b36-c72a-0ed8423ed850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.dtype"
      ],
      "metadata": {
        "id": "5SzMp1moIcKu",
        "outputId": "6ec811f6-ff4d-47c7-d907-bbbc3da50feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s the summary of our model:"
      ],
      "metadata": {
        "id": "dbd_iHx4Il5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "63EnCSccImR5",
        "outputId": "a89ecd75-1587-4795-b100-01d442003179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_input (InputLayer)       [(None, 3)]               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion"
      ],
      "metadata": {
        "id": "ZRD1kfxL9xIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the Functional API provides you with a pretty good trade-off between\n",
        "ease of use and flexibility. It also gives you direct access to layer connectivity, which is\n",
        "very powerful for use cases such as model plotting or feature extraction. \n",
        "\n",
        "If you can use\n",
        "the Functional API—that is, if your model can be expressed as a directed acyclic graph\n",
        "of layers—I recommend using it over model subclassing.\n",
        "\n",
        "In general, using Functional models\n",
        "that include subclassed layers provides the best of both worlds: high development flexibility\n",
        "while retaining the advantages of the Functional API.\n",
        "\n"
      ],
      "metadata": {
        "id": "F2c73QKJ90I7"
      }
    }
  ]
}