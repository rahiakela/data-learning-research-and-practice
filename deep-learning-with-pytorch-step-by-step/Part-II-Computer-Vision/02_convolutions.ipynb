{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOE26chANmqx/JwZBFEp8PY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/02_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolutions"
      ],
      "metadata": {
        "id": "8A9MVvQ5_T5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolution is \"a mathematical operation on two functions (`f` and `g`) that produces a third function (`f * g`) expressing how the shape of one is modified by the other.\"\n",
        "\n",
        "In image processing, a convolution matrix is also called a kernel or filter. \n",
        "\n",
        "Typical image processing operations—like blurring, sharpening, edge detection, and more, are\n",
        "accomplished by performing a convolution between a kernel and an image."
      ],
      "metadata": {
        "id": "7K_rxSuE_Uhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "BebAYVWo_VlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "id": "iiQ_qcSp_Uq6",
        "outputId": "5a231acc-1773-4c25-fb5f-272224eddee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter5()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter5 import *"
      ],
      "metadata": {
        "id": "6EwSrmrQ_cxf",
        "outputId": "4c459d41-33fd-4bd4-b4b3-e1cb98477543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Compose, Normalize\n",
        "\n",
        "from data_generation.image_classification import generate_dataset\n",
        "from helpers import index_splitter, make_balanced_sampler\n",
        "from stepbystep.v1 import StepByStep"
      ],
      "metadata": {
        "id": "ZNIlTCW9_gBk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter / Kernel"
      ],
      "metadata": {
        "id": "Rsnr8thUATxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the filters are\n",
        "small square matrices. The convolution itself is performed by applying the filter on\n",
        "the image repeatedly. \n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv1.png?raw=1)\n",
        "\n",
        "That’s the region to which the filter is being applied and is called the\n",
        "receptive field, drawing an analogy to the way human vision works.\n",
        "\n",
        "Let’s try a concrete example to make it more clear."
      ],
      "metadata": {
        "id": "xHjtaGl4ETM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single = np.array([\n",
        "  [ # batch dim\n",
        "      [ # channel dim\n",
        "          [5, 0, 8, 7, 8, 1], # height and width dim\n",
        "          [1, 9, 5, 0, 7, 7],\n",
        "          [6, 0, 2, 4, 6, 6],\n",
        "          [9, 7, 6, 6, 8, 4],\n",
        "          [8, 3, 8, 5, 1, 3],\n",
        "          [7, 2, 7, 0, 1, 0]\n",
        "      ]\n",
        "  ]\n",
        "])\n",
        "single.shape"
      ],
      "metadata": {
        "id": "jPyifdt-AUSX",
        "outputId": "7a3be48a-562d-4f31-f74f-296aae5947b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "identity = np.array([\n",
        "    [\n",
        "        [\n",
        "            [0, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]\n",
        "    ]\n",
        "])\n",
        "identity.shape"
      ],
      "metadata": {
        "id": "oiO3F9UGFO9G",
        "outputId": "93f13015-6731-4adc-a14d-e4d8b635ad3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolving"
      ],
      "metadata": {
        "id": "KkW-hK_CFhg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convulution performs an element-wise multiplication between the\n",
        "two, region and filter, and adds everything up.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv2.png?raw=1)"
      ],
      "metadata": {
        "id": "EUxO8zMfFkXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region = single[:, :, 0:3, 0:3]\n",
        "filtered_region = region * identity\n",
        "total = filtered_region.sum()\n",
        "total"
      ],
      "metadata": {
        "id": "CVEwetTtF1H2",
        "outputId": "4f2477e1-951f-4bb6-a8eb-175300696f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing a convolution produces an image with a\n",
        "reduced size.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv3.png?raw=1)"
      ],
      "metadata": {
        "id": "X69C4K0gGbWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Moving Around"
      ],
      "metadata": {
        "id": "2CYbWbW-HxNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we move the region one step to the right; that is, we change the receptive\n",
        "field and apply the filter again.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/stride1.png?raw=1)\n",
        "\n",
        "In code, it means we’re changing the slice of the input image:"
      ],
      "metadata": {
        "id": "B-uOhu84IWU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_region = single[:, :, 0:3, (0+1):(3+1)]"
      ],
      "metadata": {
        "id": "UN7eF6XnGotK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But the operation remains the same: First, an element-wise multiplication, and\n",
        "then adding up the elements of the resulting matrix.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv5.png?raw=1)"
      ],
      "metadata": {
        "id": "p801DPVnJLI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_filtered_region = new_region * identity\n",
        "new_total = new_filtered_region.sum()\n",
        "new_total"
      ],
      "metadata": {
        "id": "tu1Xmj6HJOyX",
        "outputId": "c2f7c08a-9150-427a-c261-f3b1f16b09fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! We have a second pixel value to add to our resulting image.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv6.png?raw=1)\n",
        "\n",
        "We can keep moving the gray region to the right until we can’t move it anymore.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv7.png?raw=1)\n",
        "\n",
        "The fourth step to the right will actually place the region partially outside the\n",
        "input image."
      ],
      "metadata": {
        "id": "N_zfUbc4KUzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_horizontal_region = single[:, :, 0:3, (0+4):(3+4)]"
      ],
      "metadata": {
        "id": "g8r2NNINKeUI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selected region does not match the shape of the filter anymore. \n",
        "\n",
        "So, if we try to\n",
        "perform the element-wise multiplication, it fails:"
      ],
      "metadata": {
        "id": "XP8Uby8_K4nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  last_horizontal_region * identity\n",
        "except Exception as exp:\n",
        "  print(exp)"
      ],
      "metadata": {
        "id": "zcWMNoMCK5w_",
        "outputId": "978051b5-beda-4b75-a81a-4042e81633d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "operands could not be broadcast together with shapes (1,1,3,2) (1,1,3,3) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Shape"
      ],
      "metadata": {
        "id": "jBkcwd9cLRHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lhKlTPhcLR-m"
      }
    }
  ]
}