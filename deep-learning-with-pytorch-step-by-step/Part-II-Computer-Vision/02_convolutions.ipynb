{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFPSIo6MDd27ub2vUnsBpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/02_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolutions"
      ],
      "metadata": {
        "id": "8A9MVvQ5_T5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A convolution is \"a mathematical operation on two functions (`f` and `g`) that produces a third function (`f * g`) expressing how the shape of one is modified by the other.\"\n",
        "\n",
        "In image processing, a convolution matrix is also called a kernel or filter. \n",
        "\n",
        "Typical image processing operations—like blurring, sharpening, edge detection, and more, are\n",
        "accomplished by performing a convolution between a kernel and an image."
      ],
      "metadata": {
        "id": "7K_rxSuE_Uhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "BebAYVWo_VlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "id": "iiQ_qcSp_Uq6",
        "outputId": "99267e7a-224c-4a69-ee88-28b2a461d29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter5()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter5 import *"
      ],
      "metadata": {
        "id": "6EwSrmrQ_cxf",
        "outputId": "a8f92f49-a50a-4b02-cd86-333fd4f6006a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Compose, Normalize\n",
        "\n",
        "from data_generation.image_classification import generate_dataset\n",
        "from helpers import index_splitter, make_balanced_sampler\n",
        "from stepbystep.v1 import StepByStep"
      ],
      "metadata": {
        "id": "ZNIlTCW9_gBk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter / Kernel"
      ],
      "metadata": {
        "id": "Rsnr8thUATxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the filters are\n",
        "small square matrices. The convolution itself is performed by applying the filter on\n",
        "the image repeatedly. \n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv1.png?raw=1)\n",
        "\n",
        "That’s the region to which the filter is being applied and is called the\n",
        "receptive field, drawing an analogy to the way human vision works.\n",
        "\n",
        "Let’s try a concrete example to make it more clear."
      ],
      "metadata": {
        "id": "xHjtaGl4ETM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single = np.array([\n",
        "  [ # batch dim\n",
        "      [ # channel dim\n",
        "          [5, 0, 8, 7, 8, 1], # height and width dim\n",
        "          [1, 9, 5, 0, 7, 7],\n",
        "          [6, 0, 2, 4, 6, 6],\n",
        "          [9, 7, 6, 6, 8, 4],\n",
        "          [8, 3, 8, 5, 1, 3],\n",
        "          [7, 2, 7, 0, 1, 0]\n",
        "      ]\n",
        "  ]\n",
        "])\n",
        "single.shape"
      ],
      "metadata": {
        "id": "jPyifdt-AUSX",
        "outputId": "33208a59-53a5-4946-dd20-fd6ae20b2f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "identity = np.array([\n",
        "    [\n",
        "        [\n",
        "            [0, 0, 0],\n",
        "            [0, 1, 0],\n",
        "            [0, 0, 0]\n",
        "        ]\n",
        "    ]\n",
        "])\n",
        "identity.shape"
      ],
      "metadata": {
        "id": "oiO3F9UGFO9G",
        "outputId": "0d4035d6-c921-4cf0-f43f-ab1e643afec0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolving"
      ],
      "metadata": {
        "id": "KkW-hK_CFhg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convulution performs an element-wise multiplication between the\n",
        "two, region and filter, and adds everything up.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv2.png?raw=1)"
      ],
      "metadata": {
        "id": "EUxO8zMfFkXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region = single[:, :, 0:3, 0:3]\n",
        "filtered_region = region * identity\n",
        "total = filtered_region.sum()\n",
        "total"
      ],
      "metadata": {
        "id": "CVEwetTtF1H2",
        "outputId": "3c0c7d4d-4b86-4c2f-9a85-51b3cb3292c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing a convolution produces an image with a\n",
        "reduced size.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv3.png?raw=1)"
      ],
      "metadata": {
        "id": "X69C4K0gGbWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving Around"
      ],
      "metadata": {
        "id": "2CYbWbW-HxNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we move the region one step to the right; that is, we change the receptive\n",
        "field and apply the filter again.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/stride1.png?raw=1)\n",
        "\n",
        "In code, it means we’re changing the slice of the input image:"
      ],
      "metadata": {
        "id": "B-uOhu84IWU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_region = single[:, :, 0:3, (0+1):(3+1)]"
      ],
      "metadata": {
        "id": "UN7eF6XnGotK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But the operation remains the same: First, an element-wise multiplication, and\n",
        "then adding up the elements of the resulting matrix.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv5.png?raw=1)"
      ],
      "metadata": {
        "id": "p801DPVnJLI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_filtered_region = new_region * identity\n",
        "new_total = new_filtered_region.sum()\n",
        "new_total"
      ],
      "metadata": {
        "id": "tu1Xmj6HJOyX",
        "outputId": "ff428a17-8d9b-46f2-a472-c8797d717840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! We have a second pixel value to add to our resulting image.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv6.png?raw=1)\n",
        "\n",
        "We can keep moving the gray region to the right until we can’t move it anymore.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv7.png?raw=1)\n",
        "\n",
        "The fourth step to the right will actually place the region partially outside the\n",
        "input image."
      ],
      "metadata": {
        "id": "N_zfUbc4KUzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_horizontal_region = single[:, :, 0:3, (0+4):(3+4)]"
      ],
      "metadata": {
        "id": "g8r2NNINKeUI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selected region does not match the shape of the filter anymore. \n",
        "\n",
        "So, if we try to\n",
        "perform the element-wise multiplication, it fails:"
      ],
      "metadata": {
        "id": "XP8Uby8_K4nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  last_horizontal_region * identity\n",
        "except Exception as exp:\n",
        "  print(exp)"
      ],
      "metadata": {
        "id": "zcWMNoMCK5w_",
        "outputId": "898963d5-45f3-492c-c243-0a6a7d48761a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "operands could not be broadcast together with shapes (1,1,3,2) (1,1,3,3) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Shape"
      ],
      "metadata": {
        "id": "jBkcwd9cLRHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we go back to the left side and move down one step. If we repeat the\n",
        "operation, covering all valid regions, we’ll end up with a resulting image that is\n",
        "smaller (on the right).\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/conv8.png?raw=1)\n",
        "\n",
        "How much smaller is it going to be?\n",
        "\n",
        "It depends on the size of the filter.\n",
        "\n",
        ">The larger the filter, the smaller the resulting image.\n",
        "\n",
        "Since applying a filter always produces a single value, the reduction is equal to the\n",
        "filter size minus one.\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "(h_i, w_i) * (h_f, w_f) = (h_i - (h_f - 1), w_i - (w_f - 1))\n",
        "$$\n",
        "\n",
        "If we assume the filter is a square matrix of size f, we can simplify the expression\n",
        "above to:\n",
        "\n",
        "$$\n",
        "\\Large\n",
        "(h_i, w_i) * f = (h_i - f + 1, w_i - f + 1)\n",
        "$$\n",
        "\n",
        "But I’d like to keep the image size, is it possible?\n",
        "\n",
        "Sure it is! Padding comes to our rescue in this case."
      ],
      "metadata": {
        "id": "lhKlTPhcLR-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convolving in PyTorch"
      ],
      "metadata": {
        "id": "iZdPF3vJSJNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know how a convolution works, let’s try it out using PyTorch."
      ],
      "metadata": {
        "id": "svvUMTDGSKHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert our image and filter to tensors\n",
        "image = torch.as_tensor(single).float()\n",
        "kernel = torch.as_tensor(identity).float()"
      ],
      "metadata": {
        "id": "FpDNP9utXtc6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like the activation functions, convolutions come in two\n",
        "flavors: functional and module. \n",
        "\n",
        "There is a fundamental difference between the\n",
        "two, though: The functional convolution takes the kernel / filter as an argument\n",
        "while the module has (learnable) weights to represent the kernel / filter.\n",
        "\n",
        "Let’s use the functional convolution, `F.conv2d()`, to apply the identity filter to our\n",
        "input image."
      ],
      "metadata": {
        "id": "7XxFSecQYQao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convolved = F.conv2d(image, kernel, stride=1)\n",
        "convolved"
      ],
      "metadata": {
        "id": "Fm6TCTCpYfRF",
        "outputId": "c6d5163c-7e2b-4137-be45-62e063c787e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[9., 5., 0., 7.],\n",
              "          [0., 2., 4., 6.],\n",
              "          [7., 6., 6., 8.],\n",
              "          [3., 8., 5., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s turn our attention to PyTorch’s convolution module, `nn.Conv2d`."
      ],
      "metadata": {
        "id": "2jPbCKifZuGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1)\n",
        "conv(image)"
      ],
      "metadata": {
        "id": "UxDu6pa1ZwRu",
        "outputId": "3e61ff0f-eb14-4a2e-ff16-737944fd3c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.3116, -2.5939, -2.5096,  1.8754],\n",
              "          [-1.1964, -0.3318,  0.2698,  1.8475],\n",
              "          [-1.4853,  1.1750,  0.9138, -1.0752],\n",
              "          [-2.8796,  0.1066, -4.0413, -2.7793]]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results are gibberish now because the convolutional module randomly initializes the weights representing\n",
        "the kernel / filter.\n",
        "\n",
        "That’s the whole point of the convolutional module: It will learn\n",
        "the kernel / filter on its own.\n",
        "\n",
        "In traditional computer vision, people would develop different\n",
        "filters for different purposes: blurring, sharpening, edge\n",
        "detection, and so on.\n",
        "\n",
        "Can we tell it to learn multiple filters at once?"
      ],
      "metadata": {
        "id": "0mRxitR_aIFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_multiple = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1)\n",
        "conv_multiple(image)"
      ],
      "metadata": {
        "id": "-tkVCkuuasJi",
        "outputId": "de5d40a1-01f4-40e2-fee7-6531e6f82ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.9461,  5.1062,  2.4449,  4.0832],\n",
              "          [ 5.1448,  1.9132,  3.0770,  5.8165],\n",
              "          [ 5.4219,  5.9928,  4.9376,  4.3885],\n",
              "          [ 4.2059,  2.9469,  2.8337,  1.5178]],\n",
              "\n",
              "         [[-1.7295, -5.2360, -3.8463, -1.0855],\n",
              "          [-5.8062, -0.2293, -2.4201, -5.3449],\n",
              "          [-2.0328, -3.6810, -4.5338, -3.6006],\n",
              "          [-3.9992, -2.4474, -4.3811, -2.5371]]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_multiple.weight"
      ],
      "metadata": {
        "id": "ToKEQ1v1a_fp",
        "outputId": "6784ea60-8e9c-4508-b54b-d5b10307ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[-0.2465,  0.1548, -0.0782],\n",
              "          [ 0.2471,  0.2226,  0.1297],\n",
              "          [ 0.0705,  0.1128,  0.1854]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2079, -0.2087, -0.3006],\n",
              "          [-0.2097,  0.0569, -0.0502],\n",
              "          [-0.1175, -0.0695, -0.0050]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also force a convolutional module to use a particular filter by setting its weights."
      ],
      "metadata": {
        "id": "T3e8p3TVdKkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  conv.weight[0] = kernel\n",
        "  conv.bias[0] = 0\n",
        "\n",
        "conv(image)"
      ],
      "metadata": {
        "id": "uzMNjIh6dMBq",
        "outputId": "2fee6bfa-eb76-49fb-fac3-cff72da0dde9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[9., 5., 0., 7.],\n",
              "          [0., 2., 4., 6.],\n",
              "          [7., 6., 6., 8.],\n",
              "          [3., 8., 5., 1.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv.weight"
      ],
      "metadata": {
        "id": "b5TEqL4ud8zW",
        "outputId": "e0f41438-949e-4ad1-80de-441c484845a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[0., 0., 0.],\n",
              "          [0., 1., 0.],\n",
              "          [0., 0., 0.]]]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the weights to get specific filters is at the heart of\n",
        "transfer learning. \n",
        "\n",
        "Someone else trained a model, and that model\n",
        "learned lots of useful filters, so we don’t have to learn them\n",
        "again. We can set the corresponding weights and go from there."
      ],
      "metadata": {
        "id": "5gYV5KxYeIWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Striding"
      ],
      "metadata": {
        "id": "t9HI8NnZeKMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fyfsZe1MeMGQ"
      }
    }
  ]
}