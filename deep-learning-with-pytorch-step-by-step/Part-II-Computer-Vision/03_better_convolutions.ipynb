{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+3HW3sSaJARz93bNP0Ndq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/03_better_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Better Convolutions"
      ],
      "metadata": {
        "id": "qKDOcAGwkGhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, let's use a different dataset: Rock Paper Scissors.\n",
        "\n",
        "The dataset contains 2,892 images of diverse hands in the typical rock, paper, and\n",
        "scissors poses against a white background. This is a synthetic dataset as well since\n",
        "the images were generated using CGI techniques. Each image is 300x300 pixels in\n",
        "size and has four channels (RGBA).\n",
        "\n",
        "Here are some examples of its images, one for each pose.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/download.png?raw=1)"
      ],
      "metadata": {
        "id": "KIj__-HokOxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "3WRqxBEvlvgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sJOR-0hwlwr7",
        "outputId": "aa48f72e-f23a-4feb-d301-66998133667e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter6()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter6 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXOl_Holz6M",
        "outputId": "427d3fb1-8c6d-4c14-d806-6bf35b752205"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, ToPILImage, Resize\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, MultiStepLR, CyclicLR, LambdaLR\n",
        "\n",
        "from stepbystep.v2 import StepByStep"
      ],
      "metadata": {
        "id": "54a8hhq8l2AK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0A-YvvDpDl-1",
        "outputId": "e115ea7a-0bd5-485c-a3be-429e694a166e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "iDxyNz9iEDxw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/datasets/sanikamal/rock-paper-scissors-dataset\n",
        "kaggle datasets download -d sanikamal/rock-paper-scissors-dataset\n",
        "\n",
        "unzip -qq rock-paper-scissors-dataset.zip\n",
        "rm -rf rock-paper-scissors-dataset.zip"
      ],
      "metadata": {
        "id": "imNthwCGdJTw",
        "outputId": "31b4a389-4102-483b-cfb1-95c2975914a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rock-paper-scissors-dataset.zip to /content\n",
            " 96% 436M/452M [00:03<00:00, 180MB/s]\n",
            "100% 452M/452M [00:03<00:00, 145MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Z9Sqyzlxl-Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preparation step will be a bit more demanding this time since we’ll be\n",
        "standardizing the images.Besides, we can use the ImageFolder dataset now.\n",
        "\n",
        "The Rock Paper Scissors dataset is organized like that:\n",
        "\n",
        "```\n",
        "rps/paper/paper01-000.png\n",
        "rps/paper/paper01-001.png\n",
        "\n",
        "rps/rock/rock01-000.png\n",
        "rps/rock/rock01-001.png\n",
        "\n",
        "rps/scissors/scissors01-000.png\n",
        "rps/scissors/scissors01-001.png\n",
        "```\n",
        "\n",
        "The dataset is also perfectly balanced, with each sub-folder containing 840 images\n",
        "of its particular class.\n",
        "\n",
        "Let’s create a dataset then:"
      ],
      "metadata": {
        "id": "NMt6wXGPl_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_FOLDER = \"Rock-Paper-Scissors\"\n",
        "temp_transform = Compose([Resize(28), ToTensor()])\n",
        "temp_dataset = ImageFolder(root=ROOT_FOLDER, transform=temp_transform)"
      ],
      "metadata": {
        "id": "-04BquM1nbe4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataset[0][0].shape, temp_dataset[0][1]"
      ],
      "metadata": {
        "id": "vSFRh8T8eP3G",
        "outputId": "dd21408e-b7e9-4811-97ef-d46541c727c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 28, 28]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Standardization"
      ],
      "metadata": {
        "id": "VJF-KE8Venjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To standardize data points, we need to learn their mean and standard deviation\n",
        "first.\n",
        "\n",
        "To compute these, we need to load the data.\n",
        "\n",
        "The good thing is, we have\n",
        "a (temporary) dataset with the resized images already! We’re only missing a data\n",
        "loader."
      ],
      "metadata": {
        "id": "g_figy2Eeobq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_loader = DataLoader(temp_dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "6VReWpJ_e1_S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let’s build a function that takes a mini-batch (images and labels) and computes\n",
        "the mean pixel value and standard deviation per channel of each image, adding up\n",
        "the results for all images."
      ],
      "metadata": {
        "id": "fdcIoIJFkrsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def statistics_per_channel(images, labels):\n",
        "  # NCHW\n",
        "  n_samples, n_channels, n_height, n_weight = images.size()\n",
        "  # Flatten HW into a single dimension\n",
        "  flatten_per_channel = images.reshape(n_samples, n_channels, -1)\n",
        "\n",
        "  # Computes statistics of each image per channel\n",
        "  # Average pixel value per channel (n_samples, n_channels)\n",
        "  means = flatten_per_channel.mean(axis=2)\n",
        "  # Standard deviation of pixel values per channel (n_samples, n_channels)\n",
        "  stds = flatten_per_channel.std(axis=2)\n",
        "\n",
        "  # Adds up statistics of all images in a mini-batch (1, n_channels)\n",
        "  sum_means = means.sum(axis=0)\n",
        "  sum_stds = stds.sum(axis=0)\n",
        "\n",
        "  # Makes a tensor of shape (1, n_channels) with the number of samples in the mini-batch\n",
        "  n_samples = torch.tensor([n_samples] * n_channels).float()\n",
        "\n",
        "  # Stack the three tensors on top of one another (3, n_channels)\n",
        "  return torch.stack([n_samples, sum_means, sum_stds], axis=0)\n",
        "\n",
        "setattr(StepByStep, 'statistics_per_channel', statistics_per_channel)"
      ],
      "metadata": {
        "id": "3gC8jtMYksM3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_images, first_labels = next(iter(temp_loader))\n",
        "StepByStep.statistics_per_channel(first_images, first_labels)"
      ],
      "metadata": {
        "id": "EOtdYsT9m5_R",
        "outputId": "f4ce5621-76d3-4e8c-c0a4-f292a6afdb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[16.0000, 16.0000, 16.0000],\n",
              "        [15.0968, 14.0652, 13.5893],\n",
              "        [ 0.8948,  2.3599,  3.1430]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can leverage the `loader_apply()` method we created in the last chapter to get\n",
        "the sums for the whole dataset:"
      ],
      "metadata": {
        "id": "RGdcOwxzpiUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = StepByStep.loader_apply(temp_loader, StepByStep.statistics_per_channel)\n",
        "results"
      ],
      "metadata": {
        "id": "9O780X1Spj7g",
        "outputId": "bb858dd4-40eb-4f05-f024-993da3bfbca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2925.0000, 2925.0000, 2925.0000],\n",
              "        [2506.6553, 2419.2803, 2387.8225],\n",
              "        [ 583.3219,  713.7609,  761.2370]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we can compute the average mean value and the\n",
        "average standard deviation, per channel. \n",
        "\n",
        "Better yet, let’s make it a method that\n",
        "takes a data loader and returns an instance of the `Normalize()` transform,\n",
        "statistics and all:"
      ],
      "metadata": {
        "id": "P8lDoSGMp3lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@staticmethod\n",
        "def make_normalizer(loader):\n",
        "  total_samples, total_means, total_stds = StepByStep.loader_apply(temp_loader, StepByStep.statistics_per_channel)\n",
        "  norm_mean = total_means / total_samples\n",
        "  norm_std = total_stds / total_samples\n",
        "  return Normalize(mean=norm_mean, std=norm_std)\n",
        "\n",
        "setattr(StepByStep, 'make_normalizer', make_normalizer)"
      ],
      "metadata": {
        "id": "Hn42s4lmp7xi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can use this method to create a transformation that standardizes our\n",
        "dataset:"
      ],
      "metadata": {
        "id": "-CHOtDB6qhsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = StepByStep.make_normalizer(temp_loader)\n",
        "normalizer"
      ],
      "metadata": {
        "id": "0K8vqQyFqiHG",
        "outputId": "a058457a-ce66-4ddd-b7cd-c1de858096b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normalize(mean=tensor([0.8570, 0.8271, 0.8163]), std=tensor([0.1994, 0.2440, 0.2603]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Real Datasets"
      ],
      "metadata": {
        "id": "vVhZHX_SsB6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s time to build our real datasets using the `Normalize()` transform with the\n",
        "statistics."
      ],
      "metadata": {
        "id": "Zl4V53YwsCxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "composer = Compose([Resize(28), ToTensor(), normalizer])\n",
        "\n",
        "train_data = ImageFolder(root=f\"{ROOT_FOLDER}/train\", transform=composer)\n",
        "val_data = ImageFolder(root=f\"{ROOT_FOLDER}/test\", transform=composer)\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "QW0r77mzsKad"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s take a peek at some images from the real training set."
      ],
      "metadata": {
        "id": "S7XRciiFtTYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(88)\n",
        "\n",
        "first_images, first_labels = next(iter(train_loader))\n",
        "\n",
        "fig = figure2(first_images, first_labels)"
      ],
      "metadata": {
        "id": "o2U5Fw96tLWj",
        "outputId": "06b747a4-4679-4e3f-a9c9-8288af8cd5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Three-Channel Convolutions"
      ],
      "metadata": {
        "id": "ia5v6-ebtp6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolving a three-channel filter over a three-channel image still produces a\n",
        "single value.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/3channel1.png?raw=1)\n",
        "\n",
        "Adding up the results for each\n",
        "channel produces the expected single value.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/3channel2.png?raw=1)\n",
        "\n",
        "We can also look at it in code."
      ],
      "metadata": {
        "id": "n_yi7LIptqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions = np.array([[[[5, 0, 8],\n",
        "                      [1, 9, 5],\n",
        "                      [6, 0, 2]],\n",
        "                     [[0, 5, 4],\n",
        "                      [8, 1, 9],\n",
        "                      [4, 8, 1]],\n",
        "                     [[4, 2, 0],\n",
        "                      [6, 3, 0],\n",
        "                      [5, 2, 8]]]])\n",
        "regions.shape"
      ],
      "metadata": {
        "id": "9VnF8htTmng4",
        "outputId": "0f410dad-1f6d-4b95-990c-11098e48dce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "three_channel_filter = np.array([[[[0, 3, 0],\n",
        "                                   [1, 0, 1],\n",
        "                                   [2, 1, 0]],\n",
        "                                  [[2, 1, 0],\n",
        "                                   [0, 3, 1],\n",
        "                                   [1, -1, 0]],\n",
        "                                  [[0, 1, 3],\n",
        "                                   [-1, -2, 0],\n",
        "                                   [2, 0, 1]]]])\n",
        "three_channel_filter.shape"
      ],
      "metadata": {
        "id": "Cxw0Q9IEm-iJ",
        "outputId": "a86a69e8-07f2-4347-bb39-f2258d954512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 3, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = F.conv2d(torch.as_tensor(regions), torch.as_tensor(three_channel_filter))\n",
        "result, result.shape"
      ],
      "metadata": {
        "id": "NxFWwJLCnBKd",
        "outputId": "6911bd92-d5f2-46df-90a5-d0b1bc5c4db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[39]]]]), torch.Size([1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if I have two filters?\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/images/3channel_filters1.png?raw=1)\n",
        "\n",
        "If you have two filters, and the input image has three channels, each filter has\n",
        "three channels as well, and the output has two channels.\n",
        "\n",
        ">The convolution produces as many channels as there are filters.\n"
      ],
      "metadata": {
        "id": "kC4qLRrFnYih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fancier Model"
      ],
      "metadata": {
        "id": "kDjJb_monknm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "On1OaMBqnl5l"
      }
    }
  ]
}