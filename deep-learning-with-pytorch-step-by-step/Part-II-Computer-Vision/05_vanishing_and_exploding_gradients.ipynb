{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMO7PT563cen8x3UqlA0/3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/05_vanishing_and_exploding_gradients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vanishing and Exploding Gradients"
      ],
      "metadata": {
        "id": "qKDOcAGwkGhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's consider what is Transfer learning?\n",
        "\n",
        "The idea is quite simple. First, some big tech company, which has access to virtually\n",
        "infinite amounts of data and computing power, develops and trains a huge model\n",
        "for their own purpose. \n",
        "\n",
        "Next, once it is trained, its architecture and the corresponding trained weights (the pre-trained model) are released. Finally,\n",
        "everyone else can use these weights as a starting point and fine-tune them\n",
        "further for a different (but similar) purpose.\n",
        "\n",
        "That’s transfer learning in a nutshell.\n",
        "\n",
        "Now, we are aware of the necessary steps to use transfer learning\n",
        "with pre-trained models for computer vision tasks: using ImageNet statistics for\n",
        "pre-processing the inputs, freezing layers (or not), replacing the \"top\" layer, and\n",
        "optionally speeding up training by generating features and training the \"top\" of\n",
        "the model independently.\n",
        "\n"
      ],
      "metadata": {
        "id": "KIj__-HokOxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "3WRqxBEvlvgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sJOR-0hwlwr7",
        "outputId": "25d73530-ada4-4f82-ccf0-ecd429049331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter7()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter7 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXOl_Holz6M",
        "outputId": "4cb1cc09-4196-4089-d2ac-0daf9c67b211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, ToPILImage, CenterCrop, RandomResizedCrop\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import alexnet, resnet18, inception_v3\n",
        "#from torchvision.models.alexnet import model_urls\n",
        "try:\n",
        "  from torchvision.models.utils import load_state_dict_from_url\n",
        "except ImportError:\n",
        "  from torch.hub import load_state_dict_from_url\n",
        "\n",
        "from stepbystep.v3 import StepByStep\n",
        "from data_generation.rps import download_rps"
      ],
      "metadata": {
        "id": "54a8hhq8l2AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0A-YvvDpDl-1",
        "outputId": "dbf163c8-e95b-4950-ce4c-9762675701bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "iDxyNz9iEDxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/datasets/sanikamal/rock-paper-scissors-dataset\n",
        "kaggle datasets download -d sanikamal/rock-paper-scissors-dataset\n",
        "\n",
        "unzip -qq rock-paper-scissors-dataset.zip\n",
        "rm -rf rock-paper-scissors-dataset.zip"
      ],
      "metadata": {
        "id": "imNthwCGdJTw",
        "outputId": "550c2926-c071-40be-c9ff-aa06960811a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rock-paper-scissors-dataset.zip to /content\n",
            " 97% 438M/452M [00:04<00:00, 100MB/s]\n",
            "100% 452M/452M [00:04<00:00, 102MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "HrCBq56i3sVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_model(model):\n",
        "  for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "def preprocessed_dataset(model, loader, device=None):\n",
        "  if device is None:\n",
        "    device = next(model.parameters()).device\n",
        "  \n",
        "  features = None\n",
        "  labels = None\n",
        "\n",
        "  for i, (x, y) in enumerate(loader):\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    output = model(x)\n",
        "    if i == 0:\n",
        "      features = output.detach().cpu()\n",
        "      labels = y.cpu()\n",
        "    else:\n",
        "      features = torch.cat([features, output.detach().cpu()])\n",
        "      labels = torch.cat([labels, y.cpu()])\n",
        "\n",
        "  dataset = TensorDataset(features, labels)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "zRrrEN1f4qu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Z9Sqyzlxl-Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preparation step will be a bit more demanding this time since we’ll be\n",
        "standardizing the images.Besides, we can use the ImageFolder dataset now.\n",
        "\n",
        "The Rock Paper Scissors dataset is organized like that:\n",
        "\n",
        "```\n",
        "rps/paper/paper01-000.png\n",
        "rps/paper/paper01-001.png\n",
        "\n",
        "rps/rock/rock01-000.png\n",
        "rps/rock/rock01-001.png\n",
        "\n",
        "rps/scissors/scissors01-000.png\n",
        "rps/scissors/scissors01-001.png\n",
        "```\n",
        "\n",
        "The dataset is also perfectly balanced, with each sub-folder containing 840 images\n",
        "of its particular class."
      ],
      "metadata": {
        "id": "NMt6wXGPl_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_FOLDER = \"Rock-Paper-Scissors\""
      ],
      "metadata": {
        "id": "-04BquM1nbe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we’re using a pre-trained model, we need to use the standardization\n",
        "parameters used to train the original model. \n",
        "\n",
        "In other words, we need to use the\n",
        "statistics of the original dataset used to train that model.\n",
        "\n",
        "So, the data preparation step for the Rock Paper Scissors dataset looks like this now:"
      ],
      "metadata": {
        "id": "Zl4V53YwsCxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "composer = Compose([\n",
        "  Resize(256),\n",
        "  CenterCrop(224),\n",
        "  ToTensor(),\n",
        "  normalizer\n",
        "])\n",
        "\n",
        "train_data = ImageFolder(root=f\"{ROOT_FOLDER}/train\", transform=composer)\n",
        "val_data = ImageFolder(root=f\"{ROOT_FOLDER}/test\", transform=composer)\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "QW0r77mzsKad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-Tuning"
      ],
      "metadata": {
        "id": "ia5v6-ebtp6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the smallest version of the `ResNet` model (`resnet18`) and either\n",
        "fine-tune it or use it as a feature extractor only."
      ],
      "metadata": {
        "id": "n_yi7LIptqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = resnet18(weights=True)\n",
        "model.fc = nn.Linear(512, 3)"
      ],
      "metadata": {
        "id": "8a1kaUIB1fvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no freezing since fine-tuning entails the training of all the weights, not only\n",
        "those from the \"top\" layer."
      ],
      "metadata": {
        "id": "RucReUnt15ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer_model = optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "c7Z1rAuIqHdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have everything set to train."
      ],
      "metadata": {
        "id": "fCpfs2pa04UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbs_transfer = StepByStep(model, multi_loss_fn, optimizer_model)\n",
        "sbs_transfer.set_loaders(train_loader, val_loader)\n",
        "sbs_transfer.train(1)"
      ],
      "metadata": {
        "id": "b600rp9I04uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see what the model can accomplish after training for a single epoch."
      ],
      "metadata": {
        "id": "0bu0-2yjwiTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StepByStep.loader_apply(val_loader, sbs_transfer.correct)"
      ],
      "metadata": {
        "id": "BpfWatQwjN0W",
        "outputId": "6c3111cf-b3ad-443d-bfb7-43b55ca986a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[124, 124],\n",
              "        [124, 124],\n",
              "        [124, 124]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we had frozen the layers in the model above, it would have been a case of\n",
        "feature extraction suitable for data augmentation since we would be training the\n",
        "\"top\" layer while it was still attached to the rest of the model."
      ],
      "metadata": {
        "id": "WK6C5w333Okb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction"
      ],
      "metadata": {
        "id": "puyt8uzt3VkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we’re modifying the model (replacing the \"top\" layer\n",
        "with an identity layer) to generate a dataset of features first and then using it to\n",
        "train the real \"top\" layer independently."
      ],
      "metadata": {
        "id": "43sdVWSe3WMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Configuration\n",
        "model = resnet18(weights=True).to(device)\n",
        "model.fc = nn.Identity()\n",
        "freeze_model(model)"
      ],
      "metadata": {
        "id": "cJn6EdV54KgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation — Preprocessing\n",
        "train_preproc = preprocessed_dataset(model, train_loader)\n",
        "val_preproc = preprocessed_dataset(model, val_loader)\n",
        "train_preproc_loader = DataLoader(train_preproc, batch_size=16, shuffle=True)\n",
        "val_preproc_loader = DataLoader(val_preproc, batch_size=16)"
      ],
      "metadata": {
        "id": "zCpc8FU25DU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the dataset of features and its corresponding loaders are ready, we only need\n",
        "to create a model corresponding to the \"top\" layer and train it in the usual way."
      ],
      "metadata": {
        "id": "KR4yWH8_6RsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Configuration — Top Model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "top_model = nn.Sequential(nn.Linear(512, 3))\n",
        "\n",
        "multi_loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer_top = optim.Adam(top_model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "7QguWiPx6Slu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training — Top Model\n",
        "sbs_top = StepByStep(top_model, multi_loss_fn, optimizer_top)\n",
        "sbs_top.set_loaders(train_preproc_loader, val_preproc_loader)\n",
        "sbs_top.train(10)"
      ],
      "metadata": {
        "id": "xvxcH05T7GOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We surely can evaluate the model now\n",
        "StepByStep.loader_apply(val_preproc_loader, sbs_top.correct)"
      ],
      "metadata": {
        "id": "fSvoNmsb7c4N",
        "outputId": "4500ac05-0fc0-4696-a08c-315d5e0399cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 98, 124],\n",
              "        [124, 124],\n",
              "        [104, 124]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, if we want to try it out on the original dataset (containing the images), we need to reattach the \"top\" layer."
      ],
      "metadata": {
        "id": "lPsqYes87-P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = top_model\n",
        "sbs_temp = StepByStep(model, None, None)"
      ],
      "metadata": {
        "id": "Ci2MWGM-8AY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, both loss function and\n",
        "optimizers are set to None since we won’t be training the model anymore."
      ],
      "metadata": {
        "id": "W_-HHZNH8Yyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StepByStep.loader_apply(val_loader, sbs_temp.correct)"
      ],
      "metadata": {
        "id": "cAQ4J_op8YNd",
        "outputId": "e82defd8-1e72-4069-e841-5c99662f9d38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 98, 124],\n",
              "        [124, 124],\n",
              "        [104, 124]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got the same results, as expected."
      ],
      "metadata": {
        "id": "Six2em2L8mRd"
      }
    }
  ]
}