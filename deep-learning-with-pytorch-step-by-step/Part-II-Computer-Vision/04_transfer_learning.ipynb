{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOE6svxP04eykhgvZWJkT5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "862bec1944704254813d667c705d233d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e3a0b3e6351425a9c3055a0f0e2727e",
              "IPY_MODEL_1caf8533f944434791e23bbc341e0e2e",
              "IPY_MODEL_9468fea0d9874bea839b0fe24c2a9c61"
            ],
            "layout": "IPY_MODEL_286275fc2fbc48449571c56d17208060"
          }
        },
        "2e3a0b3e6351425a9c3055a0f0e2727e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac51d6f29678456f86982c35db51414d",
            "placeholder": "​",
            "style": "IPY_MODEL_5d74c49de7da4277b3063af9a9919db6",
            "value": "100%"
          }
        },
        "1caf8533f944434791e23bbc341e0e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da5a96192ff4a64b36853857b0ff3e5",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d069db9491a4213a8d12fa405cc17a3",
            "value": 244408911
          }
        },
        "9468fea0d9874bea839b0fe24c2a9c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d377b79716104b4bbaddccfe816088a5",
            "placeholder": "​",
            "style": "IPY_MODEL_0a50f9b2e2b846ed8338e2a11660d485",
            "value": " 233M/233M [00:01&lt;00:00, 181MB/s]"
          }
        },
        "286275fc2fbc48449571c56d17208060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac51d6f29678456f86982c35db51414d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d74c49de7da4277b3063af9a9919db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9da5a96192ff4a64b36853857b0ff3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d069db9491a4213a8d12fa405cc17a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d377b79716104b4bbaddccfe816088a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a50f9b2e2b846ed8338e2a11660d485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/04_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer Learning"
      ],
      "metadata": {
        "id": "qKDOcAGwkGhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's consider what is Transfer learning?\n",
        "\n",
        "The idea is quite simple. First, some big tech company, which has access to virtually\n",
        "infinite amounts of data and computing power, develops and trains a huge model\n",
        "for their own purpose. \n",
        "\n",
        "Next, once it is trained, its architecture and the corresponding trained weights (the pre-trained model) are released. Finally,\n",
        "everyone else can use these weights as a starting point and fine-tune them\n",
        "further for a different (but similar) purpose.\n",
        "\n",
        "That’s transfer learning in a nutshell."
      ],
      "metadata": {
        "id": "KIj__-HokOxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "3WRqxBEvlvgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sJOR-0hwlwr7",
        "outputId": "9d1d22be-83c5-42b9-f9d7-344537e27215"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter7()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter7 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXOl_Holz6M",
        "outputId": "97ead15d-7a0f-4643-a7f8-e6396a1fd03f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, ToPILImage, CenterCrop, RandomResizedCrop\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import alexnet, resnet18, inception_v3\n",
        "from torchvision.models.alexnet import model_urls\n",
        "try:\n",
        "  from torchvision.models.utils import load_state_dict_from_url\n",
        "except ImportError:\n",
        "  from torch.hub import load_state_dict_from_url\n",
        "\n",
        "from stepbystep.v3 import StepByStep\n",
        "from data_generation.rps import download_rps"
      ],
      "metadata": {
        "id": "54a8hhq8l2AK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0A-YvvDpDl-1",
        "outputId": "46572ce8-fa51-4802-b828-2c1199872ba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "iDxyNz9iEDxw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/datasets/sanikamal/rock-paper-scissors-dataset\n",
        "kaggle datasets download -d sanikamal/rock-paper-scissors-dataset\n",
        "\n",
        "unzip -qq rock-paper-scissors-dataset.zip\n",
        "rm -rf rock-paper-scissors-dataset.zip"
      ],
      "metadata": {
        "id": "imNthwCGdJTw",
        "outputId": "62bd7878-8468-4a97-fd47-9268d23f19cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rock-paper-scissors-dataset.zip to /content\n",
            " 97% 438M/452M [00:05<00:00, 102MB/s]\n",
            "100% 452M/452M [00:05<00:00, 85.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Z9Sqyzlxl-Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preparation step will be a bit more demanding this time since we’ll be\n",
        "standardizing the images.Besides, we can use the ImageFolder dataset now.\n",
        "\n",
        "The Rock Paper Scissors dataset is organized like that:\n",
        "\n",
        "```\n",
        "rps/paper/paper01-000.png\n",
        "rps/paper/paper01-001.png\n",
        "\n",
        "rps/rock/rock01-000.png\n",
        "rps/rock/rock01-001.png\n",
        "\n",
        "rps/scissors/scissors01-000.png\n",
        "rps/scissors/scissors01-001.png\n",
        "```\n",
        "\n",
        "The dataset is also perfectly balanced, with each sub-folder containing 840 images\n",
        "of its particular class."
      ],
      "metadata": {
        "id": "NMt6wXGPl_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_FOLDER = \"Rock-Paper-Scissors\""
      ],
      "metadata": {
        "id": "-04BquM1nbe4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we’re using a pre-trained model, we need to use the standardization\n",
        "parameters used to train the original model. \n",
        "\n",
        "In other words, we need to use the\n",
        "statistics of the original dataset used to train that model.\n",
        "\n",
        "So, the data preparation step for the Rock Paper Scissors dataset looks like this now:"
      ],
      "metadata": {
        "id": "Zl4V53YwsCxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "composer = Compose([\n",
        "  Resize(256),\n",
        "  CenterCrop(224),\n",
        "  ToTensor(),\n",
        "  normalizer\n",
        "])\n",
        "\n",
        "train_data = ImageFolder(root=f\"{ROOT_FOLDER}/train\", transform=composer)\n",
        "val_data = ImageFolder(root=f\"{ROOT_FOLDER}/test\", transform=composer)\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "QW0r77mzsKad"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-Trained Model"
      ],
      "metadata": {
        "id": "ia5v6-ebtp6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by creating an instance of AlexNet without loading its pre-trained\n",
        "weights."
      ],
      "metadata": {
        "id": "n_yi7LIptqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alex = alexnet(weights=False)\n",
        "print(alex)"
      ],
      "metadata": {
        "id": "9VnF8htTmng4",
        "outputId": "e0edbd6d-b79f-4775-f4f9-a899704e5636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Adaptive Pooling"
      ],
      "metadata": {
        "id": "6IIXNpNGK_YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`AdaptiveAvgPool2d` is a special kind of pooling: Instead of requiring the kernel size\n",
        "(and stride), it requires the desired output size. \n",
        "\n",
        "In other words, whatever the\n",
        "image size it gets as input, it will return a tensor with the desired size.\n",
        "\n",
        "It gives you the freedom to use images of different sizes as inputs.\n",
        "\n",
        "Let’s verify it."
      ],
      "metadata": {
        "id": "7ImU48BSJDI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = F.adaptive_avg_pool2d(torch.randn(16, 32, 32), output_size=(6, 6))\n",
        "result2 = F.adaptive_avg_pool2d(torch.randn(16, 12, 12), output_size=(6, 6))\n",
        "\n",
        "result1.shape, result2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0oY6PmYKd4C",
        "outputId": "6bf547e6-cae0-4486-a579-68a544e7b685"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 6, 6]), torch.Size([16, 6, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading Weights"
      ],
      "metadata": {
        "id": "B3gaIQZRLET3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s download the weights\n",
        "from a given URL, which gives you the flexibility to use pre-trained weights from\n",
        "wherever you want!"
      ],
      "metadata": {
        "id": "On1OaMBqnl5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = model_urls[\"alexnet\"]\n",
        "URL"
      ],
      "metadata": {
        "id": "sfhWjLZknU3z",
        "outputId": "b47e61d1-d538-45f2-d027-96b0a5a8efab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://download.pytorch.org/models/alexnet-owt-7be5be79.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = load_state_dict_from_url(URL, model_dir=\"pretrained\", progress=True)"
      ],
      "metadata": {
        "id": "QtKjfFDNbVCn",
        "outputId": "ed40ab53-3050-490d-9824-a831965396c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "862bec1944704254813d667c705d233d",
            "2e3a0b3e6351425a9c3055a0f0e2727e",
            "1caf8533f944434791e23bbc341e0e2e",
            "9468fea0d9874bea839b0fe24c2a9c61",
            "286275fc2fbc48449571c56d17208060",
            "ac51d6f29678456f86982c35db51414d",
            "5d74c49de7da4277b3063af9a9919db6",
            "9da5a96192ff4a64b36853857b0ff3e5",
            "2d069db9491a4213a8d12fa405cc17a3",
            "d377b79716104b4bbaddccfe816088a5",
            "0a50f9b2e2b846ed8338e2a11660d485"
          ]
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to pretrained/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "862bec1944704254813d667c705d233d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load model\n",
        "alex.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "ySu-bovibn5W",
        "outputId": "0a4af0bb-637a-45cc-f33d-bf1b66af8fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Freezing"
      ],
      "metadata": {
        "id": "Tb-ieAysrUL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing the model means it won’t learn anymore; that is, its\n",
        "parameters / weights will not be updated anymore.\n",
        "\n",
        "What best characterizes a tensor representing a learnable parameter? It requires\n",
        "gradients. \n",
        "\n",
        "So, if we’d like to make them stop learning anything, we need to change\n",
        "exactly that:"
      ],
      "metadata": {
        "id": "VpiORRVBrVN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_model(model):\n",
        "  for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "freeze_model(alex)"
      ],
      "metadata": {
        "id": "QTP6DzzJtqUb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model is frozen, how I am supposed to train it for my own\n",
        "purpose?\n",
        "\n",
        "We have to unfreeze a small part of the model or, better yet,\n",
        "replace a small part of the model."
      ],
      "metadata": {
        "id": "4TqUUInJ418a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Top of the Model"
      ],
      "metadata": {
        "id": "WV8WiWi0dEHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"top\" of the model is loosely defined as the last layer(s) of the model, usually\n",
        "belonging to its classifier part. \n",
        "\n",
        "The featurizer part is usually left untouched since\n",
        "we’re trying to leverage the model’s ability to generate features for us."
      ],
      "metadata": {
        "id": "7v4iZbrThnPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(alex.features)"
      ],
      "metadata": {
        "id": "jY6vuwDHhwuC",
        "outputId": "c6d654f4-cb0e-4b84-ece6-8f0b2296a760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(alex.classifier)"
      ],
      "metadata": {
        "id": "L6hIxrJkiAFM",
        "outputId": "d815c768-d365-4753-a4d6-6062b43a71dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our Rock Paper Scissors dataset, we have three classes. \n",
        "\n",
        "So, we need to replace the\n",
        "output layer accordingly:"
      ],
      "metadata": {
        "id": "hyImVSR_49W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alex.classifier[6] = nn.Linear(in_features=4096, out_features=3)"
      ],
      "metadata": {
        "id": "PtHW64B84934"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(alex.classifier)"
      ],
      "metadata": {
        "id": "P2r_8HOdikUM",
        "outputId": "deea2505-be23-457c-8c69-1cbc52b829d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the number of input features remains the same, since it still takes the\n",
        "output from the hidden layer that precedes it. \n",
        "\n",
        "The new output layer requires\n",
        "gradients by default, but we can double-check it:"
      ],
      "metadata": {
        "id": "ihUCAeLy5ETR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in alex.named_parameters():\n",
        "  if param.requires_grad == True:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "fkA3ofAN5K8w",
        "outputId": "72bed3d6-4cea-40ce-f31c-5430381943b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.6.weight\n",
            "classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "PxkOMQPH7E7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The configuration part is short and straightforward: We use alex model, a loss\n",
        "function, and an optimizer."
      ],
      "metadata": {
        "id": "pZIN0BMD7Flv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(17)\n",
        "\n",
        "multi_loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer_alex = optim.Adam(alex.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "c7Z1rAuIqHdT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have everything set to train the \"top\" layer of our modified version of AlexNet."
      ],
      "metadata": {
        "id": "fCpfs2pa04UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbs_alex = StepByStep(alex, multi_loss_fn, optimizer_alex)\n",
        "sbs_alex.set_loaders(train_loader, val_loader)\n",
        "sbs_alex.train(1)"
      ],
      "metadata": {
        "id": "b600rp9I04uf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see how effective transfer learning is by evaluating our model after\n",
        "having trained it over one epoch only."
      ],
      "metadata": {
        "id": "0bu0-2yjwiTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StepByStep.loader_apply(val_loader, sbs_alex.correct)"
      ],
      "metadata": {
        "id": "BpfWatQwjN0W",
        "outputId": "6a888283-2f0f-4420-e44d-37028ccb6d45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[111, 124],\n",
              "        [124, 124],\n",
              "        [124, 124]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating features"
      ],
      "metadata": {
        "id": "PVFwJIKN0Ksx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, since the frozen layers are simply generating features that will be the input\n",
        "of the trainable layers, why not treat the frozen layers as such? \n",
        "\n",
        "We could do it in\n",
        "four easy steps:\n",
        "\n",
        "* Keep only the frozen layers in the model.\n",
        "* Run the whole dataset through it and collect its outputs as a dataset of\n",
        "features.\n",
        "* Train a separate model (that corresponds to the \"top\" of the original model)\n",
        "using the dataset of features.\n",
        "* Attach the trained model to the top of the frozen layers.\n",
        "\n",
        "This way, we’re effectively splitting the feature extraction and actual training\n",
        "phases, thus avoiding the overhead of generating features over and over again for\n",
        "every single forward pass.\n",
        "\n",
        "To keep only the frozen layers, we need to get rid of the \"top\" of the original model.\n",
        "\n",
        "\n",
        "But, since we also want to attach our new layer to the whole model after training,\n",
        "it is a better idea to simply replace the \"top\" layer with an identity layer instead of\n",
        "removing it entirely:"
      ],
      "metadata": {
        "id": "cbsv_jSM0PqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alex.classifier[6] = nn.Identity()\n",
        "print(alex.classifier)"
      ],
      "metadata": {
        "id": "x7HrA_N40yoE",
        "outputId": "8e763407-0d2b-4eb7-81ff-3b090e45c648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Identity()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This way, the last effective layer is still `classifier.5`, which will produce the\n",
        "features we’re interested in. We have a feature extractor in our hands now! \n",
        "\n",
        "Let’s use it to pre-process our dataset."
      ],
      "metadata": {
        "id": "kCtLx1gd1OgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessed_dataset(model, loader, device=None):\n",
        "  if device is None:\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "  features = None\n",
        "  labels = None\n",
        "\n",
        "  for i, (x, y) in enumerate(loader):\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    output = model(x)\n",
        "    if i == 0:\n",
        "      features = output.detach().cpu()\n",
        "      labels = y.cpu()\n",
        "    else:\n",
        "      features = torch.cat([features, output.detach().cpu()])\n",
        "      labels = torch.cat([labels, y.cpu()])\n",
        "\n",
        "  dataset = TensorDataset(features, labels)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "veDf3VnS0vkI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preproc = preprocessed_dataset(alex, train_loader)\n",
        "val_preproc = preprocessed_dataset(alex, val_loader)"
      ],
      "metadata": {
        "id": "nHWAiUdt18HQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also save these tensors to disk:"
      ],
      "metadata": {
        "id": "iUCNuPcs2vnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(train_preproc.tensors, \"rps_preproc.pth\")\n",
        "torch.save(val_preproc.tensors, \"rps_val_preproc.pth\")"
      ],
      "metadata": {
        "id": "fuiEix6Q2wCN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This way, they can be used to build datasets later:"
      ],
      "metadata": {
        "id": "HgZwNGXw8poX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = torch.load(\"rps_preproc.pth\")\n",
        "\n",
        "train_preproc = TensorDataset(x, y)\n",
        "val_preproc = TensorDataset(*torch.load(\"rps_val_preproc.pth\"))"
      ],
      "metadata": {
        "id": "y3vu4pMb8qDd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step of data preparation, as usual, is the creation of the data loader:"
      ],
      "metadata": {
        "id": "d4VbCwxH9Aq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_preproc_loader = DataLoader(train_preproc, batch_size=16, shuffle=True)\n",
        "val_preproc_loader = DataLoader(val_preproc, batch_size=16)"
      ],
      "metadata": {
        "id": "r_NNPO6C9BEj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has only one layer, which matches the one we used in the \"Top of the\n",
        "Model\" subsection. \n",
        "\n",
        "The rest of the model configuration part remains unchanged:"
      ],
      "metadata": {
        "id": "iAd7TUe79h07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(17)\n",
        "\n",
        "top_model = nn.Sequential(nn.Linear(4096, 3))\n",
        "multi_loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer_top = optim.Adam(top_model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "ePTqALwF9izo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model above using the\n",
        "pre-processed dataset."
      ],
      "metadata": {
        "id": "xqh_zkb690Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbs_top = StepByStep(top_model, multi_loss_fn, optimizer_top)\n",
        "sbs_top.set_loaders(train_preproc_loader, val_preproc_loader)\n",
        "sbs_top.train(10)"
      ],
      "metadata": {
        "id": "p-zZuXwD96yU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can attach the trained model to the top of the full (frozen) model:"
      ],
      "metadata": {
        "id": "aOvSQgpE-PP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbs_alex.model.classifier[6] = top_model\n",
        "print(sbs_alex.model.classifier)"
      ],
      "metadata": {
        "id": "lsaz3VCj-PuX",
        "outputId": "f364cce7-5159-4ff2-d3d1-df02c3477070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see how it performs on the validation set.\n",
        "\n",
        "We’re using the full model again, so we should use the original\n",
        "dataset instead of the pre-processed one."
      ],
      "metadata": {
        "id": "uFmNYhf8-sTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "StepByStep.loader_apply(val_loader, sbs_alex.correct)"
      ],
      "metadata": {
        "id": "O_a9Fd-c-voS",
        "outputId": "618ea1b1-7aeb-4fa8-f6ea-a83dcac955c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[103, 124],\n",
              "        [124, 124],\n",
              "        [124, 124]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is almost the same result as before.\n",
        "\n",
        "So this show you how to use\n",
        "transfer learning and how you can pre-process your dataset to speed up model\n",
        "training."
      ],
      "metadata": {
        "id": "NkiW9iLj_EOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Auxiliary Classifiers"
      ],
      "metadata": {
        "id": "fSNp6NmN_Yd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0JZ1-WkE_a1N"
      }
    }
  ]
}