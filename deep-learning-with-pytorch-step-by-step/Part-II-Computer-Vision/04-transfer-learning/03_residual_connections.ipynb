{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbrdpA8Jrg+gBaH8BazTx1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-II-Computer-Vision/04-transfer-learning/03_residual_connections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transfer Learning: Residual Connections"
      ],
      "metadata": {
        "id": "qKDOcAGwkGhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's consider what is Transfer learning?\n",
        "\n",
        "The idea is quite simple. First, some big tech company, which has access to virtually\n",
        "infinite amounts of data and computing power, develops and trains a huge model\n",
        "for their own purpose. \n",
        "\n",
        "Next, once it is trained, its architecture and the corresponding trained weights (the pre-trained model) are released. Finally,\n",
        "everyone else can use these weights as a starting point and fine-tune them\n",
        "further for a different (but similar) purpose.\n",
        "\n",
        "That’s transfer learning in a nutshell."
      ],
      "metadata": {
        "id": "KIj__-HokOxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "3WRqxBEvlvgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sJOR-0hwlwr7",
        "outputId": "849cfa17-0319-4ac8-c638-ed3031b8ba79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:80% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter7()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter7 import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXOl_Holz6M",
        "outputId": "f05977d4-c5b5-4954-daf8-3bb010e73edf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, ToPILImage, CenterCrop, RandomResizedCrop\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import alexnet, resnet18, inception_v3\n",
        "#from torchvision.models.alexnet import model_urls\n",
        "try:\n",
        "  from torchvision.models.utils import load_state_dict_from_url\n",
        "except ImportError:\n",
        "  from torch.hub import load_state_dict_from_url\n",
        "\n",
        "from stepbystep.v3 import StepByStep\n",
        "from data_generation.rps import download_rps"
      ],
      "metadata": {
        "id": "54a8hhq8l2AK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0A-YvvDpDl-1",
        "outputId": "debf8027-abdc-451a-ac13-40761de3c8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "iDxyNz9iEDxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/datasets/sanikamal/rock-paper-scissors-dataset\n",
        "kaggle datasets download -d sanikamal/rock-paper-scissors-dataset\n",
        "\n",
        "unzip -qq rock-paper-scissors-dataset.zip\n",
        "rm -rf rock-paper-scissors-dataset.zip"
      ],
      "metadata": {
        "id": "imNthwCGdJTw",
        "outputId": "09b26262-23bf-4974-fb26-afab6b5d6495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rock-paper-scissors-dataset.zip to /content\n",
            " 99% 449M/452M [00:04<00:00, 122MB/s]\n",
            "100% 452M/452M [00:04<00:00, 98.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "Z9Sqyzlxl-Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data preparation step will be a bit more demanding this time since we’ll be\n",
        "standardizing the images.Besides, we can use the ImageFolder dataset now.\n",
        "\n",
        "The Rock Paper Scissors dataset is organized like that:\n",
        "\n",
        "```\n",
        "rps/paper/paper01-000.png\n",
        "rps/paper/paper01-001.png\n",
        "\n",
        "rps/rock/rock01-000.png\n",
        "rps/rock/rock01-001.png\n",
        "\n",
        "rps/scissors/scissors01-000.png\n",
        "rps/scissors/scissors01-001.png\n",
        "```\n",
        "\n",
        "The dataset is also perfectly balanced, with each sub-folder containing 840 images\n",
        "of its particular class."
      ],
      "metadata": {
        "id": "NMt6wXGPl_on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_FOLDER = \"Rock-Paper-Scissors\""
      ],
      "metadata": {
        "id": "-04BquM1nbe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we’re using a pre-trained model, we need to use the standardization\n",
        "parameters used to train the original model. \n",
        "\n",
        "In other words, we need to use the\n",
        "statistics of the original dataset used to train that model.\n",
        "\n",
        "So, the data preparation step for the Rock Paper Scissors dataset looks like this now:"
      ],
      "metadata": {
        "id": "Zl4V53YwsCxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "composer = Compose([\n",
        "  Resize(256),\n",
        "  CenterCrop(224),\n",
        "  ToTensor(),\n",
        "  normalizer\n",
        "])\n",
        "\n",
        "train_data = ImageFolder(root=f\"{ROOT_FOLDER}/train\", transform=composer)\n",
        "val_data = ImageFolder(root=f\"{ROOT_FOLDER}/test\", transform=composer)\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "QW0r77mzsKad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Residual Connections"
      ],
      "metadata": {
        "id": "lTXahWjzPjRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of a residual connection is quite simple, actually: After passing the input\n",
        "through a layer and activation function, the input itself is added to the result.\n",
        "\n",
        "Why would I want to add the input to the result?\n",
        "\n"
      ],
      "metadata": {
        "id": "4cuKHAIyPoLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Learning the Identity"
      ],
      "metadata": {
        "id": "9hcEY1zs4LLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural networks and their nonlinearities (activation functions) are great!\n",
        "\n",
        "But nonlinearities are both a blessing and a curse: They\n",
        "make it extremely hard for a model to learn the identity function.\n",
        "\n",
        "To illustrate this, let’s start with a dummy dataset containing 100 random data\n",
        "points with a single feature. \n",
        "\n",
        "But this feature isn’t simply a feature—it is also the\n",
        "label."
      ],
      "metadata": {
        "id": "emEoCI2H4MUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(23)\n",
        "\n",
        "dummy_points = torch.randn((100, 1))\n",
        "\n",
        "dummy_dataset = TensorDataset(dummy_points, dummy_points)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "6iFvwjFU4r73"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we were using a simple linear model, that would be a no-brainer, right?\n",
        "\n",
        "But what happens if we introduce a nonlinearity? \n",
        "\n",
        "Let’s\n",
        "configure the model and train it to see what happens:"
      ],
      "metadata": {
        "id": "4ih57OQN-pHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dummy(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Dummy, self).__init__()\n",
        "\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    output = self.activation(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "2P038cwL-sSg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(555)\n",
        "\n",
        "dummy_model = Dummy()\n",
        "dummy_loss_fn = nn.MSELoss()\n",
        "dummy_optimizer = optim.SGD(dummy_model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "TSAHCpzp5ewi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_sbs = StepByStep(dummy_model, dummy_loss_fn, dummy_optimizer)\n",
        "dummy_sbs.set_loaders(dummy_loader)\n",
        "dummy_sbs.train(200)"
      ],
      "metadata": {
        "id": "-KVs-TAMBEzC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we compare the actual labels with the model’s predictions, we’ll see that it failed\n",
        "to learn the identity function:"
      ],
      "metadata": {
        "id": "HBaDPxk06MXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate([\n",
        "  dummy_points[:5].numpy(),\n",
        "  dummy_sbs.predict(dummy_points)[:5]\n",
        "], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbawQvcaBYG3",
        "outputId": "e94886ea-abed-4fa7-8309-95ef05549491"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.9012059 ,  0.        ],\n",
              "       [ 0.56559485,  0.56559485],\n",
              "       [-0.48822638,  0.        ],\n",
              "       [ 0.75069577,  0.7506957 ],\n",
              "       [ 0.58925384,  0.58925384]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the `ReLU` can only return positive values, it will\n",
        "never be able to produce the points with negative values.\n",
        "\n",
        "Wait, that doesn’t look right … where is the output layer?\n",
        "\n",
        "I suppressed the output layer on purpose to make a point here.\n",
        "\n",
        "Please bear with me a little bit longer while I add a residual connection to the\n",
        "model:"
      ],
      "metadata": {
        "id": "A-NHE73MRaX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyResidual(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DummyResidual, self).__init__()\n",
        "\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    output = self.linear(x)\n",
        "    output = self.activation(output)\n",
        "    output = output + identity\n",
        "    return output"
      ],
      "metadata": {
        "id": "G8cn_ZlIRdAU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(555)\n",
        "\n",
        "dummy_model = DummyResidual()\n",
        "dummy_loss_fn = nn.MSELoss()\n",
        "dummy_optimizer = optim.SGD(dummy_model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "jFwMS8eGhbdg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_sbs = StepByStep(dummy_model, dummy_loss_fn, dummy_optimizer)\n",
        "dummy_sbs.set_loaders(dummy_loader)\n",
        "dummy_sbs.train(100)"
      ],
      "metadata": {
        "id": "ao_JQMMp7snf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s double-check it."
      ],
      "metadata": {
        "id": "z-6GRPzYinO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate([\n",
        "  dummy_points[:5].numpy(),\n",
        "  dummy_sbs.predict(dummy_points)[:5]\n",
        "], axis=1)"
      ],
      "metadata": {
        "id": "yombOuXsioSi",
        "outputId": "2259fe6a-12a8-45cd-8071-c4d6bf2e72f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.9012059 , -0.9012059 ],\n",
              "       [ 0.56559485,  0.56559485],\n",
              "       [-0.48822638, -0.48822638],\n",
              "       [ 0.75069577,  0.75069577],\n",
              "       [ 0.58925384,  0.58925384]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like the model actually learned the identity function … or did it? \n",
        "\n",
        "Let’s check its parameters:"
      ],
      "metadata": {
        "id": "BY2ydRDfjNW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_model.state_dict()"
      ],
      "metadata": {
        "id": "cvGXkXHujaJ8",
        "outputId": "a9f5779c-cea0-4330-ad76-7d5753f43c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight', tensor([[0.1490]])),\n",
              "             ('linear.bias', tensor([-0.3329]))])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an input value equal to zero, the output of the linear layer will be -0.3326,\n",
        "which, in turn, will be chopped off by the ReLU activation.Then \n",
        "\n",
        "Which input values produce outputs greater than zero?\n",
        "\n",
        "The answer: Input values above `2.2352 (=0.3326/0.1488)` will produce positive\n",
        "outputs, which, in turn, will pass through the ReLU activation. \n",
        "\n",
        "But I have another question for you:\n",
        "\n",
        "Guess what is the highest input value in our dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "qvkrQ7kJjwKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_points.max()"
      ],
      "metadata": {
        "id": "i_gns2NCj1XR",
        "outputId": "5c54428b-effa-4e85-9b92-442265696965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2347)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what? Does it actually mean anything?\n",
        "\n",
        "It means the model learned to stay out of the way of the inputs! \n",
        "\n",
        "Now that the\n",
        "model has the ability to use the raw inputs directly, its linear layer learned to\n",
        "produce only negative values, so its nonlinearity (ReLU) produces only zeros."
      ],
      "metadata": {
        "id": "KxxsufhnkALH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###The Power of Shortcuts"
      ],
      "metadata": {
        "id": "rBfsMsudkgZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sCcofTnxkhqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_normalizer.eval()\n",
        "\n",
        "normed3 = batch_normalizer(batch3[0])\n",
        "normed3.mean(axis=0), normed3.var(axis=0, unbiased=False)"
      ],
      "metadata": {
        "id": "IxxVdtGdk-Y8",
        "outputId": "790fe3b5-6a48-4c1c-e030-022702e6358b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1350, 0.1450]), tensor([1.0134, 1.2981]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since it is standardizing unseen data using statistics computed on\n",
        "training data, the results above are expected. \n",
        "\n",
        "The mean will be around zero and\n",
        "the standard deviation will be around one."
      ],
      "metadata": {
        "id": "-kC4LcIQldBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Momentum"
      ],
      "metadata": {
        "id": "G2_1mjTBlgtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an alternative way of computing running statistics: Instead of using a\n",
        "simple average, it uses an exponentially weighted moving average (EWMA) of the\n",
        "statistics.\n",
        "\n",
        "So, to make it abundantly clear what is being computed, I present the formulas\n",
        "below:\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{array}\n",
        "& \\text{EWMA}_t(\\alpha, x) &= &\\alpha &x_t &+ &(1-\\alpha) &\\text{EWMA}_{t-1}(\\alpha, x)\n",
        "\\\\\n",
        "\\text{running stat}_t &= &\\text{\"momentum\"} &\\text{stat}_t &+ &(1-\\text{\"momentum\"}) &\\text{running stat}_{t-1}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Let’s try it out in practice."
      ],
      "metadata": {
        "id": "hkFnp2LzlheF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_normalizer_mom = nn.BatchNorm1d(num_features=2, affine=False, momentum=0.1)\n",
        "batch_normalizer_mom.state_dict()"
      ],
      "metadata": {
        "id": "1e271q5zr1ka",
        "outputId": "66833394-30ac-4d92-e14e-3c0e36a6c78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('running_mean', tensor([0., 0.])),\n",
              "             ('running_var', tensor([1., 1.])),\n",
              "             ('num_batches_tracked', tensor(0))])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we run\n",
        "the first mini-batch through it?"
      ],
      "metadata": {
        "id": "fmPVeb6jsJ0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normed1_mom = batch_normalizer_mom(batch1[0])\n",
        "batch_normalizer_mom.state_dict()"
      ],
      "metadata": {
        "id": "624n7gClsKRX",
        "outputId": "e695a19c-e612-4e84-d212-e54855f85a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('running_mean', tensor([-0.0228, -0.0212])),\n",
              "             ('running_var', tensor([1.2743, 1.3761])),\n",
              "             ('num_batches_tracked', tensor(1))])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily verify the results for the running\n",
        "means:"
      ],
      "metadata": {
        "id": "O9o1y5O0sZ-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "running_mean = torch.zeros((1, 2))\n",
        "running_mean = 0.1 * batch1[0].mean(axis=0) + (1 - 0.1) + running_mean\n",
        "running_mean"
      ],
      "metadata": {
        "id": "UXcKXfyPsad1",
        "outputId": "dc98d524-63bf-4121-d815-f85a938b7cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8772, 0.8788]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BatchNorm2d"
      ],
      "metadata": {
        "id": "M9iE__Met6Rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between the one-dimension and the two-dimension batch\n",
        "normalization is actually quite simple: The former standardizes features (columns),\n",
        "while the latter standardizes channels (pixels).\n",
        "\n"
      ],
      "metadata": {
        "id": "vcTACO-mt7c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(39)\n",
        "\n",
        "dummy_images = torch.rand((200, 3, 10, 10))\n",
        "dummy_labels = torch.randint(2, (200, 1))\n",
        "\n",
        "dummy_dataset = TensorDataset(dummy_images, dummy_labels)\n",
        "dummy_loader = DataLoader(dummy_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "iterator = iter(dummy_loader)\n",
        "batch1 = next(iterator)\n",
        "batch1[0].shape"
      ],
      "metadata": {
        "id": "yG7pYdSRuuUF",
        "outputId": "3277f6cf-b602-44df-d16d-7e645c79f347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch normalization is done over the C dimension, so it will compute statistics\n",
        "using the remaining dimensions—N, H, and `W (axis=[0, 2, 3])`—representing all\n",
        "pixels of a given channel from every image in the mini-batch.\n",
        "\n",
        "The `nn.BatchNorm2d` layer has the same arguments as its one-dimension\n",
        "counterpart, but its num_features argument must match the number of channels\n",
        "of the input instead:"
      ],
      "metadata": {
        "id": "udWxD4Qpv3nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_normalizer = nn.BatchNorm2d(num_features=3, affine=False, momentum=None)\n",
        "normed1 = batch_normalizer(batch1[0])\n",
        "normed1.mean(axis=[0, 2, 3]), normed1.var(axis=[0, 2, 3], unbiased=False)"
      ],
      "metadata": {
        "id": "cynZAsK0wB0W",
        "outputId": "a5dfb13f-af88-4435-b761-814a839d3870",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2.3283e-08, -2.3693e-08,  8.8960e-08]),\n",
              " tensor([0.9999, 0.9999, 0.9999]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, each channel in the output has its pixel values with zero mean and\n",
        "unit standard deviation."
      ],
      "metadata": {
        "id": "MWrfmpoNwyUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary"
      ],
      "metadata": {
        "id": "1s-HUgD1x6w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It goes over a lot\n",
        "of information while only scratching the surface of this topic. So, I am organizing a\n",
        "small summary of the main points we’ve addressed:\n",
        "\n",
        "* During training time, batch normalization computes statistics (mean and\n",
        "variance) for each individual mini-batch and uses these statistics to produce\n",
        "standardized outputs.\n",
        "\n",
        "* The fluctuations in the statistics from one mini-batch to the next introduce\n",
        "randomness into the process and thus have a regularizing effect.\n",
        "\n",
        "* Due to the regularizing effect of batch normalization, it may not work well if combined with other regularization techniques (like dropout).\n",
        "\n",
        "* During evaluation time, batch normalization uses a (smoothed) average of the\n",
        "statistics computed during training.\n",
        "\n",
        "* Its original motivation was to address the so-called internal covariate shift by\n",
        "producing similar distributions across different layers, but it was later found\n",
        "that it actually improves model training by making the loss surface smoother.\n",
        "\n",
        "* The batch normalization may be placed either before or after the activation\n",
        "function; there is no \"right\" or \"wrong\" way.\n",
        "\n",
        "* The layer preceding the batch normalization layer should have its bias=False\n",
        "set to avoid useless computation.\n",
        "\n",
        "* Even though batch normalization works for a different reason than initially\n",
        "thought, addressing the internal covariate shift may still bring benefits, like\n",
        "solving the vanishing gradients problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "s0yBu6Hix7tc"
      }
    }
  ]
}