{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMf6O8hW2dhuJDT9LXJomP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe693ef7bbef4e7a88344988972efefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df43c9dd1eba44b7b193d5c131004cf7",
              "IPY_MODEL_65a9426972404459840db2d40098749c",
              "IPY_MODEL_30ad82d20c304dfd966acb876fa8c2aa"
            ],
            "layout": "IPY_MODEL_8778a2b3877c4c8bada753e208110f57"
          }
        },
        "df43c9dd1eba44b7b193d5c131004cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca6442345ee4004a8febcae0aebb3a3",
            "placeholder": "​",
            "style": "IPY_MODEL_98ac2cb045ad403c957604c5d7146b2d",
            "value": "Map: 100%"
          }
        },
        "65a9426972404459840db2d40098749c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f2f198c7934d6a82b39c73fdf2d6e5",
            "max": 3852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ad2c83aed314b8599804a6d319bdf00",
            "value": 3852
          }
        },
        "30ad82d20c304dfd966acb876fa8c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32b360a716d040a2ab7cb0c6ed104561",
            "placeholder": "​",
            "style": "IPY_MODEL_84a8726da8264b8dbb5aea3af3999bfe",
            "value": " 3852/3852 [00:00&lt;00:00, 8550.46 examples/s]"
          }
        },
        "8778a2b3877c4c8bada753e208110f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca6442345ee4004a8febcae0aebb3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ac2cb045ad403c957604c5d7146b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46f2f198c7934d6a82b39c73fdf2d6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad2c83aed314b8599804a6d319bdf00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32b360a716d040a2ab7cb0c6ed104561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a8726da8264b8dbb5aea3af3999bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/07_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word Embeddings"
      ],
      "metadata": {
        "id": "I_fJ4_FUlY0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll start our NLP journey by following the steps of Alice and Dorothy, from\n",
        "[Alice’s Adventures in Wonderland](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/1476) by Lewis Carroll and [The Wonderful Wizard of Oz](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/1740) by L. Frank Baum.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/alice_dorothy.png?raw=1)\n",
        "\n",
        "*Left: \"Alice and the Baby Pig\" illustration by John Tenniel's, from \"Alice's Adventure's in Wonderland\" (1865).*\n",
        "\n",
        "*Right: \"Dorothy meets the Cowardly Lion\" illustration by W.W. Denslow, from \"The Wonderful Wizard of Oz\" (1900)*"
      ],
      "metadata": {
        "id": "6S3AN5ZklZkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "y_fsZxO6mSi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# # UPDATED\n",
        "# ###########################################################\n",
        "!pip install gensim==4.3.1\n",
        "# # The library has been archived and won't be used anymore\n",
        "# # # !pip install allennlp==0.9.0\n",
        "#!pip install flair==0.12.2\n",
        "#!pip install torchvision==0.15.1\n",
        "# # # HuggingFace\n",
        "!pip install transformers==4.32.0\n",
        "!pip install datasets==2.14.4\n",
        "# ###########################################################\n",
        "!pip -q install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "bPp9LPHbWch9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)\n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter11()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter11 import *"
      ],
      "metadata": {
        "id": "4KaJRDNLmTq_",
        "outputId": "894eba27-2c33-4b16-b4b0-0fc494451523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import errno\n",
        "import requests\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from operator import itemgetter\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "from data_generation.nlp import ALICE_URL, WIZARD_URL, download_text\n",
        "from stepbystep.v4 import StepByStep\n",
        "# These are the classes we built in Chapter 10\n",
        "from seq2seq import *\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "i9pPl_87mbqd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "lrnHpAEYgrSS",
        "outputId": "aa605dd5-6941-4e89-a11f-c5eb0781662f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora, downloader\n",
        "from gensim.parsing.preprocessing import *\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "dEQBv2ddXGS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Split\n",
        "from transformers import (\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BertModel, BertTokenizer, BertForSequenceClassification,\n",
        "    DistilBertModel, DistilBertTokenizer,\n",
        "    DistilBertForSequenceClassification,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModel, AutoTokenizer, AutoModelForCausalLM,\n",
        "    Trainer, TrainingArguments, pipeline, TextClassificationPipeline\n",
        ")\n",
        "from transformers.pipelines import SUPPORTED_TASKS"
      ],
      "metadata": {
        "id": "w1HKtpREXdlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading Books"
      ],
      "metadata": {
        "id": "VGxz6kEmX3ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data"
      ],
      "metadata": {
        "id": "4hr1Jm9kK9DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's download data\n",
        "HOME_DIR = \"data\"\n",
        "download_text(ALICE_URL, HOME_DIR)\n",
        "download_text(WIZARD_URL, HOME_DIR)"
      ],
      "metadata": {
        "id": "eTXbiieBX4Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the downloaded data\n",
        "#!cat data/alice28-1476.txt"
      ],
      "metadata": {
        "id": "45chINE_YYtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cat data/wizoz10-1740.txt"
      ],
      "metadata": {
        "id": "uM-tdJNRZcnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to remove these additions to the original texts:"
      ],
      "metadata": {
        "id": "msne6vRcZ14Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alice_file = os.path.join(HOME_DIR, \"alice28-1476.txt\")\n",
        "with open(alice_file, \"r\") as f:\n",
        "  # The actual texts of the books are contained between lines 105 and 3703\n",
        "  alice_text = \"\".join(f.readlines()[104:3704])\n",
        "\n",
        "wizard_file = os.path.join(HOME_DIR, \"wizoz10-1740.txt\")\n",
        "with open(wizard_file, \"r\") as f:\n",
        "  # The actual texts of the books are contained between lines 309 and 5099\n",
        "  wizard_text = \"\".join(f.readlines()[310:5100])"
      ],
      "metadata": {
        "id": "8z29BFQwZx4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(alice_text[:500])\n",
        "print(\"\\n\", \"#\"*70, \"\\n\")\n",
        "print(wizard_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNZmtkHNahrp",
        "outputId": "91f2a02b-3ba6-464c-ccc1-d88450e2be3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 2.8\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "                      Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "  Alice was beginning to get very tired of sitting by her sister\n",
            "on the bank, and of having nothing to do:  once or twice she had\n",
            "peeped into the book her sister was reading, but it had no\n",
            "pictures or conversations in it, `and what is the use of a book,'\n",
            "thought Alice `w\n",
            "\n",
            " ###################################################################### \n",
            "\n",
            "                    THE WONDERFUL WIZARD OF OZ\n",
            "\n",
            "\n",
            "                          1.  The Cyclone\n",
            "\n",
            "\n",
            "    Dorothy lived in the midst of the great Kansas prairies, with\n",
            "Uncle Henry, who was a farmer, and Aunt Em, who was the farmer's\n",
            "wife.  Their house was small, for the lumber to build it had to be\n",
            "carried by wagon many miles.  There were four walls, a floor and a\n",
            "roof, which made one room; and this room contained a rusty looking\n",
            "cookstove, a cupboard for the dishes, a table, three or four\n",
            "chairs, and th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can partially automate the removal of the extra lines by setting the real start and end lines of each text in a configuration file."
      ],
      "metadata": {
        "id": "zS5E4dECbotZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_cfg = \"\"\"fname,start,end\n",
        "alice28-1476.txt,104,3704\n",
        "wizoz10-1740.txt,310,5100\"\"\"\n",
        "bytes_written = open(os.path.join(HOME_DIR, 'lines.cfg'), 'w').write(text_cfg)"
      ],
      "metadata": {
        "id": "ayc3piYsbutL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentence Tokenization"
      ],
      "metadata": {
        "id": "Bk4m73rMb0gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A token is a piece of a text, and to tokenize a text means to split\n",
        "it into pieces; that is, into a list of tokens.\n",
        "\n",
        "The most common kind of piece is a word.\n",
        "\n",
        "So, tokenizing a text usually means to\n",
        "split it into words using the white space as a separator."
      ],
      "metadata": {
        "id": "6w5mJGOFb1Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I'm following the white rabbit\"\n",
        "tokens = sentence.split(\" \")\n",
        "tokens"
      ],
      "metadata": {
        "id": "oFsqtdFkenM-",
        "outputId": "0e208cd5-ba4b-4e0a-9e43-a5d5b4d8550b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I'm\", 'following', 'the', 'white', 'rabbit']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do sentence tokenization, which means to split a text into its sentences."
      ],
      "metadata": {
        "id": "3WGtMb-Qg2Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_alice = sent_tokenize(alice_text)\n",
        "corpus_wizard = sent_tokenize(wizard_text)\n",
        "\n",
        "len(corpus_alice), (len(corpus_wizard))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg1Kg0Ung7aq",
        "outputId": "4ef522aa-29c0-4962-f786-2120f0c17fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1612, 2240)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check one sentence from the first corpus of text."
      ],
      "metadata": {
        "id": "1qSQVckXh3aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_alice[2]"
      ],
      "metadata": {
        "id": "mWQQFsanh4GS",
        "outputId": "0e13c615-9c06-4c14-8d02-ff56b60ca7e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There was nothing so VERY remarkable in that; nor did Alice\\nthink it so VERY much out of the way to hear the Rabbit say to\\nitself, `Oh dear!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check one sentence from the second corpus of text."
      ],
      "metadata": {
        "id": "RIGvTC9-iFwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_wizard[30]"
      ],
      "metadata": {
        "id": "ojBtgVa1iGSs",
        "outputId": "6011e633-673e-4f74-d7eb-be576ebd0e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"There\\'s a cyclone coming, Em,\" he called to his wife.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset is going to be a collection of CSV files, one file for each book, with each\n",
        "CSV file containing one sentence per line.\n",
        "\n",
        "Therefore, we need to:\n",
        "\n",
        "* clean the line breaks to make sure each sentence is on one line only;\n",
        "* define an appropriate quote char to \"wrap\" the sentence such that the original commas and semicolons in the original text do not get misinterpreted as separation chars of the CSV file; and\n",
        "* add a second column to the CSV file to\n",
        "identify the original source of the sentence since we’ll be concatenating, and\n",
        "shuffling the sentences before training a model on our corpora.\n",
        "\n",
        "The sentence above should end up looking like this:\n",
        "```log\n",
        "\\\"There's a cyclone coming, Em,\" he called to his wife.\\,wizoz10-1740.txt\n",
        "```\n",
        "\n",
        "The function below does the grunt work of cleaning, splitting, and saving the\n",
        "sentences to a CSV file for us:"
      ],
      "metadata": {
        "id": "6_QMReIwkcaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_tokenize(source, quote_char=\"\\\\\", sep_char=\",\", include_header=True, include_source=True, extensions=(\"txt\"), **kwargs):\n",
        "  # If source is a folder, goes through all files inside it that match the desired extensions ('txt' by default)\n",
        "  if os.path.isdir(source):\n",
        "    filenames = [f for f in os.listdir(source) if os.path.isfile(os.path.join(source, f)) and os.path.splitext(f)[1][1:] in extensions]\n",
        "  elif isinstance(source, str):\n",
        "    filenames = [source]\n",
        "\n",
        "  # If there is a configuration file, builds a dictionary with the corresponding start and end lines of each text file\n",
        "  config_file = os.path.join(source, \"lines.cfg\")\n",
        "  config = {}\n",
        "  if os.path.exists(config_file):\n",
        "    with open(config_file, \"r\") as f:\n",
        "      rows = f.readlines()\n",
        "    for r in rows[1:]:\n",
        "      fname, start, end = r.strip().split(\",\")\n",
        "      config.update({fname: (int(start), int(end))})\n",
        "\n",
        "  new_fnames = []\n",
        "  # For each file of text\n",
        "  for fname in filenames:\n",
        "    # If there's a start and end line for that file, use it\n",
        "    try:\n",
        "        start, end = config[fname]\n",
        "    except KeyError:\n",
        "        start = None\n",
        "        end = None\n",
        "\n",
        "    # Opens the file, slices the configures lines (if any)\n",
        "    # cleans line breaks and uses the sentence tokenizer\n",
        "    with open(os.path.join(source, fname), 'r') as f:\n",
        "        contents = (''.join(f.readlines()[slice(start, end, None)]).replace('\\n', ' ').replace('\\r', ''))\n",
        "    corpus = sent_tokenize(contents, **kwargs)\n",
        "\n",
        "    # Builds a CSV file containing tokenized sentences\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    new_fname = f'{base}.sent.csv'\n",
        "    new_fname = os.path.join(source, new_fname)\n",
        "    with open(new_fname, 'w') as f:\n",
        "        # Header of the file\n",
        "        if include_header:\n",
        "            if include_source:\n",
        "                f.write('sentence,source\\n')\n",
        "            else:\n",
        "                f.write('sentence\\n')\n",
        "        # Writes one line for each sentence\n",
        "        for sentence in corpus:\n",
        "            if include_source:\n",
        "                f.write(f'{quote_char}{sentence}{quote_char}{sep_char}{fname}\\n')\n",
        "            else:\n",
        "                f.write(f'{quote_char}{sentence}{quote_char}\\n')\n",
        "    new_fnames.append(new_fname)\n",
        "\n",
        "  # Returns list of the newly generated CSV files\n",
        "  return sorted(new_fnames)"
      ],
      "metadata": {
        "id": "2BxVWK0Rk21Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_fnames = sentence_tokenize(HOME_DIR)\n",
        "new_fnames"
      ],
      "metadata": {
        "id": "95M-z4GlFTgy",
        "outputId": "68efb64d-c0dc-4c0a-8630-72c69304d1d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/alice28-1476.sent.csv', 'data/wizoz10-1740.sent.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spacy sentence tokenization"
      ],
      "metadata": {
        "id": "CAFblQB6MEge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "sentences = []\n",
        "for doc in nlp.pipe(corpus_alice):\n",
        "  sentences.extend(sent.text for sent in doc.sents)\n",
        "\n",
        "len(sentences), sentences[2]"
      ],
      "metadata": {
        "id": "cUlNTST_SUmH",
        "outputId": "eb53b990-ca19-4cc0-e76c-6555d50d2f08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1615,\n",
              " 'There was nothing so VERY remarkable in that; nor did Alice\\nthink it so VERY much out of the way to hear the Rabbit say to\\nitself, `Oh dear!')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HuggingFace’s Dataset"
      ],
      "metadata": {
        "id": "gMQtKHL5VMvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load from local files using HuggingFace\n",
        "dataset = load_dataset(path=\"csv\", data_files=new_fnames, quotechar=\"\\\\\", split=Split.TRAIN)"
      ],
      "metadata": {
        "id": "wDWkbp0-VNmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see attributes, like features, num_columns, and shape\n",
        "dataset.features, dataset.num_columns, dataset.shape"
      ],
      "metadata": {
        "id": "cUGmh8d9upmR",
        "outputId": "d592e608-8f98-4898-8a05-fb4250410448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'sentence': Value(dtype='string', id=None),\n",
              "  'source': Value(dtype='string', id=None)},\n",
              " 2,\n",
              " (3852, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "id": "qbcE5hb2u7Rp",
        "outputId": "f05747df-c1c7-450f-f6cd-c460fdb3dabe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, `Oh dear!',\n",
              " 'source': 'alice28-1476.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"sentence\"][:3]"
      ],
      "metadata": {
        "id": "HwwhVPVhvL8-",
        "outputId": "edee1f14-5ed0-4f2a-8e26-416d2ea69daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"                ALICE'S ADVENTURES IN WONDERLAND                            Lewis Carroll                 THE MILLENNIUM FULCRUM EDITION 2.8                                 CHAPTER I                        Down the Rabbit-Hole     Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do:  once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\",\n",
              " 'So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.',\n",
              " 'There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, `Oh dear!']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"source\"][:3]"
      ],
      "metadata": {
        "id": "-jLahzGpvB4m",
        "outputId": "1faca640-322e-40e1-a2b9-0e2a0dab811d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alice28-1476.txt', 'alice28-1476.txt', 'alice28-1476.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the unique sources\n",
        "dataset.unique(\"source\")"
      ],
      "metadata": {
        "id": "JtCGLGaVGxI1",
        "outputId": "72405468-7ce4-48de-a2d4-782174b858e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alice28-1476.txt', 'wizoz10-1740.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create new columns\n",
        "def is_alice_label(row):\n",
        "  is_alice = int(row[\"source\"] == \"alice28-1476.txt\")\n",
        "  return {\"label\": is_alice}"
      ],
      "metadata": {
        "id": "qqTGqoNzHBUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(is_alice_label)"
      ],
      "metadata": {
        "id": "yO6tDsIrHUHZ",
        "outputId": "7801d5cf-5472-4f4c-89bd-f7068dbd417f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fe693ef7bbef4e7a88344988972efefe",
            "df43c9dd1eba44b7b193d5c131004cf7",
            "65a9426972404459840db2d40098749c",
            "30ad82d20c304dfd966acb876fa8c2aa",
            "8778a2b3877c4c8bada753e208110f57",
            "cca6442345ee4004a8febcae0aebb3a3",
            "98ac2cb045ad403c957604c5d7146b2d",
            "46f2f198c7934d6a82b39c73fdf2d6e5",
            "8ad2c83aed314b8599804a6d319bdf00",
            "32b360a716d040a2ab7cb0c6ed104561",
            "84a8726da8264b8dbb5aea3af3999bfe"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3852 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe693ef7bbef4e7a88344988972efefe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "id": "kW04h9hFHw8f",
        "outputId": "d9427699-4b2a-4cd6-8761-3b300f07432a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 'There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, `Oh dear!',\n",
              " 'source': 'alice28-1476.txt',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can finally shuffle the dataset and split it into training and test sets\n",
        "shuffled_dataset = dataset.shuffle(seed=42)\n",
        "split_dataset = shuffled_dataset.train_test_split(test_size=0.2)\n",
        "split_dataset"
      ],
      "metadata": {
        "id": "kTby8KlRQtDQ",
        "outputId": "e09470cd-3bfa-41b9-8cec-75e83485765b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'source', 'label'],\n",
              "        num_rows: 3081\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'source', 'label'],\n",
              "        num_rows: 771\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]"
      ],
      "metadata": {
        "id": "pNKEmyDIRD32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "_fb8D7pYRQkW",
        "outputId": "1e1b7af1-0c38-4bb8-e821-78ccc47c8f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': '\"And back to Kansas?\"', 'source': 'wizoz10-1740.txt', 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vocabulary"
      ],
      "metadata": {
        "id": "BovMzxtw2vO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = train_dataset[\"sentence\"]\n",
        "tokens = [simple_preprocess(sent) for sent in sentences]"
      ],
      "metadata": {
        "id": "BzjO7lLW2v7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a vocabulary\n",
        "dictionary = corpora.Dictionary(tokens)\n",
        "print(dictionary)"
      ],
      "metadata": {
        "id": "0ZDoBi5422Sk",
        "outputId": "55c703e9-798e-423a-a274-6dbc3972f17b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary<3677 unique tokens: ['and', 'back', 'kansas', 'to', 'as']...>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = list(dictionary.token2id.keys())\n",
        "vocab[:5]"
      ],
      "metadata": {
        "id": "VRc6jXRY25Zb",
        "outputId": "f74b95a6-2a53-4971-904d-c1f5e40737a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'back', 'kansas', 'to', 'as']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add special token to unknown word\n",
        "special_tokens = {\n",
        "    \"[PAD]\": 0,\n",
        "    \"[UNK]\": 1\n",
        "}\n",
        "\n",
        "dictionary.patch_with_special_tokens(special_tokens)"
      ],
      "metadata": {
        "id": "COPYreo229tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rare_ids(dictionary, min_freq):\n",
        "  rare_ids = [t[0] for t in dictionary.cfs.items() if t[1] < min_freq]\n",
        "  return rare_ids"
      ],
      "metadata": {
        "id": "SBiXOr4H3AjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_vocab(sentences, folder=None, special_tokens=None, vocab_size=None, min_freq=None):\n",
        "\n",
        "  if folder is not None:\n",
        "    if not os.path.exists(folder):\n",
        "      os.mkdir(folder)\n",
        "\n",
        "  # tokenizes the sentences and create a Dictionary\n",
        "  tokens = [simple_preprocess(sent) for sent in sentences]\n",
        "  dictionary = corpora.Dictionary(tokens)\n",
        "\n",
        "  # keeps only the most frequent words (vocab size)\n",
        "  if vocab_size is not None:\n",
        "    dictionary.filter_extremes(keep_n=vocab_size)\n",
        "\n",
        "  # removes rare words (in case the vocab size still includes words with low frequency)\n",
        "  if min_freq is not None:\n",
        "    rare_tokens = get_rare_ids(dictionary, min_freq)\n",
        "    dictionary.filter_tokens(bad_ids=rare_tokens)\n",
        "\n",
        "  # gets the whole list of tokens and frequencies\n",
        "  items = dictionary.cfs.items()\n",
        "\n",
        "  # sorts the tokens in descending order\n",
        "  words = [dictionary[t[0]] for t in sorted(dictionary.cfs.items(), key=lambda t: -t[1])]\n",
        "\n",
        "  # prepends special tokens, if any\n",
        "  if special_tokens is not None:\n",
        "    to_add = []\n",
        "    for special_token in special_tokens:\n",
        "      if special_token not in words:\n",
        "        to_add.append(special_token)\n",
        "    words = to_add + words\n",
        "\n",
        "  with open(os.path.join(folder, \"vocab.txt\"), \"w\") as f:\n",
        "    for word in words:\n",
        "      f.write(f\"{word}\\n\")"
      ],
      "metadata": {
        "id": "bXogiiHo3BWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_vocab(\n",
        "    train_dataset[\"sentence\"],\n",
        "    \"our_vocab/\",\n",
        "    special_tokens=['[PAD]', '[UNK]', '[SEP]', '[CLS]', '[MASK]'],\n",
        "    min_freq=2\n",
        ")"
      ],
      "metadata": {
        "id": "AEjeVtJY3DmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HugginFace's Tokenizer"
      ],
      "metadata": {
        "id": "2O6_LQhwM5P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, before loading a pre-trained tokenizer, let’s create our own tokenizer using our\n",
        "own vocabulary."
      ],
      "metadata": {
        "id": "l6OsR5AQ3L5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer(\"our_vocab/vocab.txt\")"
      ],
      "metadata": {
        "id": "zyTwT20d3LZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s apply our tokenizer to our dataset of sentences, padding them and\n",
        "returning PyTorch tensors:"
      ],
      "metadata": {
        "id": "QhUvETeOAReV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenizer(dataset[\"sentence\"],\n",
        "                              padding=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              max_length=50,\n",
        "                              truncation=True)\n",
        "tokenized_dataset[\"input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwkfzV3AASH2",
        "outputId": "64a40c52-9284-4024-ea90-78231386e11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   3,   26,    1,  ...,  103,  867,    2],\n",
              "        [   3,   24,   10,  ..., 1304,    5,    2],\n",
              "        [   3,   50,   12,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   3,    1,    6,  ...,    0,    0,    0],\n",
              "        [   3,    6,  130,  ...,    0,    0,    0],\n",
              "        [   3,    1,    1,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can we feed the input_ids to BERT and watch the magic happen?\n",
        "\n",
        "BERT is actually using vectors to represent the words. The\n",
        "token IDs we’ll be sending it are simply the indices of an enormous lookup table.\n",
        "\n",
        "That lookup table has a very nice name: **Word Embeddings**.\n",
        "\n",
        "Each row of the lookup table corresponds to a different token, and each row is\n",
        "represented by a vector. The size of the vectors is the dimensionality of the\n",
        "embedding."
      ],
      "metadata": {
        "id": "3m5yLhzHMCbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text representation"
      ],
      "metadata": {
        "id": "vbGRfN2lSckj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before getting to the actual word embeddings, let’s start with the basics and text representations."
      ],
      "metadata": {
        "id": "I8Q8t1InYQCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###One-Hot Encoding"
      ],
      "metadata": {
        "id": "EG_k8wCPSeHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea behind OHE is quite simple: Each unique token (word) is represented by a vector full of zeros except for one position, which corresponds to the token’s index.\n",
        "\n",
        "Let’s see one-hot encoding representations for 5 words.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/ohe1.png?raw=1)\n",
        "\n",
        "But there are 3,704 unique tokens in our text\n",
        "corpora (not counting the added special tokens), so the OHE actually looks like this.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/ohe2.png?raw=1)\n",
        "\n",
        "That’s quite a large and sparse vector, right?\n",
        "\n",
        "Clearly, this isn’t very practical.\n",
        "\n",
        "Nonetheless, the sparse vectors produced by the one-hot\n",
        "encoding are the basis of a fairly basic NLP model: the bag-of-words (BoW)."
      ],
      "metadata": {
        "id": "_n5iKKJMZTJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bag-of-Words"
      ],
      "metadata": {
        "id": "X8uH8jRzaMQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bag-of-words model is literally a bag of words: It simply sums up the\n",
        "corresponding OHE vectors, completely disregarding any underlying structure or\n",
        "relationships between the words."
      ],
      "metadata": {
        "id": "S9CzuIXYaNHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"the white rabbit is a rabbit\"\n",
        "bow_tokens = simple_preprocess(sentence)\n",
        "bow_tokens"
      ],
      "metadata": {
        "id": "pAHmAtcCUgVI",
        "outputId": "98fce592-8221-4f25-e717-de0cb0a175c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', 'white', 'rabbit', 'is', 'rabbit']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = dictionary.doc2bow(bow_tokens)\n",
        "bow"
      ],
      "metadata": {
        "id": "exjRsktyvC9A",
        "outputId": "4189dc23-5a59-4b0f-e22b-5a640f9ce990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(18, 1), (35, 1), (631, 2), (1077, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Representing words using\n",
        "one-hot-encoded vectors also presents severe limitations: Not only do the vectors become more and more sparse (that is, have more zeros in them) as the vocabulary\n",
        "grows, but also every word is orthogonal to all the other words.\n",
        "\n",
        "If we use one-hot-encoded vectors to represent words, we’re\n",
        "basically saying that no two words are similar to each other."
      ],
      "metadata": {
        "id": "6NzPynsAwQe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word Embeddings"
      ],
      "metadata": {
        "id": "TLl6U27awH-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec has two model architectures: continuous bag-of-words (CBoW) and skip-gram (SG)."
      ],
      "metadata": {
        "id": "E5t85Yn3rrZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word2Vec"
      ],
      "metadata": {
        "id": "JeqPATo1rrjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.linear = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    embeddings = self.embedding(X)\n",
        "    bow = embeddings.mean(dim=1)\n",
        "    logits = self.linear(bow)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "FBv34YVcvMmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If our vocabulary had only five words (\"the,\"\n",
        "\"small,\" \"is,\" \"barking,\" and \"dog\"), we could try to represent each word with an\n",
        "embedding of three dimensions.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/cbow.png?raw=1)"
      ],
      "metadata": {
        "id": "HHzK_2IGqIEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "dummy_cbow = CBOW(vocab_size=5, embedding_size=3)\n",
        "dummy_cbow.embedding.state_dict()"
      ],
      "metadata": {
        "id": "ofRQGAxWtBSE",
        "outputId": "68e534cd-0f73-49d2-bf53-4254909b525c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 0.3367,  0.1288,  0.2345],\n",
              "                      [ 0.2303, -1.1229, -0.1863],\n",
              "                      [ 2.2082, -0.6380,  0.4617],\n",
              "                      [ 0.2674,  0.5349,  0.8094],\n",
              "                      [ 1.1103, -1.6898, -0.9890]]))])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/w2v_embed.png?raw=1)\n",
        "\n",
        "PyTorch’s `nn.Embedding` layer is a large lookup table.To actually\n",
        "retrieve the values, we need to call the embedding layer with a list of token\n",
        "indices, and it will return the corresponding rows of the table.\n",
        "\n",
        "Let's retrieve the embeddings for the tokens \"is\" and \"barking\" using\n",
        "their corresponding indices (two and three):"
      ],
      "metadata": {
        "id": "doZhP1fCtwJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens: ['is', 'barking']\n",
        "dummy_cbow.embedding(torch.as_tensor([2, 3]))"
      ],
      "metadata": {
        "id": "e7sbAH_nuNTg",
        "outputId": "1eb35f71-bf9a-4e43-c631-b1686962d811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2082, -0.6380,  0.4617],\n",
              "        [ 0.2674,  0.5349,  0.8094]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That’s why the main job of the tokenizer is to transform a\n",
        "sentence into a list of token IDs. That list is used as an input to\n",
        "the embedding layer, and from then on, the tokens are\n",
        "represented by dense vectors.\n",
        "\n",
        "In our former example, \"dog\" was the central word and the other four words were the context words:"
      ],
      "metadata": {
        "id": "j3L29dYbu6Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_vocab = [\"the\", \"small\", \"is\", \"barking\", \"dog\"]\n",
        "context_words = [\"the\", \"small\", \"is\", \"barking\"]\n",
        "target_words = [\"dog\"]"
      ],
      "metadata": {
        "id": "U3tjMbAcuYYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s pretend that we tokenized the words and got their corresponding\n",
        "indices:"
      ],
      "metadata": {
        "id": "C78n0OjawBra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_context = torch.as_tensor([[0, 1, 2, 3]]).long()\n",
        "batch_target = torch.as_tensor([[4]]).long()"
      ],
      "metadata": {
        "id": "mwSL8FCnv9_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In its very first training step, the model would compute the continuous bag-ofwords\n",
        "for the inputs by averaging the corresponding embeddings.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/w2v_cbow.png?raw=1)"
      ],
      "metadata": {
        "id": "3hhXHBRZwwC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_features = dummy_cbow.embedding(batch_context).mean(dim=1)\n",
        "cbow_features"
      ],
      "metadata": {
        "id": "mmUjvFuNw2EN",
        "outputId": "70326a51-ee5a-4200-aa00-0a8a687dd3dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7606, -0.2743,  0.3298]], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bag-of-words has three dimensions, which are the features used to compute\n",
        "the logits for our multiclass classification problem.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/w2v_logits.png?raw=1)"
      ],
      "metadata": {
        "id": "nm9VtzAhyzAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = dummy_cbow.linear(cbow_features)\n",
        "logits"
      ],
      "metadata": {
        "id": "-XIRiwTAy3bD",
        "outputId": "3b7105e5-1187-49fe-d5fa-48d9d17bde8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3542,  0.6937, -0.2028, -0.5873,  0.2099]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The largest logit corresponds to the word \"small\" (class index one), so that would be\n",
        "the predicted central word: \"The small small is barking.\" The prediction is obviously\n",
        "wrong, but, then again, that’s still a randomly initialized model.\n",
        "\n",
        "Given a large enough dataset of context and target words, we could train the CBOW model above using an `nn.CrossEntropyLoss()` to learn actual word embeddings."
      ],
      "metadata": {
        "id": "H8V5V4K3zSVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What Is an Embedding"
      ],
      "metadata": {
        "id": "DJhFvgNCfsCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An embedding is a representation of an entity (a word, in our case), and each of its\n",
        "dimensions can be seen as an attribute or feature.\n",
        "\n",
        "Let’s forget about words for a moment and talk about restaurants instead. We can\n",
        "rate restaurants over many different dimensions, like food, price, and service, for\n",
        "example.\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/rest_discrete.png?raw=1)"
      ],
      "metadata": {
        "id": "Q2FQLHQFfsyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although it’s fairly obvious to spot the similarities and differences among the restaurants in the table above, it wouldn’t be so easy to spot them if there were dozens of dimensions to compare.\n",
        "\n",
        "Besides, it would be very hard to objectively\n",
        "measure the similarity between any two restaurants using categorical scales like that.\n",
        "\n",
        "What if we use continuous scales instead?\n",
        "\n",
        "Perfect! Let’s do that and assign values in the range [-1, 1], from very bad (-1) to\n",
        "very good (1), or from very expensive (-1) to very cheap (1).\n",
        "\n",
        "\n",
        "![](https://github.com/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/Part-III-NLP/images/rest_continuous.png?raw=1)"
      ],
      "metadata": {
        "id": "UwC-93Maf8D9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values are like \"restaurant embeddings\" :-)\n",
        "\n",
        "Well, they’re not quite embeddings, but at least we can use cosine similarity to find\n",
        "out how similar to each other two restaurants are:"
      ],
      "metadata": {
        "id": "xbaY_Ze2pqVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = torch.as_tensor([\n",
        "    [.7, -.4, .7],\n",
        "    [.3, .7, -.5],\n",
        "    [.9, -.55, .8],\n",
        "    [-.3, .8, .34]\n",
        "]).float()\n",
        "\n",
        "sims = torch.zeros(4, 4)\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    sims[i, j] = F.cosine_similarity(ratings[i], ratings[j], dim=0)\n",
        "sims"
      ],
      "metadata": {
        "id": "vyMESL5NzB49",
        "outputId": "5bcbfd35-ab33-4755-ebc9-6df67401306b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000, -0.4318,  0.9976, -0.2974],\n",
              "        [-0.4318,  1.0000, -0.4270,  0.3581],\n",
              "        [ 0.9976, -0.4270,  1.0000, -0.3598],\n",
              "        [-0.2974,  0.3581, -0.3598,  1.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we can compute the cosine similarity between two restaurants now, the\n",
        "values in the table above are not real embeddings. It was only an example that\n",
        "illustrates well the concept of embedding dimensions as attributes."
      ],
      "metadata": {
        "id": "ZFEHSijRuDz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-trained Word2Vec"
      ],
      "metadata": {
        "id": "S-QTHiccuJX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SRZ0T_qDuKXf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQc4_5pkt8Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}