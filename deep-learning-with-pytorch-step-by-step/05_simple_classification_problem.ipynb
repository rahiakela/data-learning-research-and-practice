{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGR+L3wuMiY/fzq/vV/84l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/05_simple_classification_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Classification Problem"
      ],
      "metadata": {
        "id": "eB520cKUnVhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a classification problem, we’re trying to predict which class a data\n",
        "point belongs to.\n",
        "\n",
        "Let’s say we have two classes of points: they are either red or blue. These are the\n",
        "labels `(y)` of the points. \n",
        "\n",
        "Sure enough, we need to assign numeric values to them. We\n",
        "could assign zero to red and one to blue. The class associated with zero is the\n",
        "negative class, while one corresponds to the positive class.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5wTQQbxanWY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "a60l9BX2oE0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter3()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter3 import *"
      ],
      "metadata": {
        "id": "pgGfHWV5oZqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rahiakela/deep-learning-research-and-practice/raw/main/deep-learning-with-pytorch-step-by-step/networks/linear_regression.py"
      ],
      "metadata": {
        "id": "W84boD_8VMQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
        "\n",
        "from linear_regression import LinearRegression"
      ],
      "metadata": {
        "id": "TUEV99bdogt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Generation"
      ],
      "metadata": {
        "id": "IS1-btItoZ1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start generating some synthetic data: we start with a vector of `100 (N)` points\n",
        "for our feature `(x)` and create our labels `(y)` using `b = 1, w = 2`, and some Gaussian noise (epsilon)."
      ],
      "metadata": {
        "id": "U6ucNoo7oawj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "# Data Generation\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (.1 * np.random.rand(N, 1))\n",
        "y = true_b + true_w * x + epsilon"
      ],
      "metadata": {
        "id": "7i8oVtQPpATN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's split our synthetic data into train and validation sets, shuffling the array\n",
        "of indexes and using the first 80 shuffled points for training."
      ],
      "metadata": {
        "id": "6Bg1PAVnpncx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles the indices\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:int(N * .8)]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[int(N * .8): ]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "6c8vMI5Kpn3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Model Training"
      ],
      "metadata": {
        "id": "ARz968upHBAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let's consider again with our previous important question:\n",
        "\n",
        "Would the code inside the training loop change if we were using a\n",
        "different optimizer, or loss, or even model?\n",
        "\n",
        "The answer: NO.\n",
        "\n",
        "The model training involves looping over the four gradient descent steps (or one\n",
        "training step, for that matter) and those are always the same, regardless of which model, loss or optimizer we use.\n",
        "\n",
        "Let’s take a look at the code once again:"
      ],
      "metadata": {
        "id": "v1jAx0vDHBtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preparation"
      ],
      "metadata": {
        "id": "tRX_F3wmRFXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After generating our\n",
        "data points, the only preparation step performed so far was\n",
        "transforming Numpy arrays into PyTorch tensors."
      ],
      "metadata": {
        "id": "xzol68u0RSOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v0.py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors and then we send them to the chosen device\n",
        "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
      ],
      "metadata": {
        "id": "x-rPHa6LRWuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v0.py"
      ],
      "metadata": {
        "id": "cBF7SEYSTI_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we’re using the -i option, it works exactly as if we had copied the code from\n",
        "the files into a cell and executed it."
      ],
      "metadata": {
        "id": "kg6FC-O9TZUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Configuration"
      ],
      "metadata": {
        "id": "4jQqdmSYTaHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of organizing our code, we’ll include the following elements in the\n",
        "model configuration part:\n",
        "\n",
        "* a model\n",
        "* a loss function\n",
        "* an optimizer"
      ],
      "metadata": {
        "id": "wGBV8Zb_TcVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v0.py\n",
        "\n",
        "# This is redundant now, but it won't be when we introduce Datasets...\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")"
      ],
      "metadata": {
        "id": "WeoEaGC9Tzxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v0.py"
      ],
      "metadata": {
        "id": "m_h5sDaTewxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Training"
      ],
      "metadata": {
        "id": "tMRPucpXfHdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the last part, where the actual training takes place. It loops over the gradient\n",
        "descent steps.\n",
        "\n",
        "* Step 1: compute model’s predictions\n",
        "* Step 2: compute the loss\n",
        "* Step 3: compute the gradients\n",
        "* Step 4: update the parameters\n",
        "\n",
        "Since we are not manually creating parameters anymore, the initialization is\n",
        "handled inside each layer during model creation."
      ],
      "metadata": {
        "id": "M4_DEgYjfILZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v0.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Sets model to TRAIN mode\n",
        "  model.train()\n",
        "\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = model(x_train_tensor)\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "xiuJG7Qtfg8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v0.py"
      ],
      "metadata": {
        "id": "kWvH9I1FgVfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One last check to make sure we have everything right."
      ],
      "metadata": {
        "id": "2lHjU-fbgd0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "aoGyMDKOgefz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about writing a function that takes a model, a loss, and an optimizer and\n",
        "returns another function that performs a training step?\n",
        "\n",
        "The latter would then\n",
        "take the features and corresponding labels as arguments and returning the\n",
        "corresponding loss.\n",
        "\n",
        ">Wait, what?! A function that returns another function?\n",
        "\n",
        "Sounds complicated, right? \n",
        "\n",
        "It is not as bad as it sounds, though… that’s called a\n",
        "higher-order function, and it is very useful for reducing boilerplate."
      ],
      "metadata": {
        "id": "JAo6Iogwh5tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Better Model Training"
      ],
      "metadata": {
        "id": "Pa5P-hTuo4Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The higher-order function that builds a training step function for us is taking the key elements of our training loop: model, loss, and\n",
        "optimizer. \n",
        "\n",
        "The actual training step function to be returned will have two\n",
        "arguments, namely, features and labels, and will return the corresponding loss\n",
        "value."
      ],
      "metadata": {
        "id": "gkCmgzGoo8Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "\n",
        "  # Builds function that performs a step in the train loop\n",
        "  def perform_train_step(x, y):\n",
        "    # Sets model to TRAIN mode\n",
        "    model.train()\n",
        "\n",
        "    # Step 1 - Computes model's predictions - forward pass\n",
        "    yhat = model(x)\n",
        "\n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y)\n",
        "\n",
        "    # Step 3 - Computes gradients for \"b\" and \"w\" parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Step 4 - Updates parameters using gradients and the learning rate\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Returns the loss\n",
        "    return loss.item()\n",
        "\n",
        "  # Returns the function that will be called inside the train loop\n",
        "  return perform_train_step"
      ],
      "metadata": {
        "id": "b3XefPFXpRn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to update our Model Configuration code to call this higher-order function to build a `train_step` function. \n",
        "\n",
        "But\n",
        "we need to run a data preparation script first."
      ],
      "metadata": {
        "id": "vApqciVVswCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v0.py"
      ],
      "metadata": {
        "id": "VZysAc4ys19V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v1.py\n",
        "\n",
        "# This is redundant now, but it won't be when we introduce Datasets...\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)"
      ],
      "metadata": {
        "id": "cBmRPVIUtgUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "8Ll6fOk5uSAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check our `train_step` function out!"
      ],
      "metadata": {
        "id": "ZIWCLSLcubIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_step"
      ],
      "metadata": {
        "id": "4auCaYf7ucuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good! \n",
        "\n",
        "Now we need to update our Model Training to replace the code\n",
        "inside the loop with a call to our newly created function."
      ],
      "metadata": {
        "id": "-2jASa-WuvLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v1.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "# Keeping track of the training loss\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "  # Performs one train step and returns the corresponding loss\n",
        "  loss = train_step(x_train_tensor, y_train_tensor)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "PiCi6H2Kuvw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v1.py"
      ],
      "metadata": {
        "id": "iUtoiOiZvVA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we check if our changes did not introduce any bugs? \n",
        "\n",
        "We can inspect our model’s `state_dict()`:"
      ],
      "metadata": {
        "id": "GST-Bs1ww_PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "UXvayjiTxCXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "NP8OOLSfxUck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, a dataset is represented by a regular Python class that inherits from the Dataset class. \n",
        "\n",
        "You can think of it as a list of tuples, each tuple corresponding to one point (features, label).\n",
        "\n",
        "The most fundamental methods it needs to implement are:\n",
        "\n",
        "* `__init__(self)`: it takes whatever arguments needed to build a list of tuples —it may be the name of a CSV file that will be loaded and processed; it may be two tensors, one for features, another one for labels; or anything else, depending on the task at hand.\n",
        "\n",
        "* `__get_item__(self, index)`: it allows the dataset to be indexed so that it can work like a `list(dataset[i])` — it must return a `tuple (features, label)` corresponding to the requested data point.\n",
        "\n",
        "* `__len__(self)`: it should simply return the size of the whole dataset so,\n",
        "whenever it is sampled, its indexing is limited to the actual size.\n",
        "\n",
        "Let’s build a simple custom dataset that takes two tensors as arguments: one for\n",
        "the features, one for the labels. \n",
        "\n",
        "For any given index, our dataset class will return\n",
        "the corresponding slice of each one of those tensors.\n",
        "\n"
      ],
      "metadata": {
        "id": "4srFgmz4xVaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, x_tensor, y_tensor):\n",
        "    self.x = x_tensor\n",
        "    self.y = y_tensor\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.x[index], self.y[index])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "metadata": {
        "id": "kXCHwb_Mh1ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "NfjY1KNTioKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don’t want our whole training data to be loaded into GPU\n",
        "tensors, as we have been doing in our example so far, because it\n",
        "takes up space in our precious graphics card’s RAM.\n",
        "\n",
        "But, we can use PyTorch’s TensorDataset class, which\n",
        "will do pretty much the same as our custom dataset."
      ],
      "metadata": {
        "id": "DH5fVRIPkJGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "0SphydMtki6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, fine, but then again, why are we building a dataset anyway? \n",
        "\n",
        "We’re doing it because we want to use a....**DataLoader**."
      ],
      "metadata": {
        "id": "KtGGiTvZk1EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataLoader"
      ],
      "metadata": {
        "id": "qd1DwTWWk48j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Until now, we have used the whole training data at every training step. It has been\n",
        "batch gradient descent all along. This is fine for our ridiculously small dataset, sure,\n",
        "but if we want to go serious about all this, we must use mini-batch gradient\n",
        "descent. Thus, we need mini-batches. Thus, we need to slice our dataset\n",
        "accordingly.\n",
        "\n",
        "So we use PyTorch’s DataLoader class for this job. We tell it which dataset to use, the desired mini-batch size, and\n",
        "if we’d like to shuffle it or not. That’s it!\n",
        "\n",
        ">There is more to a DataLoader than meets the eye… it is also\n",
        "possible to use it together with a sampler to fetch mini-batches\n",
        "that compensate for imbalanced classes, for instance.\n",
        "\n",
        "Our loader will behave like an iterator, so we can loop over it and fetch a different mini-batch every time.\n",
        "\n",
        "In our example, we have only 80 training points, so I chose a mini-batch size of 16\n",
        "to conveniently split the training set into five mini-batches."
      ],
      "metadata": {
        "id": "GojMDQEsk63m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "EOAzhlgMnDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve a mini-batch, one can simply run the command below — it will return a\n",
        "list containing two tensors, one for the features, another one for the labels:"
      ],
      "metadata": {
        "id": "qlujyigtnViT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "id": "8I2fCHaUnWDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this change our code so far? Let’s check it out!\n",
        "\n",
        "First, we need to add both Dataset and DataLoader elements into our data\n",
        "preparation part of the code. \n",
        "\n",
        "Also, notice that we do not send our tensors to the\n",
        "device just yet."
      ],
      "metadata": {
        "id": "hAi0z6RsyGGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v1.py\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "x_train_tensor = torch.as_tensor(x_train).float()\n",
        "y_train_tensor = torch.as_tensor(y_train).float()\n",
        "\n",
        "# Builds Dataset\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "# Builds DataLoader\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "iMa22sWVyKAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py"
      ],
      "metadata": {
        "id": "_WPDJl1X0L-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to incorporate the mini-batch gradient descent logic into our model\n",
        "training part of the code."
      ],
      "metadata": {
        "id": "RGyD5CRh0kVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to run the model configuration first\n",
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "mCCDiFu40k9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v2.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "# Keeping track of the training loss\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "  mini_batch_losses = []\n",
        "  # mini-batch inner loop\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    # the dataset \"lives\" in the CPU, so do our mini-batches \n",
        "    # therefore, we need to send those mini-batches to the device where the model \"lives\"\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    # Performs one train step and returns the corresponding loss for this mini-batch\n",
        "    mini_batch_loss = train_step(x_batch, y_batch)\n",
        "    # Keeping track of the loss inside each mini-batch\n",
        "    mini_batch_losses.append(mini_batch_loss)\n",
        "  \n",
        "  # Computes average loss over all mini-batches \n",
        "  # That's the epoch loss\n",
        "  loss = np.mean(mini_batch_losses)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "L8RR9G-W0xj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v2.py"
      ],
      "metadata": {
        "id": "Eif7Ri4t2jYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not so bad, right? So, it is time to check if our code still works well."
      ],
      "metadata": {
        "id": "foAlAncZ7d0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "r6J6geS87ene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did you get slightly different values? \n",
        "\n",
        "Try running the whole\n",
        "pipeline again:"
      ],
      "metadata": {
        "id": "6sG9EyPf7poX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py\n",
        "%run -i model_configuration/v1.py\n",
        "%run -i model_training/v2.py"
      ],
      "metadata": {
        "id": "0-SO9Fe17q9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "8BF3OIf975aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the DataLoader draws random samples, executing other\n",
        "code between the last two steps of the pipeline may interfere\n",
        "with the reproducibility of the results.\n",
        "\n",
        "Did you notice it is taking longer to train now? Can you guess\n",
        "why?\n",
        "\n",
        "The training time is longer now because the inner loop is executed five\n",
        "times for each epoch (in our example, since we are using a mini-batch of size 16 and we have 80 training data points in total, we execute the inner loop `80 / 16 = 5` times). \n",
        "\n",
        "So, in total, we are calling the train_step a total of 5,000 times now! No\n",
        "wonder it’s taking longer!"
      ],
      "metadata": {
        "id": "FaKrHaQ28Bz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mini-Batch"
      ],
      "metadata": {
        "id": "nT6ko3vR8fMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now on, it is very unlikely that you’ll ever use (full) batch gradient descent again, both in this book or in real life :-) \n",
        "\n",
        "So, it makes sense to, once again, organize a\n",
        "piece of code that’s going to be used repeatedly into its own function: the minibatch\n",
        "inner loop!\n",
        "\n",
        "The inner loop depends on three elements:\n",
        "\n",
        "* the device where data is being sent to\n",
        "* data loader to draw mini-batches from\n",
        "* step function, returning the corresponding loss"
      ],
      "metadata": {
        "id": "5eP4OIY58f-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch(device, data_loader, step):\n",
        "  mini_batch_losses = []\n",
        "  for x_batch, y_batch in data_loader:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    mini_batch_loss = step(x_batch, y_batch)\n",
        "    mini_batch_losses.append(mini_batch_loss)\n",
        "  \n",
        "  loss = np.mean(mini_batch_losses)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "nCaO2fXPqiaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we realized that we were executing five times more updates per epoch due to the mini-batch inner loop. Before, 1,000\n",
        "epochs meant 1,000 updates. \n",
        "\n",
        "Now, we only need 200 epochs to perform the same\n",
        "1,000 updates."
      ],
      "metadata": {
        "id": "qHemM4WwrxnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py\n",
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "cXHuzakqsD2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v3.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # mini_batch inner loop\n",
        "  loss = mini_batch(device, train_loader, train_step)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "C-C6VS8XsMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v3.py"
      ],
      "metadata": {
        "id": "SzmQ3oMctvEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "pD2jeR73t2Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Split"
      ],
      "metadata": {
        "id": "bGOoj1uhuG8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch’s `random_split()` method is an easy and familiar way of performing a\n",
        "training-validation split."
      ],
      "metadata": {
        "id": "lhVJCAZGuIha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v2.py\n",
        "\n",
        "torch.manual_seed(13)\n",
        "\n",
        "# Builds tensors from numpy arrays BEFORE split\n",
        "x_tensor = torch.as_tensor(x).float()\n",
        "y_tensor = torch.as_tensor(y).float()\n",
        "\n",
        "# Builds dataset containing ALL data points\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "# Performs the split\n",
        "ratio = 0.8\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * ratio)\n",
        "n_val = n_total - n_train\n",
        "# Performing train-validation split in PyTorch\n",
        "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "eyGsp5N6ufUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v2.py"
      ],
      "metadata": {
        "id": "NgleCDlVvtfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation"
      ],
      "metadata": {
        "id": "OLBsh4POv-QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to use the model to compute predictions and then use the loss\n",
        "function to compute the loss, given our predictions and the true labels.\n",
        "\n",
        "And most importantly, we need to use the model’s `eval()` method. The only thing it\n",
        "does is setting the model to evaluation mode (just like its `train()` counterpart\n",
        "did), so the model can adjust its behavior accordingly when it has to perform some\n",
        "operations, like `Dropout`.\n",
        "\n",
        "Just like `make_train_step`, our new function, `make_val_step` is a higher-order\n",
        "function as well."
      ],
      "metadata": {
        "id": "n0BnDBLmv_pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_val_step(model, loss_fn):\n",
        "\n",
        "  # Builds function that performs a step in the validation loop\n",
        "  def perform_val_step(x, y):\n",
        "    # Sets model to EVAL mode\n",
        "    model.eval()\n",
        "\n",
        "    # Step 1 - Computes our model's predicted output forward pass\n",
        "    yhat = model(x)\n",
        "\n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y)\n",
        "\n",
        "    # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
        "    return loss.item()\n",
        "\n",
        "  return perform_val_step"
      ],
      "metadata": {
        "id": "AZSJuH92N2QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then, we update our Model Configuration code to include the creation of the\n",
        "corresponding function for the validation step."
      ],
      "metadata": {
        "id": "Hbq9ve1YOnHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v2.py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step = make_val_step(model, loss_fn)"
      ],
      "metadata": {
        "id": "LLpJHmOYOnlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v2.py"
      ],
      "metadata": {
        "id": "Uv6svg2OQHhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to change the training loop to include the evaluation of our model."
      ],
      "metadata": {
        "id": "YLf0Ri9rQi0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v4.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # mini_batch inner loop\n",
        "  loss = mini_batch(device, train_loader, train_step)\n",
        "  losses.append(loss)\n",
        "\n",
        "  # VALIDATION - no gradients in validation to prevent gradient computation!\n",
        "  with torch.no_grad():\n",
        "    val_loss = mini_batch(device, val_loader, val_step)\n",
        "    val_losses.append(val_loss)"
      ],
      "metadata": {
        "id": "I1cDNCy6QjOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v4.py"
      ],
      "metadata": {
        "id": "vfavVaFzRPRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "ZCGw9HGMRdlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s take a look at both losses - training, and validation:"
      ],
      "metadata": {
        "id": "4jNVVaAFRnQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v2.py\n",
        "%run -i model_configuration/v2.py\n",
        "%run -i model_training/v4.py"
      ],
      "metadata": {
        "id": "Ro4Jx1vtR-Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plot_losses(losses, val_losses)"
      ],
      "metadata": {
        "id": "gOgb4lcNRn5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TensorBoard"
      ],
      "metadata": {
        "id": "XmClJUYnSTDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir runs"
      ],
      "metadata": {
        "id": "VcrQWKbFc3q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "rxffZI4GZjT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It all starts with the creation of a SummaryWriter."
      ],
      "metadata": {
        "id": "cLsdFgBibYQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(\"runs/test\")"
      ],
      "metadata": {
        "id": "mlhmF9tHbZDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary writer implements several methods to allow us sending information\n",
        "to TensorBoard."
      ],
      "metadata": {
        "id": "WDWaEuJubnuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's add model to graph\n",
        "try:\n",
        "  writer.add_graph(model)\n",
        "except TypeError as error:\n",
        "  print(error)"
      ],
      "metadata": {
        "id": "sLPjBEGsbgIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we do need to send it some inputs together with our model… \n",
        "\n",
        "Let’s fetch a\n",
        "mini-batch of data points from our train_loader and then pass it as input to\n",
        "add_graph:"
      ],
      "metadata": {
        "id": "BjJsUFQOcL9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching a tuple of feature (sample_x) and label (sample_y)\n",
        "sample_x, sample_y = next(iter(train_loader))\n",
        "\n",
        "# Since our model was sent to device, we need to do the same with the data\n",
        "# Even here, both model and data need to be on the same device!\n",
        "writer.add_graph(model, sample_x.to(device))"
      ],
      "metadata": {
        "id": "SZTesL_UcNHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "Sz_AraUrcu6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `add_scalars` method to send multiple scalar values at once, and it needs three arguments:\n",
        "\n",
        "* `main_tag`: the parent name of the tags or, the \"group tag\"\n",
        "* `tag_scalar_dict`: the dictionary containing the key: value pairs for the scalars you want to keep track of\n",
        "* `global_step`: step value, that is, the index you’re associating with the values you’re sending in the dictionary - the epoch comes to mind in our case, as losses are computed for each epoch"
      ],
      "metadata": {
        "id": "Ajng8Q4AdeJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer.add_scalars(\"loss\", {\"training\": loss, \"validation\": val_loss}, epoch)"
      ],
      "metadata": {
        "id": "CRFrfbF2k0sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "35kTmtHekWKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to incorporate these elements into our Model\n",
        "Configuration and Model Training codes."
      ],
      "metadata": {
        "id": "POqG6B9Gleo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v2.py"
      ],
      "metadata": {
        "id": "BsSQHv8JlfZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v3.py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step = make_val_step(model, loss_fn)\n",
        "\n",
        "# Creates a Summary Writer to interface with TensorBoard\n",
        "writer = SummaryWriter(\"runs/simple_linear_regression\")\n",
        "\n",
        "# Fetches a single mini-batch so we can use add_graph\n",
        "x_dummy, y_dummy = next(iter(train_loader))\n",
        "writer.add_graph(model, x_dummy.to(device))"
      ],
      "metadata": {
        "id": "5ORk0KZblma9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v3.py"
      ],
      "metadata": {
        "id": "YjkGEVNAmOTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v5.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # mini_batch inner loop\n",
        "  loss = mini_batch(device, train_loader, train_step)\n",
        "  losses.append(loss)\n",
        "\n",
        "  # VALIDATION - no gradients in validation to prevent gradient computation!\n",
        "  with torch.no_grad():\n",
        "    val_loss = mini_batch(device, val_loader, val_step)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "  # Records both losses for each epoch under tag \"loss\"\n",
        "  writer.add_scalars(main_tag=\"loss\",\n",
        "                     tag_scalar_dict={\"training\": loss, \"validation\": val_loss}, \n",
        "                     global_step=epoch)\n",
        "\n",
        "# Closes the writer\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "b8jL5z7ymioH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v5.py"
      ],
      "metadata": {
        "id": "0wW4m1ABoENx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "L5ES7iCKoVwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s inspect TensorBoard."
      ],
      "metadata": {
        "id": "2DUBBh-zod2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "2vju6mrxoeUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the same plot we’ve built before using our lists and Matplotlib. \n",
        "\n",
        "If our model\n",
        "were big or complex enough to take at least a couple of minutes to train, we would\n",
        "be able to see the evolution of our losses in TensorBoard during training."
      ],
      "metadata": {
        "id": "D-FH1hfYo0J0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving and Loading Models"
      ],
      "metadata": {
        "id": "uwaDnoGgpHey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To checkpoint a model, we basically have to save its state to a file so that it can be loaded back later - nothing special, actually.\n",
        "\n",
        "Now, wrap everything into a Python dictionary and use `torch.save()` to dump it all into a file."
      ],
      "metadata": {
        "id": "aJqOLVH2pI0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "  \"epoch\": n_epochs,\n",
        "  \"model_state_dict\": model.state_dict(),\n",
        "  \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "  \"loss\": losses,\n",
        "  \"val_loss\": val_losses\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"model_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "mk1jMnyEmDDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Resuming Training"
      ],
      "metadata": {
        "id": "y0T_ucJzwwZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we’re starting fresh, we have to set up the stage before actually loading the model. This means\n",
        "we need to load the data and configure the model."
      ],
      "metadata": {
        "id": "0lEUefPpm7kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v2.py\n",
        "%run -i model_configuration/v3.py"
      ],
      "metadata": {
        "id": "acFnET9SnAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "bPTIrOmCnJTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to load the model back."
      ],
      "metadata": {
        "id": "kvLrTr1LnZfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dictionary back\n",
        "checkpoint = torch.load(\"model_checkpoint.pth\")\n",
        "\n",
        "# load model and optimizer state dictionaries back\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "# load everything else into their corresponding variables\n",
        "saved_epoch = checkpoint[\"epoch\"]\n",
        "saved_losses = checkpoint[\"loss\"]\n",
        "saved_val_losses = checkpoint[\"val_loss\"]\n",
        "\n",
        "# always use TRAIN for resuming training\n",
        "model.train()"
      ],
      "metadata": {
        "id": "JRdCwILGnaDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "_yEdi1Qspc7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cool, we recovered our model’s state, and we can resume training.\n",
        "\n",
        "Next, we can run Model Training V5 to train it for another 200 epochs."
      ],
      "metadata": {
        "id": "l8wbt4glpnf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v5.py"
      ],
      "metadata": {
        "id": "8tjhHIOIucja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "BnDPomPduhHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check the evolution of the losses, before and after checkpointing."
      ],
      "metadata": {
        "id": "r0hD9GJWurwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plot_resumed_losses(saved_epoch, saved_losses, saved_val_losses, n_epochs,losses, val_losses)"
      ],
      "metadata": {
        "id": "s3tbNXwoutIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, the loss was already at a minimum before the checkpoint so, nothing has changed!"
      ],
      "metadata": {
        "id": "THFSQxOTvMoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Deploying / Making Predictions"
      ],
      "metadata": {
        "id": "uF9TgsVTveSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, if we’re starting fresh, we have to set up the stage before actually loading the model. But, this\n",
        "time, we only need to configure the model:"
      ],
      "metadata": {
        "id": "uzk7fB56vfTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v3.py"
      ],
      "metadata": {
        "id": "v2d6HikMvitc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the model is fully trained, we don’t need to load the optimizer or anything else."
      ],
      "metadata": {
        "id": "q9UIZ1qlvqX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_checkpoint.pth\")\n",
        "\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "LnOObSyfvmA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After recovering our model’s state, we can finally use it to make predictions for\n",
        "new inputs:"
      ],
      "metadata": {
        "id": "EruIgeVUwAIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_inputs = torch.tensor([[.20], [.34], [.57]])\n",
        "\n",
        "# always use EVAL for fully trained models!\n",
        "model.eval()\n",
        "model(new_inputs.to(device))"
      ],
      "metadata": {
        "id": "Q3Bf59oOwAzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After loading a fully trained model for deployment / to make\n",
        "predictions, make sure you ALWAYS set it to evaluation mode."
      ],
      "metadata": {
        "id": "212STkJxwis-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Putting It All Together"
      ],
      "metadata": {
        "id": "nP9ZDKakwllt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %load data_preparation/v2.py\n",
        "\n",
        "torch.manual_seed(13)\n",
        "\n",
        "# Builds tensors from numpy arrays BEFORE split\n",
        "x_tensor = torch.as_tensor(x).float()\n",
        "y_tensor = torch.as_tensor(y).float()\n",
        "\n",
        "# Builds dataset containing ALL data points\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "# Performs the split\n",
        "ratio = 0.8\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * ratio)\n",
        "n_val = n_total - n_train\n",
        "# Performing train-validation split in PyTorch\n",
        "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "YuMuEsDuq-C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %load model_configuration/v3.py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "# Creates the val_step function for our model and loss function\n",
        "val_step = make_val_step(model, loss_fn)\n",
        "\n",
        "# Creates a Summary Writer to interface with TensorBoard\n",
        "writer = SummaryWriter(\"runs/simple_linear_regression\")\n",
        "\n",
        "# Fetches a single mini-batch so we can use add_graph\n",
        "x_sample, y_sample = next(iter(train_loader))\n",
        "writer.add_graph(model, x_sample.to(device))"
      ],
      "metadata": {
        "id": "O9n3tG46raqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %load model_training/v5.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # mini_batch inner loop\n",
        "  loss = mini_batch(device, train_loader, train_step)\n",
        "  losses.append(loss)\n",
        "\n",
        "  # VALIDATION - no gradients in validation to prevent gradient computation!\n",
        "  with torch.no_grad():\n",
        "    val_loss = mini_batch(device, val_loader, val_step)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "  # Records both losses for each epoch under tag \"loss\"\n",
        "  writer.add_scalars(main_tag=\"loss\",\n",
        "                     tag_scalar_dict={\"training\": loss, \"validation\": val_loss}, \n",
        "                     global_step=epoch)\n",
        "\n",
        "# Closes the writer\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "eeypdvR_r9n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "jOBL9rQWsQs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "rdmDKR_PsnDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the general structure you’ll use over and over again for\n",
        "training PyTorch models.\n",
        "\n",
        "Sure, a different dataset and problem will require a different\n",
        "model and loss function, and you may want to try a different\n",
        "optimizer and a cycling learning rate, but\n",
        "the rest is likely to remain exactly the same."
      ],
      "metadata": {
        "id": "iX88BMO9s3pY"
      }
    }
  ]
}