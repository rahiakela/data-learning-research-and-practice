{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkNajGvIMNC9caJ8kFiUv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/02_simple_regression_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Regression Problem"
      ],
      "metadata": {
        "id": "eB520cKUnVhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I will stick with a simple and familiar problem:\n",
        "a linear regression with a single feature x! It doesn’t get much simpler than that…\n",
        "\n",
        "$$ y = b + wx + ϵ$$\n",
        "\n",
        "It is also possible to think of it as the simplest neural network possible: one input,\n",
        "one output, and no activation function (that is, linear).\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5wTQQbxanWY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "a60l9BX2oE0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter1()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter1 import *"
      ],
      "metadata": {
        "id": "pgGfHWV5oZqU",
        "outputId": "9d748206-296f-477d-fb00-1c4eaaf0a8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torchviz...\n",
            "Downloading files from GitHub repo to Colab...\n",
            "Creating folders...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "TUEV99bdogt_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Generation"
      ],
      "metadata": {
        "id": "IS1-btItoZ1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start generating some synthetic data: we start with a vector of `100 (N)` points\n",
        "for our feature `(x)` and create our labels `(y)` using `b = 1, w = 2`, and some Gaussian noise (epsilon)."
      ],
      "metadata": {
        "id": "U6ucNoo7oawj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "# Data Generation\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (.1 * np.random.rand(N, 1))\n",
        "y = true_b + true_w * x + epsilon"
      ],
      "metadata": {
        "id": "7i8oVtQPpATN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let’s split our synthetic data into train and validation sets, shuffling the array\n",
        "of indexes and using the first 80 shuffled points for training."
      ],
      "metadata": {
        "id": "6Bg1PAVnpncx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles the indices\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:int(N * .8)]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[int(N * .8): ]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "6c8vMI5Kpn3Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure1(x_train, y_train, x_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ZBTcz6BhqYoR",
        "outputId": "6300453e-a0db-4e89-f413-8894526ef83d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 864x432 with 2 Axes>,\n",
              " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fdf50db2410>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fdebeb3d190>],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that b = 1, w = 2, but now let’s see how close we can get to the true\n",
        "values by using gradient descent and the 80 points in the training set."
      ],
      "metadata": {
        "id": "u3BTZsQaqZQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Descent"
      ],
      "metadata": {
        "id": "21NT7ES1qg4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I’ll cover the five basic steps you’d need to go through to use gradient descent."
      ],
      "metadata": {
        "id": "dUjLq0Lfqi5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 0: Random Initialization"
      ],
      "metadata": {
        "id": "sDiR9dYjqqZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training a model, you need to randomly initialize the parameters/weights."
      ],
      "metadata": {
        "id": "H5yEPuTVTJks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "np.random.seed(42)\n",
        "\n",
        "b = np.random.randn(1)\n",
        "w = np.random.randn(1)\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "br2g0-4HSk4d",
        "outputId": "22a7b106-685e-4898-924e-ed8ab41675ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49671415] [-0.1382643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1: Compute Model's Predictions"
      ],
      "metadata": {
        "id": "B18OXUGQS0fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the forward pass - it simply computes the model’s predictions using the current\n",
        "values of the parameters/weights."
      ],
      "metadata": {
        "id": "dWR0NKt7TPu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b + w * x_train"
      ],
      "metadata": {
        "id": "cHzyWY9FS1s3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 2: Compute the Loss"
      ],
      "metadata": {
        "id": "louZXxr4S_v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a regression problem, the loss is given by the Mean Squared Error (MSE), that\n",
        "is, the average of all squared errors, that is, the average of all squared differences\n",
        "between labels (`y`) and predictions (`b + wx`).\n",
        "\n",
        "Here, we are using all data points of the training set to compute the\n",
        "loss, so `n = N = 80`, meaning we are performing batch gradient descent."
      ],
      "metadata": {
        "id": "t7ZFJK_hTYss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 - Computing the loss\n",
        "\n",
        "# We are using ALL data points, so this is BATCH gradient descent. How wrong is our model? That's the error!\n",
        "error = (yhat - y_train)\n",
        "\n",
        "# It is a regression, so it computes mean squared error (MSE)\n",
        "loss = (error ** 2).mean()\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "1n2CtsUXS9gj",
        "outputId": "c0fda6b0-fb85-47a0-a550-4690922a34a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.808129216295391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 3: Compute the Gradients"
      ],
      "metadata": {
        "id": "DpLPVKTmT3IN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A gradient is a partial derivative — why partial? Because one computes it with\n",
        "respect to (w.r.t.) a single parameter. We have two parameters, b and w, so we must compute two partial derivatives.\n",
        "\n",
        "A derivative tells you how much a given quantity changes when you slightly vary\n",
        "some other quantity. In our case, how much does our MSE loss change when we\n",
        "vary each one of our two parameters separately?\n",
        "\n",
        "> **Gradient** = how much the loss changes if ONE parameter\n",
        "changes a little bit!"
      ],
      "metadata": {
        "id": "YD9USz_wT30a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "b_grad = 2 * error.mean()\n",
        "w_grad = 2 * (x_train * error).mean()\n",
        "print(b_grad, w_grad)"
      ],
      "metadata": {
        "id": "Vl3-r09yURpb",
        "outputId": "a5ffb0d0-411a-4639-d29a-af7835d4746f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3.108262701823821 -1.8206663430690853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 4 - Update the Parameters"
      ],
      "metadata": {
        "id": "jeBiRiOMUknN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the final step, we use the gradients to update the parameters. \n",
        "\n",
        "Since we are\n",
        "trying to minimize our losses, we reverse the sign of the gradient for the update.\n",
        "\n",
        "In our example, let’s start with a value of 0.1 for the learning rate."
      ],
      "metadata": {
        "id": "wKC5qiATUlRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "print(b, w)\n",
        "\n",
        "# Step 4 - Updates parameters using gradients and the learning rate\n",
        "b = b - lr * b_grad\n",
        "w = w - lr * w_grad\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "pkbTlKSbUrD4",
        "outputId": "069e6e2f-06f6-42f9-a295-9b488eb14db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[0.80754042] [0.04380233]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5 - Rinse and Repeat!"
      ],
      "metadata": {
        "id": "robyWOO0VQNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the updated parameters to go back to Step 1 and restart the process.\n",
        "\n",
        "Repeating this process over and over for many epochs is, in a nutshell, training a\n",
        "model."
      ],
      "metadata": {
        "id": "x_8OmIQ8VQ6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear Regression in Numpy"
      ],
      "metadata": {
        "id": "hnago_O4Vmvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It’s time to implement our linear regression model using gradient descent and\n",
        "Numpy only.\n",
        "\n",
        "For each epoch, there are four training steps:\n",
        "\n",
        "1. Compute model’s predictions — this is the forward pass\n",
        "2. Compute the loss, using predictions and labels and the appropriate loss function\n",
        "3. Compute the gradients for every parameter\n",
        "4. Update the parameters\n",
        "\n",
        "For now, we will be using batch gradient descent only, meaning, we’ll use all data\n",
        "points for each one of the four steps above. It also means that going once through\n",
        "all of the steps is already one epoch."
      ],
      "metadata": {
        "id": "4vsVHIgOVo7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = np.random.randn(1)\n",
        "w = np.random.randn(1)\n",
        "print(b, w)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = b + w * x_train\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  # We are using ALL data points, so this is BATCH gradient descent. How wrong is our model? That's the error! \n",
        "  error = (yhat - y_train)\n",
        "  # It is a regression, so it computes mean squared error (MSE)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  b_grad = 2 * error.mean()\n",
        "  w_grad = 2 * (x_train * error).mean()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate\n",
        "  b = b - lr * b_grad\n",
        "  w = w - lr * w_grad\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "uzXq0fwnDFgE",
        "outputId": "4f1f0de1-3f0b-4945-8a4e-67a740d8a92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[1.05303414] [1.99581323]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to make sure we haven’t done any mistakes in our code, we can use Scikit-\n",
        "Learn’s Linear Regression to fit the model and compare the coefficients."
      ],
      "metadata": {
        "id": "bDE1NocjFyk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check: do we get the same results as our gradient descent?\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x_train, y_train)\n",
        "print(lin_reg.intercept_, lin_reg.coef_[0])"
      ],
      "metadata": {
        "id": "WqxxP3wSFz-D",
        "outputId": "69b3a454-e9c7-4114-dc05-e76dae328023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.05303354] [1.99581441]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They match up to 6 decimal places — we have a fully working implementation of linear\n",
        "regression using Numpy."
      ],
      "metadata": {
        "id": "49Q7oFVdGT82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = figure3(x_train, y_train)"
      ],
      "metadata": {
        "id": "5IwTRGzuGUbG",
        "outputId": "fc2470a7-c705-4429-a41c-f558840c1209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PyTorch Basic"
      ],
      "metadata": {
        "id": "E3tHpvUYGqpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Numpy, you may have an array that has three dimensions, right? That is,\n",
        "technically speaking, a tensor.\n",
        "\n",
        "You can create tensors in PyTorch pretty much the same way you create arrays in\n",
        "Numpy. \n",
        "\n",
        "Using `tensor()` you can create either a scalar or a tensor."
      ],
      "metadata": {
        "id": "vzhYQ-Q3GsRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(3.14159)\n",
        "vector = torch.tensor([1, 2, 3])\n",
        "matrix = torch.ones((2, 3), dtype=torch.float)\n",
        "tensor = torch.randn((2, 3, 4), dtype=torch.float)\n",
        "\n",
        "print(scalar)\n",
        "print(vector)\n",
        "print(matrix)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "8QA2sK9tiodM",
        "outputId": "0f565268-1e4b-490a-9e0c-47a43a74eca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.1416)\n",
            "tensor([1, 2, 3])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[[ 0.6291, -0.4928, -0.0780, -0.4176],\n",
            "         [ 0.2595,  0.4698,  0.0641,  0.8023],\n",
            "         [ 0.5542, -0.5085, -1.4040,  0.8507]],\n",
            "\n",
            "        [[ 0.3093, -1.2875,  2.2664, -1.7359],\n",
            "         [-0.1595,  1.0394, -0.5099, -0.8586],\n",
            "         [ 1.0344, -0.5021,  2.0779,  0.3138]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can get the shape of a tensor using its `size()` method or its shape attribute."
      ],
      "metadata": {
        "id": "pibBdsgLjcSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.size(), tensor.shape)"
      ],
      "metadata": {
        "id": "v13QAvfnjd8p",
        "outputId": "e742d61f-11af-4dde-d7d0-f7229d3b9020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4]) torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scalars have \"empty\" shapes\n",
        "print(scalar.size(), scalar.shape)"
      ],
      "metadata": {
        "id": "SEUjmq7sjm1e",
        "outputId": "0304d776-ce11-408f-b1e6-8510b9f78574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([]) torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also reshape a tensor using its `view()` (preferred) or `reshape()` methods."
      ],
      "metadata": {
        "id": "sn6ZczR2jwwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get a tensor with a different shape but it still is the SAME tensor\n",
        "same_matrix = matrix.view(1, 6)\n",
        "\n",
        "# If we change one of its elements...\n",
        "same_matrix[0, 1] = 2.\n",
        "\n",
        "# It changes both variables: matrix and same_matrix\n",
        "print(matrix)\n",
        "print(same_matrix)"
      ],
      "metadata": {
        "id": "GUGgd1V_jziz",
        "outputId": "a1d05074-961d-463b-fa5b-3e401e6dbcb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 2., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to copy all data for real, that is, duplicate the data in memory, you may\n",
        "use either its `new_tensor()` or `clone()` methods."
      ],
      "metadata": {
        "id": "VZ3f0wxRkQ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use \"new_tensor\" method to REALLY copy it into a new one\n",
        "different_matrix = matrix.new_tensor(matrix.view(1, 6))\n",
        "\n",
        "# Now, if we change one of its elements...\n",
        "different_matrix[0, 1] = 3.\n",
        "\n",
        "# The original tensor (matrix) is left untouched!\n",
        "# But we get a \"warning\" from PyTorch telling us to use \"clone()\" instead!\n",
        "print(matrix)\n",
        "print(different_matrix)"
      ],
      "metadata": {
        "id": "hIwAxu6jkTsO",
        "outputId": "279e0073-8bf0-4e88-88be-b770c3e5436b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 3., 1., 1., 1., 1.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that PyTorch prefers that we use `clone()` - together with `detach()` -\n",
        "instead of `new_tensor()`… Both ways accomplish exactly the same result.\n",
        "\n",
        "> `detach()` removes the tensor from the computation graph."
      ],
      "metadata": {
        "id": "3OiXlzOjlpad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets follow PyTorch's suggestion and use \"clone\" method\n",
        "another_matrix = matrix.view(1, 6).clone().detach()\n",
        "\n",
        "# Again, if we change one of its elements...\n",
        "another_matrix[0, 1] = 4.\n",
        "\n",
        "# The original tensor (matrix) is left untouched!\n",
        "print(matrix)\n",
        "print(another_matrix)"
      ],
      "metadata": {
        "id": "J127k_PVlqHN",
        "outputId": "b9a79a62-bc1f-4a99-e6f7-8ba93cfb1f6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 4., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading Data, Devices and CUDA"
      ],
      "metadata": {
        "id": "P2h8HWgGtJm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is time to start converting our Numpy code to PyTorch: we’ll start with the\n",
        "training data."
      ],
      "metadata": {
        "id": "xNbU2J2ktKfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "x_train.dtype, x_train_tensor.dtype"
      ],
      "metadata": {
        "id": "i2ZOA43XtLKF",
        "outputId": "6e122668-7c49-4c7a-e3e6-8395f426110d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also easily cast it to a different type."
      ],
      "metadata": {
        "id": "IqHPiFmFtnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_tensor = x_train_tensor.float()\n",
        "float_tensor.dtype"
      ],
      "metadata": {
        "id": "bhb3xZwXtoRe",
        "outputId": "0572bf46-4a69-49fa-dafd-2f8d02628e9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**IMPORTANT**: both `as_tensor()` and `from_numpy()` return a\n",
        "tensor that shares the underlying data with the original Numpy\n",
        "array. Similarly to what happened when we used view() in the\n",
        "last section, if you modify the original Numpy array, you’re\n",
        "modifying the corresponding PyTorch tensor too, and vice-versa."
      ],
      "metadata": {
        "id": "j0K4ooSruHnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_array = np.array([1, 2, 3])\n",
        "dummy_tensor = torch.as_tensor(dummy_array)\n",
        "\n",
        "# Modifies the numpy array\n",
        "dummy_array[1] = 0\n",
        "\n",
        "# Tensor gets modified too...\n",
        "dummy_tensor"
      ],
      "metadata": {
        "id": "s1JGislIuNIg",
        "outputId": "cfe0599b-1905-43f6-887f-74fd429f75f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_array"
      ],
      "metadata": {
        "id": "ZAU0yUFeunmX",
        "outputId": "bc865488-8c39-4161-d831-b4355f8d4afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform the opposite operation, transforming a PyTorch tensor back to a Numpy array\n",
        "dummy_tensor.numpy() "
      ],
      "metadata": {
        "id": "DLl4GTfzutxt",
        "outputId": "f60ec1dc-cfdd-4aa7-cffd-4b06c489bb2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we have only created CPU tensors. \n",
        "\n",
        "What does it mean? \n",
        "\n",
        "It means the data in\n",
        "the tensor is stored in the computer’s main memory and any operations performed\n",
        "on it are going to be handled by its CPU.\n",
        "\n",
        "Is there any other kind of tensor?\n",
        "\n",
        "Yes, there is also a GPU tensor. \n",
        "\n",
        "A GPU (which stands for Graphics Processing Unit)\n",
        "is the processor of a graphics card. These tensors store their data in the graphics\n",
        "card’s memory and operations on top of them are performed by the GPU.\n",
        "\n",
        "Let's find out if we have a GPU."
      ],
      "metadata": {
        "id": "txwssrh3xuso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "_Utu0cE4yCRk",
        "outputId": "b8f5e093-e56e-4bc6-f127-fb6eb0da7320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's figure it out how many GPUs we have."
      ],
      "metadata": {
        "id": "jzEReCm7ysed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_cudas = torch.cuda.device_count()\n",
        "for i in range(n_cudas):\n",
        "  print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "id": "7eRDuC6byxqP",
        "outputId": "f4bdfe52-009a-4b24-91d6-128595ec7dc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is only one thing left to do: turn our tensor into a GPU tensor. That’s what\n",
        "`to()` is good for. It sends a tensor to the specified device."
      ],
      "metadata": {
        "id": "ZGqKywkjzlv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
        "gpu_tensor[0]  # GPU tensor"
      ],
      "metadata": {
        "id": "_UX1wXYUznz7",
        "outputId": "8e92ca5f-e190-4c75-cbd3-37627ec6c3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5227], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor[0]  # CPU tensor"
      ],
      "metadata": {
        "id": "SHdNn3S_0yFt",
        "outputId": "d3678ec0-9066-4e01-901d-b407311ae1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5227], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Should I use `to(device)`, even if I am using CPU only?\n",
        "\n",
        "Yes, you should, because there is no cost in doing so. If you have only a CPU, your\n",
        "tensor is already a CPU tensor, so nothing will happen. But if you share your code\n",
        "with others on GitHub, whoever has a GPU will benefit from it.\n",
        "\n",
        "Let’s put it all together now and make our training data ready for PyTorch."
      ],
      "metadata": {
        "id": "XDC38rWJ1CPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them\n",
        "# into PyTorch's Tensors and then we send them to the chosen device\n",
        "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
      ],
      "metadata": {
        "id": "vOPC3dRA1c78"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the difference - notice that `.type()` is more useful since it also tells us WHERE the tensor is (device)."
      ],
      "metadata": {
        "id": "pd3ut_Z82pQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())  # GPU tensor"
      ],
      "metadata": {
        "id": "UErHp9X22tU2",
        "outputId": "b686469c-70c6-4bd6-8ded-f2de7f01fbc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dummy_array), type(dummy_tensor), dummy_tensor.type())  # CPU tensor"
      ],
      "metadata": {
        "id": "dMDY9RT43A0W",
        "outputId": "ca9487a2-3c30-4461-ca74-bc987eb6115f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But where does the x_train_tensor “live”? Is it a CPU or a GPU tensor? \n",
        "\n",
        "You can’t\n",
        "say… but if you use PyTorch’s `type()`, it will reveal its location — `torch.cuda.FloatTensor` — a GPU tensor in this case.\n",
        "\n",
        "Now, let's see.\n",
        "\n",
        "What if we want to turn a GPU tensor back into a Numpy array?"
      ],
      "metadata": {
        "id": "FTUmvGkm3cw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  back_to_numpy = x_train_tensor.numpy()\n",
        "except TypeError:\n",
        "  print(\"TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\")"
      ],
      "metadata": {
        "id": "9ciOSjfg3vLw",
        "outputId": "116b963e-ae91-4f13-a391-991205455a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, Numpy cannot handle GPU tensors… you need to make them CPU\n",
        "tensors first using `cpu()`."
      ],
      "metadata": {
        "id": "MEo6Gfpb4BQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "back_to_numpy = x_train_tensor.cpu().numpy()"
      ],
      "metadata": {
        "id": "DLGHsBBO4Dbl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, to avoid this error, use first `cpu()` and then `numpy()`, even if you are using a CPU."
      ],
      "metadata": {
        "id": "uzNx7npJ4Nho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating Parameters"
      ],
      "metadata": {
        "id": "nCK-G-Mm4P9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What distinguishes a tensor used for training data (or validation, or test) — like the\n",
        "ones we’ve just created — from a tensor used as a (trainable) parameter/weight?\n",
        "\n",
        "The latter requires the computation of its gradients, so we can update their values\n",
        "(the parameters’ values, that is). \n",
        "\n",
        "That’s what the `requires_grad=True` argument is\n",
        "good for. It tells PyTorch to compute gradients for us.\n",
        "\n",
        "> A tensor for a learnable parameter requires a gradient!"
      ],
      "metadata": {
        "id": "gEIymB6T4SJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# FIRST\n",
        "# Initializes parameters \"b\" and \"w\" randomly, ALMOST as we\n",
        "# did in Numpy since we want to apply gradient descent on\n",
        "# these parameters we need to set REQUIRES_GRAD = TRUE\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "oDj4_Y6VrjXC",
        "outputId": "ad69dc7e-f20f-4455-cf40-26ecfd98de89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# SECOND\n",
        "# But what if we want to run it on a GPU? We could just send them to device, right?\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "ZXi9U1tavKJZ",
        "outputId": "f588151c-0b81-4c1b-adb8-f7611f408d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], device='cuda:0', grad_fn=<ToCopyBackward0>) tensor([0.1288], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# THIRD\n",
        "# We can either create regular tensors and send them to the device (as we did with our data)\n",
        "b = torch.randn(1, dtype=torch.float).to(device)\n",
        "w = torch.randn(1, dtype=torch.float).to(device)\n",
        "# and THEN set them as requiring gradients...\n",
        "b.requires_grad_()\n",
        "w.requires_grad_()\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "32L6EkM5ved4",
        "outputId": "911dee88-57b1-4005-e800-2da973bb627b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], device='cuda:0', requires_grad=True) tensor([0.1288], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach worked fine; we managed to end up with gradient-requiring GPU\n",
        "tensors for our parameters `b` and `w`. \n",
        "\n",
        "It seems a lot of work, though… Can we do\n",
        "better still?\n",
        "\n",
        "Yes, we can do better: we can assign tensors to a device at the moment of their\n",
        "creation."
      ],
      "metadata": {
        "id": "RTyq7F8Gv8Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# FINAL\n",
        "# We can specify the device at the moment of creation\n",
        "# RECOMMENDED!\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "HyvDwy8nwARL",
        "outputId": "11b30bc9-2101-4172-8eae-068eb53ab7fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know how to create tensors that require gradients, let’s see how\n",
        "PyTorch handles them."
      ],
      "metadata": {
        "id": "yyo3pJzzwi6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Autograd"
      ],
      "metadata": {
        "id": "P-1hyTcXwj_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autograd is PyTorch’s automatic differentiation package. Thanks to it, we don’t need\n",
        "to worry about partial derivatives, chain rule, or anything like it.\n",
        "\n",
        "Do you remember the starting point for computing the gradients? \n",
        "\n",
        "It was the loss,\n",
        "as we computed its partial derivatives w.r.t. our parameters. \n",
        "\n",
        "Hence, we need to\n",
        "invoke the `backward()` method from the corresponding Python variable:\n",
        "`loss.backward()`."
      ],
      "metadata": {
        "id": "wTCSiNLnwtk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b + w * x_train_tensor\n",
        "\n",
        "# Step 2 - Computes the loss\n",
        "# We are using ALL data points, so this is BATCH gradient descent\n",
        "# How wrong is our model? That's the error! \n",
        "error = (yhat - y_train_tensor)\n",
        "# It is a regression, so it computes mean squared error (MSE)\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "# Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "# No more manual computation of gradients! \n",
        "# b_grad = 2 * error.mean()\n",
        "# w_grad = 2 * (x_tensor * error).mean()\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "1IYeoeWBHyDP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you see the pattern here? \n",
        "\n",
        "If a tensor in the list is used to compute another\n",
        "tensor, the latter will also be included in the list. Tracking these dependencies is\n",
        "exactly what the dynamic computation graph is doing."
      ],
      "metadata": {
        "id": "cyUMdmUpJTfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(error.requires_grad, yhat.requires_grad, b.requires_grad, w.requires_grad)\n",
        "print(y_train_tensor.requires_grad, x_train_tensor.requires_grad)"
      ],
      "metadata": {
        "id": "TJXqvhBrJVkT",
        "outputId": "dd056dad-3903-482c-ef6b-08211591a547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True True True True\n",
            "False False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about the actual values of the gradients? \n",
        "\n",
        "We can inspect them by looking at\n",
        "the grad attribute of a tensor."
      ],
      "metadata": {
        "id": "ZqCg5jkOKRgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.grad, w.grad)"
      ],
      "metadata": {
        "id": "0wAoFPquKSv6",
        "outputId": "605d1a34-2760-45fa-9072-c4cb2a6b5bee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.4542], device='cuda:0') tensor([-1.9347], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you check the method’s documentation, it clearly states that **gradients are\n",
        "accumulated**. \n",
        "\n",
        "What does it mean? \n",
        "\n",
        "It means that, if we run gradient update twice and check the grad attribute afterward."
      ],
      "metadata": {
        "id": "kiPxOFAWKcVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.grad, w.grad)"
      ],
      "metadata": {
        "id": "3wQ4_IAMKok2",
        "outputId": "0707bd51-f468-4c37-c6b1-250ea73c363e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.4542], device='cuda:0') tensor([-1.9347], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These gradients' values are exactly twice as much as they were before, as\n",
        "expected!\n",
        "\n",
        "OK, but that is actually a problem: we need to use the gradients corresponding to the current loss to perform the parameter update. \n",
        "\n",
        "We should NOT use\n",
        "accumulated gradients.\n",
        "\n",
        "So, every time we use the gradients to update the parameters, we need to zero the\n",
        "gradients afterward.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UB-KiiwEKyCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code will be placed _after_ Step 4 (updating the parameters)\n",
        "b.grad.zero_(), w.grad.zero_()"
      ],
      "metadata": {
        "id": "R6IzDoodVAlA",
        "outputId": "cba2c475-19d9-43c9-dcf2-b0adeef9e77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.], device='cuda:0'), tensor([0.], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Updating Parameters"
      ],
      "metadata": {
        "id": "ujZxCDGaQ0nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, our Numpy's code for updating parameters is not enough… why\n",
        "not?! \n",
        "\n",
        "Let’s try it out, simply copying and pasting it (this is the first attempt), changing\n",
        "it slightly (second attempt), and then asking PyTorch to back off (yes, it is PyTorch’s\n",
        "fault!)."
      ],
      "metadata": {
        "id": "IIrjMY3HM3WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = b + w * x_train_tensor\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  error = (yhat - y_train_tensor)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  # No more manual computation of gradients! \n",
        "  # b_grad = 2 * error.mean()\n",
        "  # w_grad = 2 * (x_tensor * error).mean()   \n",
        "  # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate. But not so fast...\n",
        "\n",
        "  # FIRST ATTEMPT - just using the same code as before\n",
        "  # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "  # b = b - lr * b.grad\n",
        "  # w = w - lr * w.grad\n",
        "  # print(b)\n",
        "  \n",
        "  # SECOND ATTEMPT - using in-place Python assigment\n",
        "  # RuntimeError: a leaf Variable that requires grad\n",
        "  # has been used in an in-place operation.\n",
        "  # b -= lr * b.grad\n",
        "  # w -= lr * w.grad \n",
        "\n",
        "  # THIRD ATTEMPT - NO_GRAD for the win!\n",
        "  # We need to use NO_GRAD to keep the update out of\n",
        "  # the gradient computation. Why is that? It boils \n",
        "  # down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "  with torch.no_grad():\n",
        "    b -= lr * b.grad\n",
        "    w -= lr * w.grad\n",
        "\n",
        "  # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "  b.grad.zero_() # zero_ prevents gradient accumulation\n",
        "  w.grad.zero_()\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "pCF_d2tVM3o1",
        "outputId": "d2bd013a-d3cf-482d-9283-437587d238c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0530], device='cuda:0', requires_grad=True) tensor([1.9958], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dynamic Computation Graph"
      ],
      "metadata": {
        "id": "_0PXHilSQ5Al"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `PyTorchViz` package and its `make_dot(variable)` method allow us to easily\n",
        "visualize a graph associated with a given Python variable involved in the gradient\n",
        "computation.\n",
        "\n"
      ],
      "metadata": {
        "id": "_TKcJt2dQ7Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "\n",
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b + w * x_train_tensor\n",
        "\n",
        "# Step 2 - Computes the loss\n",
        "error = (yhat - y_train_tensor)\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "# We can try plotting the graph for any python variable\n",
        "make_dot(yhat)"
      ],
      "metadata": {
        "id": "QraKDeUrXxJC",
        "outputId": "b424fcec-08b7-4798-a620-c464c261c589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fdebc584490>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"234pt\" height=\"338pt\"\n viewBox=\"0.00 0.00 234.00 338.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 334)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-334 230,-334 230,4 -4,4\"/>\n<!-- 140594619303888 -->\n<g id=\"node1\" class=\"node\">\n<title>140594619303888</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"144,-31 79,-31 79,0 144,0 144,-31\"/>\n<text text-anchor=\"middle\" x=\"111.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 140596786515664 -->\n<g id=\"node2\" class=\"node\">\n<title>140596786515664</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"156,-86 67,-86 67,-67 156,-67 156,-86\"/>\n<text text-anchor=\"middle\" x=\"111.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140596786515664&#45;&gt;140594619303888 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140596786515664&#45;&gt;140594619303888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M111.5,-66.9688C111.5,-60.1289 111.5,-50.5621 111.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.0001,-41.3678 111.5,-31.3678 108.0001,-41.3678 115.0001,-41.3678\"/>\n</g>\n<!-- 140596786515728 -->\n<g id=\"node3\" class=\"node\">\n<title>140596786515728</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"107,-141 0,-141 0,-122 107,-122 107,-141\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ToCopyBackward0</text>\n</g>\n<!-- 140596786515728&#45;&gt;140596786515664 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140596786515728&#45;&gt;140596786515664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M63.6028,-121.9197C71.9004,-114.0514 83.8537,-102.7164 93.7431,-93.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.2745,-95.7615 101.1224,-86.3408 91.4578,-90.6821 96.2745,-95.7615\"/>\n</g>\n<!-- 140596786515280 -->\n<g id=\"node4\" class=\"node\">\n<title>140596786515280</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140596786515280&#45;&gt;140596786515728 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140596786515280&#45;&gt;140596786515728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M51.0226,-176.9197C51.405,-169.9083 51.9376,-160.1442 52.411,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"55.9133,-151.5166 52.9632,-141.3408 48.9237,-151.1353 55.9133,-151.5166\"/>\n</g>\n<!-- 140594659542128 -->\n<g id=\"node5\" class=\"node\">\n<title>140594659542128</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140594659542128&#45;&gt;140596786515280 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140594659542128&#45;&gt;140596786515280</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-231.791C50.5,-224.0249 50.5,-214.5706 50.5,-206.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-206.0647 50.5,-196.0648 47.0001,-206.0648 54.0001,-206.0647\"/>\n</g>\n<!-- 140596786513424 -->\n<g id=\"node6\" class=\"node\">\n<title>140596786513424</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-141 126,-141 126,-122 215,-122 215,-141\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140596786513424&#45;&gt;140596786515664 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140596786513424&#45;&gt;140596786515664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M160.223,-121.9197C151.7824,-114.0514 139.623,-102.7164 129.5631,-93.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.7578,-90.5995 122.0565,-86.3408 126.9846,-95.7198 131.7578,-90.5995\"/>\n</g>\n<!-- 140594658727248 -->\n<g id=\"node7\" class=\"node\">\n<title>140594658727248</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"226,-196 119,-196 119,-177 226,-177 226,-196\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ToCopyBackward0</text>\n</g>\n<!-- 140594658727248&#45;&gt;140596786513424 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140594658727248&#45;&gt;140596786513424</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M172.1516,-176.9197C171.8967,-169.9083 171.5416,-160.1442 171.226,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.719,-151.207 170.8578,-141.3408 167.7237,-151.4614 174.719,-151.207\"/>\n</g>\n<!-- 140596498539216 -->\n<g id=\"node8\" class=\"node\">\n<title>140596498539216</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"223,-257 122,-257 122,-238 223,-238 223,-257\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140596498539216&#45;&gt;140594658727248 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140596498539216&#45;&gt;140594658727248</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M172.5,-237.9688C172.5,-229.5131 172.5,-216.8901 172.5,-206.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.0001,-206.1656 172.5,-196.1656 169.0001,-206.1657 176.0001,-206.1656\"/>\n</g>\n<!-- 140594659541936 -->\n<g id=\"node9\" class=\"node\">\n<title>140594659541936</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"199.5,-330 145.5,-330 145.5,-299 199.5,-299 199.5,-330\"/>\n<text text-anchor=\"middle\" x=\"172.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140594659541936&#45;&gt;140596498539216 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140594659541936&#45;&gt;140596498539216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M172.5,-298.9604C172.5,-289.6356 172.5,-277.6748 172.5,-267.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.0001,-267.35 172.5,-257.3501 169.0001,-267.3501 176.0001,-267.35\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, even though there are more tensors involved in the operations performed by\n",
        "the computation graph, it only shows gradient-computing tensors and its\n",
        "dependencies.\n",
        "\n",
        "What would happen to the computation graph if we set `requires_grad` to False for\n",
        "our parameter `b`?"
      ],
      "metadata": {
        "id": "x1dY9QWBZltK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b_no_grad = torch.randn(1, requires_grad=False, dtype=torch.float).to(device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "\n",
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b_no_grad + w * x_train_tensor\n",
        "\n",
        "make_dot(yhat)"
      ],
      "metadata": {
        "id": "MlvRH-J_Zo0r",
        "outputId": "231858ad-8097-4b90-b727-4e6b115500bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fdebca87d50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"115pt\" height=\"326pt\"\n viewBox=\"0.00 0.00 115.00 326.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 322)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-322 111,-322 111,4 -4,4\"/>\n<!-- 140594624767952 -->\n<g id=\"node1\" class=\"node\">\n<title>140594624767952</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"86,-31 21,-31 21,0 86,0 86,-31\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 140594619771472 -->\n<g id=\"node2\" class=\"node\">\n<title>140594619771472</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"98,-86 9,-86 9,-67 98,-67 98,-86\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140594619771472&#45;&gt;140594624767952 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140594619771472&#45;&gt;140594624767952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-66.9688C53.5,-60.1289 53.5,-50.5621 53.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-41.3678 53.5,-31.3678 50.0001,-41.3678 57.0001,-41.3678\"/>\n</g>\n<!-- 140594619771536 -->\n<g id=\"node3\" class=\"node\">\n<title>140594619771536</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"98,-141 9,-141 9,-122 98,-122 98,-141\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140594619771536&#45;&gt;140594619771472 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140594619771536&#45;&gt;140594619771472</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-121.9197C53.5,-114.9083 53.5,-105.1442 53.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-96.3408 53.5,-86.3408 50.0001,-96.3409 57.0001,-96.3408\"/>\n</g>\n<!-- 140594658471504 -->\n<g id=\"node4\" class=\"node\">\n<title>140594658471504</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"107,-196 0,-196 0,-177 107,-177 107,-196\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ToCopyBackward0</text>\n</g>\n<!-- 140594658471504&#45;&gt;140594619771536 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140594658471504&#45;&gt;140594619771536</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-176.9197C53.5,-169.9083 53.5,-160.1442 53.5,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-151.3408 53.5,-141.3408 50.0001,-151.3409 57.0001,-151.3408\"/>\n</g>\n<!-- 140594619727440 -->\n<g id=\"node5\" class=\"node\">\n<title>140594619727440</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"104,-251 3,-251 3,-232 104,-232 104,-251\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140594619727440&#45;&gt;140594658471504 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140594619727440&#45;&gt;140594658471504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-231.9197C53.5,-224.9083 53.5,-215.1442 53.5,-206.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-206.3408 53.5,-196.3408 50.0001,-206.3409 57.0001,-206.3408\"/>\n</g>\n<!-- 140594659542032 -->\n<g id=\"node6\" class=\"node\">\n<title>140594659542032</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"80.5,-318 26.5,-318 26.5,-287 80.5,-287 80.5,-318\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140594659542032&#45;&gt;140594619727440 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140594659542032&#45;&gt;140594619727440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-286.791C53.5,-279.0249 53.5,-269.5706 53.5,-261.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-261.0647 53.5,-251.0648 50.0001,-261.0648 57.0001,-261.0647\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Simple enough: no gradients, no graph!\n",
        "\n",
        "The best thing about the dynamic computation graph is the fact that you can make it as complex as you want it. You can even use control flow statements (e.g., if\n",
        "statements) to control the flow of the gradients."
      ],
      "metadata": {
        "id": "w2x1-thMaG0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "\n",
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b + w * x_train_tensor\n",
        "\n",
        "# Step 2 - Computes the loss\n",
        "error = (yhat - y_train_tensor)\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "# this makes no sense!!\n",
        "if loss > 0:\n",
        "  yhat2 = w * x_train_tensor\n",
        "  error2 = (yhat2 - y_train_tensor)\n",
        "# neither does this :-)\n",
        "loss += error2.mean()\n",
        "\n",
        "# We can try plotting the graph for any python variable\n",
        "make_dot(loss)"
      ],
      "metadata": {
        "id": "vYVtlt5PaVCh",
        "outputId": "272098b8-76d7-48bd-e324-d35bd54622a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fdebc578d90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"332pt\" height=\"558pt\"\n viewBox=\"0.00 0.00 332.00 558.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 554)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-554 328,-554 328,4 -4,4\"/>\n<!-- 140594624697456 -->\n<g id=\"node1\" class=\"node\">\n<title>140594624697456</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"248.5,-31 194.5,-31 194.5,0 248.5,0 248.5,-31\"/>\n<text text-anchor=\"middle\" x=\"221.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 140594619451728 -->\n<g id=\"node2\" class=\"node\">\n<title>140594619451728</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"266,-86 177,-86 177,-67 266,-67 266,-86\"/>\n<text text-anchor=\"middle\" x=\"221.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140594619451728&#45;&gt;140594624697456 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140594619451728&#45;&gt;140594624697456</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.5,-66.9688C221.5,-60.1289 221.5,-50.5621 221.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"225.0001,-41.3678 221.5,-31.3678 218.0001,-41.3678 225.0001,-41.3678\"/>\n</g>\n<!-- 140594619322064 -->\n<g id=\"node3\" class=\"node\">\n<title>140594619322064</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231,-141 136,-141 136,-122 231,-122 231,-141\"/>\n<text text-anchor=\"middle\" x=\"183.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 140594619322064&#45;&gt;140594619451728 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140594619322064&#45;&gt;140594619451728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.1191,-121.9197C195.2863,-114.4409 202.6174,-103.8301 208.8944,-94.745\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.8961,-96.5577 214.7009,-86.3408 206.137,-92.5786 211.8961,-96.5577\"/>\n</g>\n<!-- 140594624747792 -->\n<g id=\"node4\" class=\"node\">\n<title>140594624747792</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"211,-196 122,-196 122,-177 211,-177 211,-196\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 140594624747792&#45;&gt;140594619322064 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140594624747792&#45;&gt;140594619322064</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.4612,-176.9197C171.6524,-169.8304 174.7135,-159.9269 177.4182,-151.1763\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.8491,-151.9285 180.4583,-141.3408 174.1612,-149.8613 180.8491,-151.9285\"/>\n</g>\n<!-- 140594619415184 -->\n<g id=\"node5\" class=\"node\">\n<title>140594619415184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"211,-251 122,-251 122,-232 211,-232 211,-251\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140594619415184&#45;&gt;140594624747792 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140594619415184&#45;&gt;140594624747792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M166.5,-231.9197C166.5,-224.9083 166.5,-215.1442 166.5,-206.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.0001,-206.3408 166.5,-196.3408 163.0001,-206.3409 170.0001,-206.3408\"/>\n</g>\n<!-- 140594619415504 -->\n<g id=\"node6\" class=\"node\">\n<title>140594619415504</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"211,-306 122,-306 122,-287 211,-287 211,-306\"/>\n<text text-anchor=\"middle\" x=\"166.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140594619415504&#45;&gt;140594619415184 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140594619415504&#45;&gt;140594619415184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M166.5,-286.9197C166.5,-279.9083 166.5,-270.1442 166.5,-261.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.0001,-261.3408 166.5,-251.3408 163.0001,-261.3409 170.0001,-261.3408\"/>\n</g>\n<!-- 140594619413584 -->\n<g id=\"node7\" class=\"node\">\n<title>140594619413584</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"107,-361 0,-361 0,-342 107,-342 107,-361\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ToCopyBackward0</text>\n</g>\n<!-- 140594619413584&#45;&gt;140594619415504 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140594619413584&#45;&gt;140594619415504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.1831,-341.9197C90.9787,-333.2581 117.4052,-320.3957 137.5977,-310.5675\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.2036,-313.6785 146.6633,-306.155 136.14,-307.3844 139.2036,-313.6785\"/>\n</g>\n<!-- 140594619415888 -->\n<g id=\"node8\" class=\"node\">\n<title>140594619415888</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"104,-416 3,-416 3,-397 104,-397 104,-416\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140594619415888&#45;&gt;140594619413584 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140594619415888&#45;&gt;140594619413584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-396.9197C53.5,-389.9083 53.5,-380.1442 53.5,-371.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-371.3408 53.5,-361.3408 50.0001,-371.3409 57.0001,-371.3408\"/>\n</g>\n<!-- 140594619410576 -->\n<g id=\"node9\" class=\"node\">\n<title>140594619410576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"80.5,-483 26.5,-483 26.5,-452 80.5,-452 80.5,-483\"/>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140594619410576&#45;&gt;140594619415888 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140594619410576&#45;&gt;140594619415888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-451.791C53.5,-444.0249 53.5,-434.5706 53.5,-426.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-426.0647 53.5,-416.0648 50.0001,-426.0648 57.0001,-426.0647\"/>\n</g>\n<!-- 140594619415120 -->\n<g id=\"node10\" class=\"node\">\n<title>140594619415120</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-361 125,-361 125,-342 214,-342 214,-361\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140594619415120&#45;&gt;140594619415504 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140594619415120&#45;&gt;140594619415504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M168.9774,-341.9197C168.595,-334.9083 168.0624,-325.1442 167.589,-316.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.0763,-316.1353 167.0368,-306.3408 164.0867,-316.5166 171.0763,-316.1353\"/>\n</g>\n<!-- 140594619413008 -->\n<g id=\"node11\" class=\"node\">\n<title>140594619413008</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"279,-416 172,-416 172,-397 279,-397 279,-416\"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ToCopyBackward0</text>\n</g>\n<!-- 140594619413008&#45;&gt;140594619415120 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140594619413008&#45;&gt;140594619415120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M215.7455,-396.9197C207.8135,-389.1293 196.4212,-377.9405 186.9288,-368.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.1068,-365.8509 179.5198,-361.3408 184.2018,-370.845 189.1068,-365.8509\"/>\n</g>\n<!-- 140594619416080 -->\n<g id=\"node16\" class=\"node\">\n<title>140594619416080</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"321,-361 232,-361 232,-342 321,-342 321,-361\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140594619413008&#45;&gt;140594619416080 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140594619413008&#45;&gt;140594619416080</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M234.3835,-396.9197C241.5352,-389.2072 251.7753,-378.1639 260.3675,-368.8978\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"263.1419,-371.0533 267.3749,-361.3408 258.009,-366.2937 263.1419,-371.0533\"/>\n</g>\n<!-- 140594619413264 -->\n<g id=\"node12\" class=\"node\">\n<title>140594619413264</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"276,-477 175,-477 175,-458 276,-458 276,-477\"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-465\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140594619413264&#45;&gt;140594619413008 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140594619413264&#45;&gt;140594619413008</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M225.5,-457.9688C225.5,-449.5131 225.5,-436.8901 225.5,-426.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.0001,-426.1656 225.5,-416.1656 222.0001,-426.1657 229.0001,-426.1656\"/>\n</g>\n<!-- 140594619412304 -->\n<g id=\"node13\" class=\"node\">\n<title>140594619412304</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"252.5,-550 198.5,-550 198.5,-519 252.5,-519 252.5,-550\"/>\n<text text-anchor=\"middle\" x=\"225.5\" y=\"-526\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140594619412304&#45;&gt;140594619413264 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140594619412304&#45;&gt;140594619413264</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M225.5,-518.9604C225.5,-509.6356 225.5,-497.6748 225.5,-487.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.0001,-487.35 225.5,-477.3501 222.0001,-487.3501 229.0001,-487.35\"/>\n</g>\n<!-- 140594619319184 -->\n<g id=\"node14\" class=\"node\">\n<title>140594619319184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"324,-196 229,-196 229,-177 324,-177 324,-196\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 140594619319184&#45;&gt;140594619451728 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140594619319184&#45;&gt;140594619451728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M271.6191,-176.7382C262.4636,-158.4271 242.5757,-118.6514 230.791,-95.082\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"233.8941,-93.4618 226.2914,-86.0828 227.6331,-96.5924 233.8941,-93.4618\"/>\n</g>\n<!-- 140594624745744 -->\n<g id=\"node15\" class=\"node\">\n<title>140594624745744</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"321,-306 232,-306 232,-287 321,-287 321,-306\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140594624745744&#45;&gt;140594619319184 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140594624745744&#45;&gt;140594619319184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-286.7382C276.5,-268.7541 276.5,-230.0652 276.5,-206.3599\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-206.0828 276.5,-196.0828 273.0001,-206.0829 280.0001,-206.0828\"/>\n</g>\n<!-- 140594619416080&#45;&gt;140594624745744 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140594619416080&#45;&gt;140594624745744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-341.9197C276.5,-334.9083 276.5,-325.1442 276.5,-316.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-316.3408 276.5,-306.3408 273.0001,-316.3409 280.0001,-316.3408\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the computation is nonsensical, you can clearly see the effect of\n",
        "adding a control flow statement.\n",
        "\n"
      ],
      "metadata": {
        "id": "rZ8LQ0vbbF4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizer"
      ],
      "metadata": {
        "id": "4Nk1CaQcbJk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An optimizer takes the parameters we want to update, the learning rate we want\n",
        "to use (and possibly many other hyper-parameters as well!), and performs the\n",
        "updates through its `step()` method.\n",
        "\n",
        "Besides, we also don’t need to zero the gradients one by one anymore. We just\n",
        "invoke the optimizer’s `zero_grad()` method, and that’s it!"
      ],
      "metadata": {
        "id": "eaf0dzELbKon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([b, w], lr=lr)\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = b + w * x_train_tensor\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  error = (yhat - y_train_tensor)\n",
        "  loss = (error ** 2).mean()\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate. But not so fast...\n",
        "\n",
        "  # the learning rate. No more manual update!\n",
        "  # with torch.no_grad():\n",
        "  #     b -= lr * b.grad\n",
        "  #     w -= lr * w.grad\n",
        "  optimizer.step()\n",
        "\n",
        "  # No more telling Pytorch to let gradients go!\n",
        "  # b.grad.zero_()\n",
        "  # w.grad.zero_()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "fr2HTVn4hw3O",
        "outputId": "a250fba7-88ac-4c1f-b245-7e9bbefab03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0530], device='cuda:0', requires_grad=True) tensor([1.9958], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss"
      ],
      "metadata": {
        "id": "OW2RsRudkUH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now tackle the loss computation.\n",
        "\n",
        "There are many loss functions to choose from, depending on the task at\n",
        "hand. Since ours is a regression, we are using the Mean Squared Error (MSE) as\n",
        "loss, and thus we need PyTorch’s `nn.MSELoss`."
      ],
      "metadata": {
        "id": "wbFK8CpBkVEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "loss_fn"
      ],
      "metadata": {
        "id": "usMFBmFQkxvr",
        "outputId": "ff945fc0-f213-475e-888c-16361bb47f78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MSELoss()"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that `nn.MSELoss` is NOT the loss function itself: we do not pass predictions\n",
        "and labels to it!\n",
        "\n",
        "Instead, as you can see, it returns another function, which we called\n",
        "`loss_fn`: that is the actual loss function. \n",
        "\n",
        "So, we can pass a prediction and a label to\n",
        "it and get the corresponding loss value."
      ],
      "metadata": {
        "id": "0f-1YDdBlHgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a random example to illustrate the loss function\n",
        "predictions = torch.tensor([0.5, 1.0])\n",
        "labels = torch.tensor([2.0, 1.3])\n",
        "loss_fn(predictions, labels)"
      ],
      "metadata": {
        "id": "NTb9Wdu4lIDf",
        "outputId": "a20cdfeb-dcbf-465e-e27e-8b9cd02b22f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1700)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Technically speaking, `nn.MSELoss` is a higher-order function."
      ],
      "metadata": {
        "id": "C4Ofk-vglz8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([b, w], lr=lr)\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = b + w * x_train_tensor\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  # No more manual loss!\n",
        "  # error = (yhat - y_train_tensor)\n",
        "  # loss = (error ** 2).mean()\n",
        "  loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate. But not so fast...\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(b, w)"
      ],
      "metadata": {
        "id": "bvJ86Oz6l1o9",
        "outputId": "2c566e31-c1d3-4ef4-93e2-ff4d42f76399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0530], device='cuda:0', requires_grad=True) tensor([1.9958], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s take a look at the loss value at the end of training."
      ],
      "metadata": {
        "id": "dtnqEJnUmhz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "oGXVfhRdmiWI",
        "outputId": "9e8e59db-255a-46c8-aca4-d0b78057a416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we wanted to have it as a Numpy array?"
      ],
      "metadata": {
        "id": "Nnj9Dy1FmtAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  loss.cpu().numpy()\n",
        "except RuntimeError as re:\n",
        "  print(re)"
      ],
      "metadata": {
        "id": "0iqgVbOwmtad",
        "outputId": "82443ed9-be55-4979-9c7a-aed877cc7150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happened here? \n",
        "\n",
        "Unlike our data tensors, the loss tensor is actually computing\n",
        "gradients - to use `numpy()`, we need to `detach()` the tensor from the computation\n",
        "graph first:"
      ],
      "metadata": {
        "id": "inEsdzNKnMXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "XyPP7w9MnQS5",
        "outputId": "df47b641-5dcd-493f-bbff-a3d0ca2d0f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(0.00081317, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This seems like a lot of work; there must be an easier way! \n",
        "\n",
        "And there is one indeed:\n",
        "* we can use `item()`, for tensors with a single element \n",
        "* or tolist() otherwise (it still returns a scalar if there is only one element, though)"
      ],
      "metadata": {
        "id": "3_NG1DVNnkqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item(), loss.tolist())"
      ],
      "metadata": {
        "id": "3FPLnbTbnxoz",
        "outputId": "a7afa94e-e3e5-474b-ec9a-d102bd264958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0008131694048643112 0.0008131694048643112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "nRnSxxCVn-Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most fundamental methods a model class needs to implement are:\n",
        "\n",
        "* `__init__(self)`: it defines the parts that make up the model — in our case,\n",
        "two parameters, `b` and `w`.\n",
        "* `forward(self, x)`: it performs the actual computation, that is, it outputs a\n",
        "prediction, given the input `x`.\n",
        "\n",
        "Let’s build a proper (yet simple) model for our regression task."
      ],
      "metadata": {
        "id": "1pKAXyURn-4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    # To make \"b\" and \"w\" real parameters of the model, we need to wrap them with nn.Parameter\n",
        "    self.w = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Computes the outputs / predictions\n",
        "    return self.b + self.w * x"
      ],
      "metadata": {
        "id": "eCzfSjmHxn-K"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why should we care about the parameters of the model?\n",
        "\n",
        "By doing so, we can use our model’s `parameters()`\n",
        "method to retrieve an iterator over all model’s parameters, including parameters\n",
        "of nested models. \n",
        "\n",
        "Then we can use it to feed our optimizer (instead of building a list\n",
        "of parameters ourselves!)."
      ],
      "metadata": {
        "id": "2opqEi2azQbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Creates a \"dummy\" instance of our LinearRegression model\n",
        "dummy = LinearRegression()\n",
        "list(dummy.parameters())"
      ],
      "metadata": {
        "id": "kRWmGk-pzbgp",
        "outputId": "13347a6e-08b2-4eb1-8491-bfba298a798f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True), Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, we can get the current values of all parameters using our model’s\n",
        "`state_dict()` method."
      ],
      "metadata": {
        "id": "UIndaC2rz7ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy.state_dict()"
      ],
      "metadata": {
        "id": "FlE_fkdqz9Pa",
        "outputId": "02302c8f-5067-415a-85ad-d3260d1010f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('w', tensor([0.3367])), ('b', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the way, the optimizer itself has a `state_dict()` too, which contains its internal\n",
        "state, as well as other hyper-parameters."
      ],
      "metadata": {
        "id": "aBIiEna00OrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.state_dict()"
      ],
      "metadata": {
        "id": "ghbpwjzi0QsR",
        "outputId": "5b9d0256-353b-49cc-9a45-efae0b7f2fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'state': {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}},\n",
              " 'param_groups': [{'lr': 0.1,\n",
              "   'momentum': 0,\n",
              "   'dampening': 0,\n",
              "   'weight_decay': 0,\n",
              "   'nesterov': False,\n",
              "   'maximize': False,\n",
              "   'foreach': None,\n",
              "   'params': [0, 1]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to send our model to the same device\n",
        "where the data is. If our data is made of GPU tensors, our model\n",
        "must “live” inside the GPU as well."
      ],
      "metadata": {
        "id": "LenGC-op0oQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Creates a \"dummy\" instance of our LinearRegression model and sends it to the device\n",
        "dummy = LinearRegression().to(device)"
      ],
      "metadata": {
        "id": "SQyJ9nLz0sV9"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward pass is the moment when the model makes predictions.\n",
        "\n",
        ">Remember: you should make predictions calling `model(x)`"
      ],
      "metadata": {
        "id": "vqoVcPSm3TDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "# b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "# w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = LinearRegression().to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([b, w], lr=lr)\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()  # set the model to training mode\n",
        "\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  # No more manual prediction!\n",
        "  yhat = model(x_train_tensor)\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate. But not so fast...\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "# We can also inspect its parameters using its state_dict\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "zomSC5t03WzE",
        "outputId": "8b492034-68e7-4fd8-ffe6-66570a546546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('w', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Nested Models"
      ],
      "metadata": {
        "id": "_KguFZXp41go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bsq1hLN442f7"
      }
    }
  ]
}