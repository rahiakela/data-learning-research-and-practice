{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9AleyRMuSDC24fHPgRbmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-research-and-practice/blob/main/deep-learning-with-pytorch-step-by-step/03_rethinking_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rethinking the Training Loop"
      ],
      "metadata": {
        "id": "eB520cKUnVhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I will stick with a simple and familiar problem:\n",
        "a linear regression with a single feature x! It doesn’t get much simpler than that…\n",
        "\n",
        "$$ y = b + wx + ϵ$$\n",
        "\n",
        "It is also possible to think of it as the simplest neural network possible: one input,\n",
        "one output, and no activation function (that is, linear).\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5wTQQbxanWY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "a60l9BX2oE0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    import requests\n",
        "    url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/config.py'\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    open('config.py', 'wb').write(r.content)    \n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "\n",
        "from config import *\n",
        "config_chapter2()\n",
        "# This is needed to render the plots in this chapter\n",
        "from plots.chapter2 import *"
      ],
      "metadata": {
        "id": "pgGfHWV5oZqU",
        "outputId": "a070d008-1ccd-44eb-eee6-3a806b8540d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files from GitHub repo to Colab...\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "TUEV99bdogt_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Generation"
      ],
      "metadata": {
        "id": "IS1-btItoZ1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start generating some synthetic data: we start with a vector of `100 (N)` points\n",
        "for our feature `(x)` and create our labels `(y)` using `b = 1, w = 2`, and some Gaussian noise (epsilon)."
      ],
      "metadata": {
        "id": "U6ucNoo7oawj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "# Data Generation\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (.1 * np.random.rand(N, 1))\n",
        "y = true_b + true_w * x + epsilon"
      ],
      "metadata": {
        "id": "7i8oVtQPpATN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's split our synthetic data into train and validation sets, shuffling the array\n",
        "of indexes and using the first 80 shuffled points for training."
      ],
      "metadata": {
        "id": "6Bg1PAVnpncx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffles the indices\n",
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:int(N * .8)]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[int(N * .8): ]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "metadata": {
        "id": "6c8vMI5Kpn3Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Model Training"
      ],
      "metadata": {
        "id": "ARz968upHBAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let's consider again with our previous important question:\n",
        "\n",
        "Would the code inside the training loop change if we were using a\n",
        "different optimizer, or loss, or even model?\n",
        "\n",
        "The answer: NO.\n",
        "\n",
        "The model training involves looping over the four gradient descent steps (or one\n",
        "training step, for that matter) and those are always the same, regardless of which model, loss or optimizer we use.\n",
        "\n",
        "Let’s take a look at the code once again:"
      ],
      "metadata": {
        "id": "v1jAx0vDHBtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preparation"
      ],
      "metadata": {
        "id": "tRX_F3wmRFXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After generating our\n",
        "data points, the only preparation step performed so far was\n",
        "transforming Numpy arrays into PyTorch tensors."
      ],
      "metadata": {
        "id": "xzol68u0RSOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v0.py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors and then we send them to the chosen device\n",
        "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
      ],
      "metadata": {
        "id": "x-rPHa6LRWuq",
        "outputId": "96886c86-2329-433c-cc2b-35c4f9009095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_preparation/v0.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v0.py"
      ],
      "metadata": {
        "id": "cBF7SEYSTI_-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we’re using the -i option, it works exactly as if we had copied the code from\n",
        "the files into a cell and executed it."
      ],
      "metadata": {
        "id": "kg6FC-O9TZUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Configuration"
      ],
      "metadata": {
        "id": "4jQqdmSYTaHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of organizing our code, we’ll include the following elements in the\n",
        "model configuration part:\n",
        "\n",
        "* a model\n",
        "* a loss function\n",
        "* an optimizer"
      ],
      "metadata": {
        "id": "wGBV8Zb_TcVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v0.py\n",
        "\n",
        "# This is redundant now, but it won't be when we introduce Datasets...\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")"
      ],
      "metadata": {
        "id": "WeoEaGC9Tzxd",
        "outputId": "416f0c62-8799-4309-8062-b6b153bb1c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_configuration/v0.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v0.py"
      ],
      "metadata": {
        "id": "m_h5sDaTewxh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Training"
      ],
      "metadata": {
        "id": "tMRPucpXfHdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the last part, where the actual training takes place. It loops over the gradient\n",
        "descent steps.\n",
        "\n",
        "* Step 1: compute model’s predictions\n",
        "* Step 2: compute the loss\n",
        "* Step 3: compute the gradients\n",
        "* Step 4: update the parameters\n",
        "\n",
        "Since we are not manually creating parameters anymore, the initialization is\n",
        "handled inside each layer during model creation."
      ],
      "metadata": {
        "id": "M4_DEgYjfILZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v0.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Sets model to TRAIN mode\n",
        "  model.train()\n",
        "\n",
        "  # Step 1 - Computes model's predicted output - forward pass\n",
        "  yhat = model(x_train_tensor)\n",
        "\n",
        "  # Step 2 - Computes the loss\n",
        "  loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "  # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # Step 4 - Updates parameters using gradients and the learning rate\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "xiuJG7Qtfg8E",
        "outputId": "41c50d7a-0bdd-404d-8fab-3fcaf4a455d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_training/v0.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v0.py"
      ],
      "metadata": {
        "id": "kWvH9I1FgVfn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One last check to make sure we have everything right."
      ],
      "metadata": {
        "id": "2lHjU-fbgd0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "aoGyMDKOgefz",
        "outputId": "7ce4398c-29c1-4efd-fead-d5212c264e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9958]])), ('0.bias', tensor([1.0530]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about writing a function that takes a model, a loss, and an optimizer and\n",
        "returns another function that performs a training step?\n",
        "\n",
        "The latter would then\n",
        "take the features and corresponding labels as arguments and returning the\n",
        "corresponding loss.\n",
        "\n",
        ">Wait, what?! A function that returns another function?\n",
        "\n",
        "Sounds complicated, right? \n",
        "\n",
        "It is not as bad as it sounds, though… that’s called a\n",
        "higher-order function, and it is very useful for reducing boilerplate."
      ],
      "metadata": {
        "id": "JAo6Iogwh5tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Better Model Training"
      ],
      "metadata": {
        "id": "Pa5P-hTuo4Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The higher-order function that builds a training step function for us is taking the key elements of our training loop: model, loss, and\n",
        "optimizer. \n",
        "\n",
        "The actual training step function to be returned will have two\n",
        "arguments, namely, features and labels, and will return the corresponding loss\n",
        "value."
      ],
      "metadata": {
        "id": "gkCmgzGoo8Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "\n",
        "  # Builds function that performs a step in the train loop\n",
        "  def perform_train_step(x, y):\n",
        "    # Sets model to TRAIN mode\n",
        "    model.train()\n",
        "\n",
        "    # Step 1 - Computes model's predictions - forward pass\n",
        "    yhat = model(x)\n",
        "\n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y)\n",
        "\n",
        "    # Step 3 - Computes gradients for \"b\" and \"w\" parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Step 4 - Updates parameters using gradients and the learning rate\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Returns the loss\n",
        "    return loss.item()\n",
        "\n",
        "  # Returns the function that will be called inside the train loop\n",
        "  return perform_train_step"
      ],
      "metadata": {
        "id": "b3XefPFXpRn_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to update our Model Configuration code to call this higher-order function to build a `train_step` function. \n",
        "\n",
        "But\n",
        "we need to run a data preparation script first."
      ],
      "metadata": {
        "id": "vApqciVVswCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v0.py"
      ],
      "metadata": {
        "id": "VZysAc4ys19V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_configuration/v1.py\n",
        "\n",
        "# This is redundant now, but it won't be when we introduce Datasets...\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBmRPVIUtgUm",
        "outputId": "bbb5ef51-435a-4f85-bcae-3935d39b95ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_configuration/v1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "8Ll6fOk5uSAL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check our `train_step` function out!"
      ],
      "metadata": {
        "id": "ZIWCLSLcubIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4auCaYf7ucuv",
        "outputId": "bb2fd7ec-55e6-4aad-aa85-bb73f03994cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.make_train_step.<locals>.perform_train_step(x, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking good! \n",
        "\n",
        "Now we need to update our Model Training to replace the code\n",
        "inside the loop with a call to our newly created function."
      ],
      "metadata": {
        "id": "-2jASa-WuvLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v1.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "# Keeping track of the training loss\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "  # Performs one train step and returns the corresponding loss\n",
        "  loss = train_step(x_train_tensor, y_train_tensor)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiCi6H2Kuvw6",
        "outputId": "ed12c630-cea6-4b5e-aa27-e69f2160fc1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v1.py"
      ],
      "metadata": {
        "id": "iUtoiOiZvVA7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we check if our changes did not introduce any bugs? \n",
        "\n",
        "We can inspect our model’s `state_dict()`:"
      ],
      "metadata": {
        "id": "GST-Bs1ww_PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXvayjiTxCXj",
        "outputId": "661d9b7c-a724-4b52-e6fa-4f0547767c2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9958]])), ('0.bias', tensor([1.0530]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "NP8OOLSfxUck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, a dataset is represented by a regular Python class that inherits from the Dataset class. \n",
        "\n",
        "You can think of it as a list of tuples, each tuple corresponding to one point (features, label).\n",
        "\n",
        "The most fundamental methods it needs to implement are:\n",
        "\n",
        "* `__init__(self)`: it takes whatever arguments needed to build a list of tuples —it may be the name of a CSV file that will be loaded and processed; it may be two tensors, one for features, another one for labels; or anything else, depending on the task at hand.\n",
        "\n",
        "* `__get_item__(self, index)`: it allows the dataset to be indexed so that it can work like a `list(dataset[i])` — it must return a `tuple (features, label)` corresponding to the requested data point.\n",
        "\n",
        "* `__len__(self)`: it should simply return the size of the whole dataset so,\n",
        "whenever it is sampled, its indexing is limited to the actual size.\n",
        "\n",
        "Let’s build a simple custom dataset that takes two tensors as arguments: one for\n",
        "the features, one for the labels. \n",
        "\n",
        "For any given index, our dataset class will return\n",
        "the corresponding slice of each one of those tensors.\n",
        "\n"
      ],
      "metadata": {
        "id": "4srFgmz4xVaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, x_tensor, y_tensor):\n",
        "    self.x = x_tensor\n",
        "    self.y = y_tensor\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return (self.x[index], self.y[index])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "metadata": {
        "id": "kXCHwb_Mh1ZN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "NfjY1KNTioKk",
        "outputId": "5f755f29-6617-4f97-8f74-54c9a0f3aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.5227]), tensor([2.1181]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don’t want our whole training data to be loaded into GPU\n",
        "tensors, as we have been doing in our example so far, because it\n",
        "takes up space in our precious graphics card’s RAM.\n",
        "\n",
        "But, we can use PyTorch’s TensorDataset class, which\n",
        "will do pretty much the same as our custom dataset."
      ],
      "metadata": {
        "id": "DH5fVRIPkJGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "0SphydMtki6C",
        "outputId": "474860d2-887d-43a0-f13c-3677f6f4e1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.5227]), tensor([2.1181]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, fine, but then again, why are we building a dataset anyway? \n",
        "\n",
        "We’re doing it because we want to use a....**DataLoader**."
      ],
      "metadata": {
        "id": "KtGGiTvZk1EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataLoader"
      ],
      "metadata": {
        "id": "qd1DwTWWk48j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Until now, we have used the whole training data at every training step. It has been\n",
        "batch gradient descent all along. This is fine for our ridiculously small dataset, sure,\n",
        "but if we want to go serious about all this, we must use mini-batch gradient\n",
        "descent. Thus, we need mini-batches. Thus, we need to slice our dataset\n",
        "accordingly.\n",
        "\n",
        "So we use PyTorch’s DataLoader class for this job. We tell it which dataset to use, the desired mini-batch size, and\n",
        "if we’d like to shuffle it or not. That’s it!\n",
        "\n",
        ">There is more to a DataLoader than meets the eye… it is also\n",
        "possible to use it together with a sampler to fetch mini-batches\n",
        "that compensate for imbalanced classes, for instance.\n",
        "\n",
        "Our loader will behave like an iterator, so we can loop over it and fetch a different mini-batch every time.\n",
        "\n",
        "In our example, we have only 80 training points, so I chose a mini-batch size of 16\n",
        "to conveniently split the training set into five mini-batches."
      ],
      "metadata": {
        "id": "GojMDQEsk63m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "EOAzhlgMnDsy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve a mini-batch, one can simply run the command below — it will return a\n",
        "list containing two tensors, one for the features, another one for the labels:"
      ],
      "metadata": {
        "id": "qlujyigtnViT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "id": "8I2fCHaUnWDq",
        "outputId": "cfa5174f-c806-491a-c8fd-f779ef6e97d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.3309],\n",
              "         [0.8662],\n",
              "         [0.1849],\n",
              "         [0.8155],\n",
              "         [0.3042],\n",
              "         [0.3253],\n",
              "         [0.3745],\n",
              "         [0.4938],\n",
              "         [0.1196],\n",
              "         [0.1960],\n",
              "         [0.4402],\n",
              "         [0.7081],\n",
              "         [0.6075],\n",
              "         [0.1997],\n",
              "         [0.5467],\n",
              "         [0.6842]]), tensor([[1.7543],\n",
              "         [2.8079],\n",
              "         [1.3976],\n",
              "         [2.6536],\n",
              "         [1.6889],\n",
              "         [1.7235],\n",
              "         [1.7522],\n",
              "         [2.0225],\n",
              "         [1.2485],\n",
              "         [1.4681],\n",
              "         [1.9775],\n",
              "         [2.4238],\n",
              "         [2.2568],\n",
              "         [1.4811],\n",
              "         [2.0986],\n",
              "         [2.4048]])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this change our code so far? Let’s check it out!\n",
        "\n",
        "First, we need to add both Dataset and DataLoader elements into our data\n",
        "preparation part of the code. \n",
        "\n",
        "Also, notice that we do not send our tensors to the\n",
        "device just yet."
      ],
      "metadata": {
        "id": "hAi0z6RsyGGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v1.py\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "x_train_tensor = torch.as_tensor(x_train).float()\n",
        "y_train_tensor = torch.as_tensor(y_train).float()\n",
        "\n",
        "# Builds Dataset\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "# Builds DataLoader\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "iMa22sWVyKAx",
        "outputId": "4b334b29-edfa-4a2f-9e1d-34c2e2720754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preparation/v1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py"
      ],
      "metadata": {
        "id": "_WPDJl1X0L-I"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to incorporate the mini-batch gradient descent logic into our model\n",
        "training part of the code."
      ],
      "metadata": {
        "id": "RGyD5CRh0kVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to run the model configuration first\n",
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "mCCDiFu40k9z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v2.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "# Keeping track of the training loss\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "  mini_batch_losses = []\n",
        "  # mini-batch inner loop\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    # the dataset \"lives\" in the CPU, so do our mini-batches \n",
        "    # therefore, we need to send those mini-batches to the device where the model \"lives\"\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    # Performs one train step and returns the corresponding loss for this mini-batch\n",
        "    mini_batch_loss = train_step(x_batch, y_batch)\n",
        "    # Keeping track of the loss inside each mini-batch\n",
        "    mini_batch_losses.append(mini_batch_loss)\n",
        "  \n",
        "  # Computes average loss over all mini-batches \n",
        "  # That's the epoch loss\n",
        "  loss = np.mean(mini_batch_losses)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "L8RR9G-W0xj2",
        "outputId": "f0362e29-0b4d-40e5-a0c4-4739accff937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v2.py"
      ],
      "metadata": {
        "id": "Eif7Ri4t2jYe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not so bad, right? So, it is time to check if our code still works well."
      ],
      "metadata": {
        "id": "foAlAncZ7d0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "r6J6geS87ene",
        "outputId": "a9cfaf15-dfd9-4b88-f672-6eb46b192bd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9959]])), ('0.bias', tensor([1.0531]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did you get slightly different values? \n",
        "\n",
        "Try running the whole\n",
        "pipeline again:"
      ],
      "metadata": {
        "id": "6sG9EyPf7poX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py\n",
        "%run -i model_configuration/v1.py\n",
        "%run -i model_training/v2.py"
      ],
      "metadata": {
        "id": "0-SO9Fe17q9o"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "8BF3OIf975aY",
        "outputId": "ffc3b4b5-f606-4ad3-e549-dce39ce7c3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9959]])), ('0.bias', tensor([1.0531]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the DataLoader draws random samples, executing other\n",
        "code between the last two steps of the pipeline may interfere\n",
        "with the reproducibility of the results.\n",
        "\n",
        "Did you notice it is taking longer to train now? Can you guess\n",
        "why?\n",
        "\n",
        "The training time is longer now because the inner loop is executed five\n",
        "times for each epoch (in our example, since we are using a mini-batch of size 16 and we have 80 training data points in total, we execute the inner loop `80 / 16 = 5` times). \n",
        "\n",
        "So, in total, we are calling the train_step a total of 5,000 times now! No\n",
        "wonder it’s taking longer!"
      ],
      "metadata": {
        "id": "FaKrHaQ28Bz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mini-Batch"
      ],
      "metadata": {
        "id": "nT6ko3vR8fMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now on, it is very unlikely that you’ll ever use (full) batch gradient descent again, both in this book or in real life :-) \n",
        "\n",
        "So, it makes sense to, once again, organize a\n",
        "piece of code that’s going to be used repeatedly into its own function: the minibatch\n",
        "inner loop!\n",
        "\n",
        "The inner loop depends on three elements:\n",
        "\n",
        "* the device where data is being sent to\n",
        "* data loader to draw mini-batches from\n",
        "* step function, returning the corresponding loss"
      ],
      "metadata": {
        "id": "5eP4OIY58f-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch(device, data_loader, step):\n",
        "  mini_batch_losses = []\n",
        "  for x_batch, y_batch in data_loader:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    mini_batch_loss = step(x_batch, y_batch)\n",
        "    mini_batch_losses.append(mini_batch_loss)\n",
        "  \n",
        "  loss = np.mean(mini_batch_losses)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "nCaO2fXPqiaD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we realized that we were executing five times more updates per epoch due to the mini-batch inner loop. Before, 1,000\n",
        "epochs meant 1,000 updates. \n",
        "\n",
        "Now, we only need 200 epochs to perform the same\n",
        "1,000 updates."
      ],
      "metadata": {
        "id": "qHemM4WwrxnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation//v1.py\n",
        "%run -i model_configuration/v1.py"
      ],
      "metadata": {
        "id": "cXHuzakqsD2l"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_training/v3.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 200\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # mini_batch inner loop\n",
        "  loss = mini_batch(device, train_loader, train_step)\n",
        "  losses.append(loss)"
      ],
      "metadata": {
        "id": "C-C6VS8XsMh1",
        "outputId": "8d7c59f0-6a75-4d41-b77a-29d58392722c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_training/v3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i model_training/v3.py"
      ],
      "metadata": {
        "id": "SzmQ3oMctvEq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "id": "pD2jeR73t2Yu",
        "outputId": "762041bb-8bbb-490e-8888-cb3bcf7dde9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[1.9959]])), ('0.bias', tensor([1.0534]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Split"
      ],
      "metadata": {
        "id": "bGOoj1uhuG8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch’s `random_split()` method is an easy and familiar way of performing a\n",
        "training-validation split."
      ],
      "metadata": {
        "id": "lhVJCAZGuIha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preparation/v2.py\n",
        "\n",
        "torch.manual_seed(13)\n",
        "\n",
        "# Builds tensors from numpy arrays BEFORE split\n",
        "x_tensor = torch.as_tensor(x).float()\n",
        "y_tensor = torch.as_tensor(y).float()\n",
        "\n",
        "# Builds dataset containing ALL data points\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "# Performs the split\n",
        "ratio = 0.8\n",
        "n_total = len(dataset)\n",
        "n_train = int(n_total * ratio)\n",
        "n_val = n_total - n_train\n",
        "# Performing train-validation split in PyTorch\n",
        "train_data, val_data = random_split(dataset, [n_train, n_val])\n",
        "\n",
        "# Builds a loader of each set\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=16)"
      ],
      "metadata": {
        "id": "eyGsp5N6ufUX",
        "outputId": "85fbd256-d3e3-4f41-8660-94d41f246e1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preparation/v2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i data_preparation/v2.py"
      ],
      "metadata": {
        "id": "NgleCDlVvtfR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation"
      ],
      "metadata": {
        "id": "OLBsh4POv-QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n0BnDBLmv_pG"
      }
    }
  ]
}